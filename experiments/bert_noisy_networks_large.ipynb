{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_noisy_networks_large.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaT3om3nMpml",
        "colab_type": "text"
      },
      "source": [
        "# Textworld starting kit notebook\n",
        "\n",
        "Model: *Bert-DQN with replay memory*\n",
        "\n",
        "When running first: \n",
        " 1. Run the first 2 code cells(with pip installations)\n",
        " 2. Restart runtime\n",
        " 3. Countinue with the next cells\n",
        "\n",
        "This is done, because there is a problem with dependencies of **textworld** and **colab**, requiring different versions of **prompt-toolkit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-XUxa37Z1S5",
        "colab_type": "code",
        "outputId": "b7c7ba80-2d53-4fdc-bb56-6a3589bdb611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "!pip install textworld"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textworld in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pillow>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from textworld) (6.1.0)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.0.3)\n",
            "Requirement already satisfied: greenlet==0.4.13 in /usr/local/lib/python3.6/dist-packages (from textworld) (0.4.13)\n",
            "Requirement already satisfied: tatsu>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from textworld) (4.4.0)\n",
            "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.3.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from textworld) (7.0.0)\n",
            "Requirement already satisfied: urwid>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from textworld) (2.0.1)\n",
            "Requirement already satisfied: selenium>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from textworld) (3.141.0)\n",
            "Requirement already satisfied: jericho>=1.1.5 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.2.4)\n",
            "Requirement already satisfied: gym==0.10.4 in /usr/local/lib/python3.6/dist-packages (from textworld) (0.10.4)\n",
            "Requirement already satisfied: networkx>=2 in /usr/local/lib/python3.6/dist-packages (from textworld) (2.3)\n",
            "Requirement already satisfied: pybars3>=0.9.3 in /usr/local/lib/python3.6/dist-packages (from textworld) (0.9.6)\n",
            "Requirement already satisfied: pyyaml>=3.12 in /usr/local/lib/python3.6/dist-packages (from textworld) (3.13)\n",
            "Requirement already satisfied: gevent==1.3.5 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.3.5)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.12.3)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from textworld)\n",
            "  Using cached https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.16.4)\n",
            "Requirement already satisfied: tqdm>=4.17.1 in /usr/local/lib/python3.6/dist-packages (from textworld) (4.28.1)\n",
            "Requirement already satisfied: hashids>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.2.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->textworld) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->textworld) (2.10.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->textworld) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->textworld) (0.15.4)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot>=1.2.4->textworld) (2.4.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium>=3.12.0->textworld) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym==0.10.4->textworld) (1.12.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.4->textworld) (1.3.2)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.4->textworld) (2.21.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2->textworld) (4.4.0)\n",
            "Requirement already satisfied: PyMeta3>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from pybars3>=0.9.3->textworld) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0.0->textworld) (2.19)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->textworld) (0.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask>=1.0.2->textworld) (1.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym==0.10.4->textworld) (0.16.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.4->textworld) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.4->textworld) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.4->textworld) (2019.6.16)\n",
            "\u001b[31mERROR: ipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: prompt-toolkit\n",
            "  Found existing installation: prompt-toolkit 1.0.16\n",
            "    Uninstalling prompt-toolkit-1.0.16:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.16\n",
            "Successfully installed prompt-toolkit-2.0.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPpv7-6bVOsP",
        "colab_type": "code",
        "outputId": "0c29a202-2f9f-4222-ee83-98fe5003657d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!pip install prompt-toolkit==1.0.16"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting prompt-toolkit==1.0.16\n",
            "  Using cached https://files.pythonhosted.org/packages/57/a8/a151b6c61718eabe6b4672b6aa760b734989316d62ec1ba4996765e602d4/prompt_toolkit-1.0.16-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit==1.0.16) (1.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit==1.0.16) (0.1.7)\n",
            "\u001b[31mERROR: textworld 1.1.1 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: jupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.16 which is incompatible.\u001b[0m\n",
            "Installing collected packages: prompt-toolkit\n",
            "  Found existing installation: prompt-toolkit 2.0.9\n",
            "    Uninstalling prompt-toolkit-2.0.9:\n",
            "      Successfully uninstalled prompt-toolkit-2.0.9\n",
            "Successfully installed prompt-toolkit-1.0.16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48AF5zST9VJK",
        "colab_type": "code",
        "outputId": "c6f479f7-3a09-4304-a2c5-950c694b5e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.175)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.6.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.175 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.175)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.175->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.175->boto3->pytorch_pretrained_bert) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.175->boto3->pytorch_pretrained_bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75fX90LVjfbT",
        "colab_type": "code",
        "outputId": "66fddeb1-1271-4577-cce3-2e87c637f079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "import logging\n",
        "import yaml\n",
        "import copy\n",
        "import spacy\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Any\n",
        "from collections import namedtuple\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "import gym\n",
        "import textworld.gym\n",
        "from textworld import EnvInfos\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-5AX-b4f25d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWGX1rdFtIgW",
        "colab_type": "text"
      },
      "source": [
        "## Generic functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zO94P3hjyH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_np(x):\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return x\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "\n",
        "def to_pt(np_matrix, enable_cuda=False, type='long'):\n",
        "    if type == 'long':\n",
        "        if enable_cuda:\n",
        "            return torch.autograd.Variable(torch.from_numpy(np_matrix).type(torch.LongTensor).cuda())\n",
        "        else:\n",
        "            return torch.autograd.Variable(torch.from_numpy(np_matrix).type(torch.LongTensor))\n",
        "    elif type == 'float':\n",
        "        if enable_cuda:\n",
        "            return torch.autograd.Variable(torch.from_numpy(np_matrix).type(torch.FloatTensor).cuda())\n",
        "        else:\n",
        "            return torch.autograd.Variable(torch.from_numpy(np_matrix).type(torch.FloatTensor))\n",
        "\n",
        "\n",
        "def _words_to_ids(words, word2id):\n",
        "    ids = []\n",
        "    for word in words:\n",
        "        try:\n",
        "            ids.append(word2id[word])\n",
        "        except KeyError:\n",
        "            ids.append(1)\n",
        "    return ids\n",
        "\n",
        "\n",
        "def preproc(s, str_type='None', tokenizer=None, lower_case=True):\n",
        "    if s is None:\n",
        "        return [\"nothing\"]\n",
        "    s = s.replace(\"\\n\", ' ')\n",
        "    if s.strip() == \"\":\n",
        "        return [\"nothing\"]\n",
        "    if str_type == 'feedback':\n",
        "        if \"$$$$$$$\" in s:\n",
        "            s = \"\"\n",
        "        if \"-=\" in s:\n",
        "            s = s.split(\"-=\")[0]\n",
        "    s = s.strip()\n",
        "    if len(s) == 0:\n",
        "        return [\"nothing\"]\n",
        "    tokens = [t.text for t in tokenizer(s)]\n",
        "    if lower_case:\n",
        "        tokens = [t.lower() for t in tokens]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def max_len(list_of_list):\n",
        "    return max(map(len, list_of_list))\n",
        "\n",
        "\n",
        "def pad_sequences(sequences, maxlen=None, dtype='int32', value=0.):\n",
        "    '''\n",
        "    Partially borrowed from Keras\n",
        "    # Arguments\n",
        "        sequences: list of lists where each element is a sequence\n",
        "        maxlen: int, maximum length\n",
        "        dtype: type to cast the resulting sequence.\n",
        "        value: float, value to pad the sequences to the desired value.\n",
        "    # Returns\n",
        "        x: numpy array with dimensions (number_of_sequences, maxlen)\n",
        "    '''\n",
        "    lengths = [len(s) for s in sequences]\n",
        "    nb_samples = len(sequences)\n",
        "    if maxlen is None:\n",
        "        maxlen = np.max(lengths)\n",
        "    # take the sample shape from the first non empty sequence\n",
        "    # checking for consistency in the main loop below.\n",
        "    sample_shape = tuple()\n",
        "    for s in sequences:\n",
        "        if len(s) > 0:\n",
        "            sample_shape = np.asarray(s).shape[1:]\n",
        "            break\n",
        "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
        "    for idx, s in enumerate(sequences):\n",
        "        if len(s) == 0:\n",
        "            continue  # empty list was found\n",
        "        # pre truncating\n",
        "        trunc = s[-maxlen:]\n",
        "        # check `trunc` has expected shape\n",
        "        trunc = np.asarray(trunc, dtype=dtype)\n",
        "        if trunc.shape[1:] != sample_shape:\n",
        "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
        "                             (trunc.shape[1:], idx, sample_shape))\n",
        "        # post padding\n",
        "        x[idx, :len(trunc)] = trunc\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HTSoK93tM6V",
        "colab_type": "text"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2VSAkD3s7Ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def masked_mean(x, m=None, dim=-1):\n",
        "    \"\"\"\n",
        "        mean pooling when there're paddings\n",
        "        input:  tensor: batch x time x h\n",
        "                mask:   batch x time\n",
        "        output: tensor: batch x h\n",
        "    \"\"\"\n",
        "    if m is None:\n",
        "        return torch.mean(x, dim=dim)\n",
        "    mask_sum = torch.sum(m, dim=-1)  # batch\n",
        "    res = torch.sum(x, dim=1)  # batch x h\n",
        "    mean = res / (mask_sum.unsqueeze(-1) + 1e-6)\n",
        "    \n",
        "    del mask_sum\n",
        "    del res\n",
        "    \n",
        "    return mean\n",
        "\n",
        "\n",
        "class Embedding(torch.nn.Module):\n",
        "    '''\n",
        "    inputs: x:          batch x seq (x is post-padded by 0s)\n",
        "    outputs:embedding:  batch x seq x emb\n",
        "            mask:       batch x seq\n",
        "    '''\n",
        "\n",
        "    def __init__(self, embedding_size, vocab_size, enable_cuda=False):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.enable_cuda = enable_cuda\n",
        "        self.embedding_layer = torch.nn.Embedding(self.vocab_size, self.embedding_size, padding_idx=0)\n",
        "\n",
        "    def compute_mask(self, x):\n",
        "        mask = torch.ne(x, 0).float()\n",
        "        if self.enable_cuda:\n",
        "            mask = mask.cuda()\n",
        "        return mask\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.embedding_layer(x)  # batch x time x emb\n",
        "        mask = self.compute_mask(x)  # batch x time\n",
        "        return embeddings, mask\n",
        "\n",
        "\n",
        "class FastUniLSTM(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Adapted from https://github.com/facebookresearch/DrQA/\n",
        "    now supports:   different rnn size for each layer\n",
        "                    all zero rows in batch (from time distributed layer, by reshaping certain dimension)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ninp, nhids, dropout_between_rnn_layers=0.):\n",
        "        super(FastUniLSTM, self).__init__()\n",
        "        self.ninp = ninp\n",
        "        self.nhids = nhids\n",
        "        self.nlayers = len(self.nhids)\n",
        "        self.dropout_between_rnn_layers = dropout_between_rnn_layers\n",
        "        self.stack_rnns()\n",
        "\n",
        "    def stack_rnns(self):\n",
        "        rnns = [torch.nn.LSTM(self.ninp if i == 0 else self.nhids[i - 1],\n",
        "                              self.nhids[i],\n",
        "                              num_layers=1,\n",
        "                              bidirectional=False) for i in range(self.nlayers)]\n",
        "        self.rnns = torch.nn.ModuleList(rnns)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "        def pad_(tensor, n):\n",
        "            if n > 0:\n",
        "                zero_pad = torch.autograd.Variable(torch.zeros((n,) + tensor.size()[1:]))\n",
        "                if x.is_cuda:\n",
        "                    zero_pad = zero_pad.cuda()\n",
        "                tensor = torch.cat([tensor, zero_pad])\n",
        "            return tensor\n",
        "\n",
        "        \"\"\"\n",
        "        inputs: x:          batch x time x inp\n",
        "                mask:       batch x time\n",
        "        output: encoding:   batch x time x hidden[-1]\n",
        "        \"\"\"\n",
        "        # Compute sorted sequence lengths\n",
        "        batch_size = x.size(0)\n",
        "        lengths = mask.data.eq(1).long().sum(1)  # .squeeze()\n",
        "        _, idx_sort = torch.sort(lengths, dim=0, descending=True)\n",
        "        _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
        "\n",
        "        lengths = list(lengths[idx_sort])\n",
        "        idx_sort = torch.autograd.Variable(idx_sort)\n",
        "        idx_unsort = torch.autograd.Variable(idx_unsort)\n",
        "\n",
        "        # Sort x\n",
        "        x = x.index_select(0, idx_sort)\n",
        "\n",
        "        # remove non-zero rows, and remember how many zeros\n",
        "        n_nonzero = np.count_nonzero(lengths)\n",
        "        n_zero = batch_size - n_nonzero\n",
        "        if n_zero != 0:\n",
        "            lengths = lengths[:n_nonzero]\n",
        "            x = x[:n_nonzero]\n",
        "\n",
        "        # Transpose batch and sequence dims\n",
        "        x = x.transpose(0, 1)\n",
        "\n",
        "        # Pack it up\n",
        "        rnn_input = torch.nn.utils.rnn.pack_padded_sequence(x, lengths)\n",
        "\n",
        "        # Encode all layers\n",
        "        outputs = [rnn_input]\n",
        "        for i in range(self.nlayers):\n",
        "            rnn_input = outputs[-1]\n",
        "\n",
        "            # dropout between rnn layers\n",
        "            if self.dropout_between_rnn_layers > 0:\n",
        "                dropout_input = F.dropout(rnn_input.data,\n",
        "                                          p=self.dropout_between_rnn_layers,\n",
        "                                          training=self.training)\n",
        "                rnn_input = torch.nn.utils.rnn.PackedSequence(dropout_input,\n",
        "                                                              rnn_input.batch_sizes)\n",
        "            seq, last = self.rnns[i](rnn_input)\n",
        "            outputs.append(seq)\n",
        "            if i == self.nlayers - 1:\n",
        "                # last layer\n",
        "                last_state = last[0]  # (num_layers * num_directions, batch, hidden_size)\n",
        "                last_state = last_state[0]  # batch x hidden_size\n",
        "\n",
        "        # Unpack everything\n",
        "        for i, o in enumerate(outputs[1:], 1):\n",
        "            outputs[i] = torch.nn.utils.rnn.pad_packed_sequence(o)[0]\n",
        "        output = outputs[-1]\n",
        "\n",
        "        # Transpose and unsort\n",
        "        output = output.transpose(0, 1)  # batch x time x enc\n",
        "\n",
        "        # re-padding\n",
        "        output = pad_(output, n_zero)\n",
        "        last_state = pad_(last_state, n_zero)\n",
        "\n",
        "        output = output.index_select(0, idx_unsort)\n",
        "        last_state = last_state.index_select(0, idx_unsort)\n",
        "\n",
        "        # Pad up to original batch sequence length\n",
        "        if output.size(1) != mask.size(1):\n",
        "            padding = torch.zeros(output.size(0),\n",
        "                                  mask.size(1) - output.size(1),\n",
        "                                  output.size(2)).type(output.data.type())\n",
        "            output = torch.cat([output, torch.autograd.Variable(padding)], 1)\n",
        "\n",
        "        output = output.contiguous() * mask.unsqueeze(-1)\n",
        "        return output, last_state, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93Y3-eLM-GRh",
        "colab_type": "text"
      },
      "source": [
        "## Noisy nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGSnUaaL-NUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoisyLinear(torch.nn.Module):\n",
        "    def __init__(self, in_features, out_features, std_init=0.4):\n",
        "        super(NoisyLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.std_init = std_init\n",
        "        self.weight_mu = torch.nn.Parameter(torch.empty(out_features, in_features))\n",
        "        self.weight_sigma = torch.nn.Parameter(torch.empty(out_features, in_features))\n",
        "        self.register_buffer('weight_epsilon', torch.empty(out_features, in_features))\n",
        "        self.bias_mu = torch.nn.Parameter(torch.empty(out_features))\n",
        "        self.bias_sigma = torch.nn.Parameter(torch.empty(out_features))\n",
        "        self.register_buffer('bias_epsilon', torch.empty(out_features))\n",
        "        self.reset_parameters()\n",
        "        self.sample_noise()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        mu_range = 1.0 / math.sqrt(self.in_features)\n",
        "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.in_features))\n",
        "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
        "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.out_features))\n",
        "\n",
        "    def _scale_noise(self, size):\n",
        "        x = torch.randn(size)\n",
        "        return x.sign().mul_(x.abs().sqrt_())\n",
        "\n",
        "    def sample_noise(self):\n",
        "        epsilon_in = self._scale_noise(self.in_features)\n",
        "        epsilon_out = self._scale_noise(self.out_features)\n",
        "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
        "        self.bias_epsilon.copy_(epsilon_out)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        if self.training:\n",
        "            return F.linear(inp, self.weight_mu + self.weight_sigma * self.weight_epsilon, self.bias_mu + self.bias_sigma * self.bias_epsilon)\n",
        "        else:\n",
        "            return F.linear(inp, self.weight_mu, self.bias_mu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0NRD6XDtRKa",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zODbJxc7xt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_input  = '-= Pantry =- \\\n",
        "You\\'ve just sauntered into a pantry. You try to gain information on your surroundings by using a technique you call \"looking.\"\\\n",
        "You see a shelf. The shelf is wooden. On the shelf you can make out a black pepper and an orange bell pepper. I mean, just wow! Isn\\'t TextWorld just the best?\\\n",
        "There is an open frosted-glass door leading south.\\\n",
        " You are carrying nothing.\\\n",
        "Recipe #1\\\n",
        "---------\\\n",
        "Gather all following ingredients and follow the directions to prepare this tasty meal.\\\n",
        "Ingredients:\\\n",
        "  black pepper\\\n",
        "  red apple\\\n",
        "  water\\\n",
        "Directions:\\\n",
        "  prepare meal\\\n",
        "                    ________  ________  __    __  ________        \\\n",
        "                   |        \\|        \\|  \\  |  \\|        \\       \\\n",
        "                    \\$$$$$$$$| $$$$$$$$| $$  | $$ \\$$$$$$$$       \\\n",
        "                      | $$   | $$__     \\$$\\/  $$   | $$          \\\n",
        "                      | $$   | $$  \\     >$$  $$    | $$          \\\n",
        "                      | $$   | $$$$$    /  $$$$\\    | $$          \\\n",
        "                      | $$   | $$_____ |  $$ \\$$\\   | $$          \\\n",
        "                      | $$   | $$     \\| $$  | $$   | $$          \\\n",
        "                       \\$$    \\$$$$$$$$ \\$$   \\$$    \\$$          \\\n",
        "              __       __   ______   _______   __        _______  \\\n",
        "             |  \\  _  |  \\ /      \\ |       \\ |  \\      |       \\ \\\n",
        "             | $$ / \\ | $$|  $$$$$$\\| $$$$$$$\\| $$      | $$$$$$$\\ \\\n",
        "             | $$/  $\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\\\n",
        "             | $$  $$$\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\\\n",
        "             | $$ $$\\$$\\$$| $$  | $$| $$$$$$$\\| $$      | $$  | $$\\\n",
        "             | $$$$  \\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\\\n",
        "             | $$$    \\$$$ \\$$    $$| $$  | $$| $$     \\| $$    $$\\\n",
        "              \\$$      \\$$  \\$$$$$$  \\$$   \\$$ \\$$$$$$$$ \\$$$$$$$ \\\n",
        "You are hungry! Let\\'s cook a delicious meal. Check the cookbook in the kitchen for the recipe. Once done, enjoy your meal!'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcWupwzq42-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preproc_example(s):\n",
        "  s = s.replace('$', '')\n",
        "  s = s.replace('#', '')\n",
        "  s = s.replace('\\n', ' ')\n",
        "  s = s.replace('  ', ' ')\n",
        "  s = s.replace('_', '')\n",
        "  s = s.replace('|', '')\n",
        "  s = s.replace('\\\\', '')\n",
        "  s = s.replace('/', '')\n",
        "  s = s.replace('-', '')\n",
        "  s = s.replace('=', '')\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0x53_FdBJ91",
        "colab_type": "code",
        "outputId": "171f5f65-5832-4eee-97ec-7910bc953daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "preproc_example(example_input)\n",
        "# example_input.replace('$', '')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Pantry  You\\'ve just sauntered into a pantry. You try to gain information on your surroundings by using a technique you call \"looking.\"You see a shelf. The shelf is wooden. On the shelf you can make out a black pepper and an orange bell pepper. I mean, just wow! Isn\\'t TextWorld just the best?There is an open frostedglass door leading south. You are carrying nothing.Recipe 1Gather all following ingredients and follow the directions to prepare this tasty meal.Ingredients: black pepper red apple waterDirections: prepare meal                                                                                                              >                                                                                                                                                                                                                                                                                                      You are hungry! Let\\'s cook a delicious meal. Check the cookbook in the kitchen for the recipe. Once done, enjoy your meal!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPMpGmA7_omf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convert_examples_to_features(sequences, tokenizer):\n",
        "  \"\"\"Loads a data file into a list of `InputFeature`s.\"\"\"\n",
        "  batch_tokens = []\n",
        "  batch_input_ids = []\n",
        "  batch_input_masks = []\n",
        "  for example in sequences:\n",
        "      _example = preproc_example(example)      \n",
        "#       print(_example)\n",
        "      tokens = tokenizer.tokenize(_example)\n",
        "      if len(tokens) > 512:\n",
        "        tokens = tokens[:512]\n",
        "      batch_tokens.append(tokens)\n",
        "      del _example\n",
        "      del tokens\n",
        "\n",
        "  max_length = max([len(x) for x in batch_tokens])\n",
        "#   print('bert_max_seqence', max_length)\n",
        "  for tokens in batch_tokens:\n",
        "      input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "      # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "      # tokens are attended to.\n",
        "      input_mask = [1] * len(input_ids)\n",
        "\n",
        "      # Zero-pad up to the sequence length.\n",
        "      while len(input_ids) < max_length:\n",
        "          input_ids.append(0)\n",
        "          input_mask.append(0)\n",
        "           \n",
        "      batch_input_ids.append(input_ids)\n",
        "      batch_input_masks.append(input_mask)\n",
        "      del input_ids\n",
        "      del input_mask\n",
        "  \n",
        "  return batch_tokens, batch_input_ids, batch_input_masks\n",
        "\n",
        "def freeze_layer(layer):\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd4txzFctSFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlogger = logging.getLogger(__name__)\n",
        "\n",
        "class Bert_DQN(torch.nn.Module):\n",
        "    model_name = 'bert_dqn'\n",
        "\n",
        "    def __init__(self, model_config, word_vocab, generate_length=5, enable_cuda=False):\n",
        "        super(Bert_DQN, self).__init__()\n",
        "        self.model_config = model_config\n",
        "        self.enable_cuda = enable_cuda\n",
        "        self.word_vocab_size = len(word_vocab)\n",
        "        self.id2word = word_vocab\n",
        "        self.generate_length = generate_length\n",
        "        self.read_config()\n",
        "#         print(enable_cuda)\n",
        "        self.device = torch.device(\"cuda\" if enable_cuda else \"cpu\")\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_model, do_lower_case=True)\n",
        "        self._def_layers()\n",
        "        self.init_weights()\n",
        "        self.print_parameters()\n",
        "\n",
        "    def print_parameters(self):\n",
        "      amount = 0\n",
        "      for p in self.parameters():\n",
        "          amount += np.prod(p.size())\n",
        "      print(\"total number of parameters: %s\" % (amount))\n",
        "      parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "      amount = 0\n",
        "      for p in parameters:\n",
        "          amount += np.prod(p.size())\n",
        "      print(\"number of trainable parameters: %s\" % (amount))\n",
        "\n",
        "    def read_config(self):\n",
        "        # model config\n",
        "#         self.embedding_size = self.model_config['embedding_size']\n",
        "#         self.encoder_rnn_hidden_size = self.model_config['encoder_rnn_hidden_size']\n",
        "#         self.action_scorer_hidden_dim = self.model_config['action_scorer_hidden_dim']\n",
        "#         self.dropout_between_rnn_layers = self.model_config['dropout_between_rnn_layers']\n",
        "        self.bert_model = self.model_config['bert_model']\n",
        "        self.layer_index = self.model_config['layer_index']\n",
        "        self.action_scorer_hidden_dim = self.model_config['action_scorer_hidden_dim']\n",
        "        self.train_bert = self.model_config['train_bert']\n",
        "        \n",
        "    def _def_layers(self):\n",
        "\n",
        "        # word embeddings\n",
        "#         self.word_embedding = Embedding(embedding_size=self.embedding_size,\n",
        "#                                         vocab_size=self.word_vocab_size,\n",
        "#                                         enable_cuda=self.enable_cuda)\n",
        "\n",
        "#         # lstm encoder\n",
        "#         self.encoder = FastUniLSTM(ninp=self.embedding_size,\n",
        "#                                    nhids=self.encoder_rnn_hidden_size,\n",
        "#                                    dropout_between_rnn_layers=self.dropout_\n",
        "        self.encoder = BertModel.from_pretrained(self.bert_model).to(self.device)\n",
        "        if not self.train_bert:\n",
        "          freeze_layer(self.encoder)\n",
        "        # only for base models\n",
        "        # for large models is \n",
        "        bert_embeddings = 768\n",
        "\n",
        "        self.action_scorer_shared = torch.nn.Linear(bert_embeddings, self.action_scorer_hidden_dim)\n",
        "        action_scorers = []\n",
        "        for _ in range(self.generate_length):\n",
        "            action_scorers.append( NoisyLinear(self.action_scorer_hidden_dim, \n",
        "                            self.word_vocab_size, \n",
        "                            std_init=self.model_config['noisy_std']))\n",
        "        self.action_scorers = torch.nn.ModuleList(action_scorers)\n",
        "        self.fake_recurrent_mask = None\n",
        "\n",
        "    def init_weights(self):\n",
        "        torch.nn.init.xavier_uniform_(self.action_scorer_shared.weight.data)\n",
        "        for i in range(len(self.action_scorers)):\n",
        "            self.action_scorers[i].sample_noise()\n",
        "        self.action_scorer_shared.bias.data.fill_(0)\n",
        "\n",
        "    def representation_generator(self, ids, mask):\n",
        "        ids = ids.to(self.device)\n",
        "        mask = mask.to(self.device)\n",
        "        \n",
        "        layers, _ = self.encoder(ids, attention_mask=mask)\n",
        "#         encoding_sequence = layers[self.layer_index]\n",
        "#         print('layer length: ', len(layers))\n",
        "        encoding_sequence = layers[-2].type(torch.FloatTensor)\n",
        "        encoding_sequence = encoding_sequence.to(self.device)\n",
        "    \n",
        "#         print('encoding_sequence: ', type(encoding_sequence))\n",
        "#         print('encoding_sequence: ', encoding_sequence)\n",
        "        mask = mask.type(torch.FloatTensor).to(self.device)\n",
        "#         print('mask: ', type(mask))\n",
        "#         print('mask: ', mask)\n",
        "        \n",
        "#         embeddings, mask = self.word_embedding.forward(_input_words)  # batch x time x emb\n",
        "#         encoding_sequence, _, _ = self.encoder.forward(embeddings, mask)  # batch x time x h\n",
        "        res_mean = masked_mean(encoding_sequence, mask)  # batch x h\n",
        "        del layers\n",
        "        del encoding_sequence\n",
        "        del mask\n",
        "        \n",
        "        return res_mean\n",
        "\n",
        "\n",
        "    def action_scorer(self, state_representation):\n",
        "        hidden = self.action_scorer_shared.forward(state_representation)  # batch x hid\n",
        "        hidden = F.relu(hidden)  # batch x hid\n",
        "        action_ranks = []\n",
        "        for i in range(len(self.action_scorers)):\n",
        "            action_ranks.append(self.action_scorers[i].forward(hidden))  # batch x n_vocab\n",
        "        del hidden\n",
        "        return action_ranks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcGhySILtg5T",
        "colab_type": "text"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jF57tZRBzMa8",
        "colab": {}
      },
      "source": [
        "# a snapshot of state to be stored in replay memory\n",
        "Transition = namedtuple('Transition', ('bert_ids', 'bert_masks',\n",
        "                                       'word_indices',\n",
        "                                       'reward', 'mask', 'done',\n",
        "                                       'next_bert_ids', 'next_bert_masks',\n",
        "                                       'next_word_masks'))\n",
        "\n",
        "\n",
        "class HistoryScoreCache(object):\n",
        "\n",
        "    def __init__(self, capacity=1):\n",
        "        self.capacity = capacity\n",
        "        self.reset()\n",
        "\n",
        "    def push(self, stuff):\n",
        "        \"\"\"stuff is float.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(stuff)\n",
        "        else:\n",
        "            self.memory = self.memory[1:] + [stuff]\n",
        "\n",
        "    def get_avg(self):\n",
        "        return np.mean(np.array(self.memory))\n",
        "\n",
        "    def reset(self):\n",
        "        self.memory = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "\n",
        "class PrioritizedReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity=100000, priority_fraction=0.0):\n",
        "        # prioritized replay memory\n",
        "        self.priority_fraction = priority_fraction\n",
        "        self.alpha_capacity = int(capacity * priority_fraction)\n",
        "        self.beta_capacity = capacity - self.alpha_capacity\n",
        "        self.alpha_memory, self.beta_memory = [], []\n",
        "        self.alpha_position, self.beta_position = 0, 0\n",
        "\n",
        "    def push(self, is_prior=False, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if self.priority_fraction == 0.0:\n",
        "            is_prior = False\n",
        "        if is_prior:\n",
        "            if len(self.alpha_memory) < self.alpha_capacity:\n",
        "                self.alpha_memory.append(None)\n",
        "            self.alpha_memory[self.alpha_position] = Transition(*args)\n",
        "            self.alpha_position = (self.alpha_position + 1) % self.alpha_capacity\n",
        "        else:\n",
        "            if len(self.beta_memory) < self.beta_capacity:\n",
        "                self.beta_memory.append(None)\n",
        "            self.beta_memory[self.beta_position] = Transition(*args)\n",
        "            self.beta_position = (self.beta_position + 1) % self.beta_capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        if self.priority_fraction == 0.0:\n",
        "            from_beta = min(batch_size, len(self.beta_memory))\n",
        "            res = random.sample(self.beta_memory, from_beta)\n",
        "        else:\n",
        "            from_alpha = min(int(self.priority_fraction * batch_size), len(self.alpha_memory))\n",
        "            from_beta = min(batch_size - int(self.priority_fraction * batch_size), len(self.beta_memory))\n",
        "            res = random.sample(self.alpha_memory, from_alpha) + random.sample(self.beta_memory, from_beta)\n",
        "        random.shuffle(res)\n",
        "        return res\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.alpha_memory) + len(self.beta_memory)\n",
        "\n",
        "\n",
        "class CustomAgent:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            word_vocab: List of words supported.\n",
        "        \"\"\"\n",
        "        self.mode = \"train\"\n",
        "        with open(\"./vocab.txt\") as f:\n",
        "            self.word_vocab = f.read().split(\"\\n\")\n",
        "        with open(\"config.yaml\") as reader:\n",
        "            self.config = yaml.safe_load(reader)\n",
        "        self.word2id = {}\n",
        "        for i, w in enumerate(self.word_vocab):\n",
        "            self.word2id[w] = i\n",
        "        self.EOS_id = self.word2id[\"</S>\"]\n",
        "\n",
        "        self.batch_size = self.config['training']['batch_size']\n",
        "        self.max_nb_steps_per_episode = self.config['training']['max_nb_steps_per_episode']\n",
        "        self.nb_epochs = self.config['training']['nb_epochs']\n",
        "\n",
        "        # Set the random seed manually for reproducibility.\n",
        "        np.random.seed(self.config['general']['random_seed'])\n",
        "        torch.manual_seed(self.config['general']['random_seed'])\n",
        "        if torch.cuda.is_available():\n",
        "            if not self.config['general']['use_cuda']:\n",
        "                print(\"WARNING: CUDA device detected but 'use_cuda: false' found in config.yaml\")\n",
        "                self.use_cuda = False\n",
        "            else:\n",
        "                torch.backends.cudnn.deterministic = True\n",
        "                torch.cuda.manual_seed(self.config['general']['random_seed'])\n",
        "                self.use_cuda = True\n",
        "        else:\n",
        "            self.use_cuda = False\n",
        "\n",
        "        self.model = Bert_DQN(model_config=self.config[\"model\"],\n",
        "                              word_vocab=self.word_vocab,\n",
        "                              enable_cuda=self.use_cuda)\n",
        "\n",
        "        self.experiment_tag = self.config['checkpoint']['experiment_tag']\n",
        "        self.model_checkpoint_path = self.config['checkpoint']['model_checkpoint_path']\n",
        "        self.save_frequency = self.config['checkpoint']['save_frequency']\n",
        "\n",
        "        if self.config['checkpoint']['load_pretrained']:\n",
        "            self.load_pretrained_model(self.model_checkpoint_path + '/' + self.config['checkpoint']['pretrained_experiment_tag'] + '.pt')\n",
        "        if self.use_cuda:\n",
        "            self.model.cuda()\n",
        "\n",
        "        self.replay_batch_size = self.config['general']['replay_batch_size']\n",
        "        self.replay_memory = PrioritizedReplayMemory(self.config['general']['replay_memory_capacity'],\n",
        "                                                     priority_fraction=self.config['general']['replay_memory_priority_fraction'])\n",
        "\n",
        "        # optimizer\n",
        "        parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
        "        self.optimizer = torch.optim.Adam(parameters, lr=self.config['training']['optimizer']['learning_rate'])\n",
        "\n",
        "        # epsilon greedy\n",
        "        self.epsilon_anneal_episodes = self.config['general']['epsilon_anneal_episodes']\n",
        "        self.epsilon_anneal_from = self.config['general']['epsilon_anneal_from']\n",
        "        self.epsilon_anneal_to = self.config['general']['epsilon_anneal_to']\n",
        "        self.epsilon = self.epsilon_anneal_from\n",
        "        self.update_per_k_game_steps = self.config['general']['update_per_k_game_steps']\n",
        "        self.clip_grad_norm = self.config['training']['optimizer']['clip_grad_norm']\n",
        "\n",
        "        self.nlp = spacy.load('en', disable=['ner', 'parser', 'tagger'])\n",
        "        self.preposition_map = {\"take\": \"from\",\n",
        "                                \"chop\": \"with\",\n",
        "                                \"slice\": \"with\",\n",
        "                                \"dice\": \"with\",\n",
        "                                \"cook\": \"with\",\n",
        "                                \"insert\": \"into\",\n",
        "                                \"put\": \"on\"}\n",
        "        self.single_word_verbs = set([\"inventory\", \"look\"])\n",
        "        self.discount_gamma = self.config['general']['discount_gamma']\n",
        "        self.current_episode = 0\n",
        "        self.current_step = 0\n",
        "        self._epsiode_has_started = False\n",
        "        self.history_avg_scores = HistoryScoreCache(capacity=1000)\n",
        "        self.best_avg_score_so_far = 0.0\n",
        "        self.loss = []\n",
        "        self.state = ''\n",
        "\n",
        "    def train(self, imitate=False):\n",
        "        \"\"\"\n",
        "        Tell the agent that it's training phase.\n",
        "        \"\"\"\n",
        "        self.mode = \"train\"\n",
        "        self.imitate = imitate\n",
        "        self.wt_index = 0\n",
        "#         print(self.wt_index)\n",
        "        self.model.train()\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"\n",
        "        Tell the agent that it's evaluation phase.\n",
        "        \"\"\"\n",
        "        self.mode = \"eval\"\n",
        "        self.model.eval()\n",
        "\n",
        "    def _start_episode(self, obs: List[str], infos: Dict[str, List[Any]]) -> None:\n",
        "        \"\"\"\n",
        "        Prepare the agent for the upcoming episode.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Initial feedback for each game.\n",
        "            infos: Additional information for each game.\n",
        "        \"\"\"\n",
        "        self.init(obs, infos)\n",
        "        self._epsiode_has_started = True\n",
        "\n",
        "    def _end_episode(self, obs: List[str], scores: List[int], infos: Dict[str, List[Any]]) -> None:\n",
        "        \"\"\"\n",
        "        Tell the agent the episode has terminated.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            score: The score obtained so far for each game.\n",
        "            infos: Additional information for each game.\n",
        "        \"\"\"\n",
        "        self.finish()\n",
        "        self._epsiode_has_started = False\n",
        "\n",
        "    def load_pretrained_model(self, load_from):\n",
        "        \"\"\"\n",
        "        Load pretrained checkpoint from file.\n",
        "\n",
        "        Arguments:\n",
        "            load_from: File name of the pretrained model checkpoint.\n",
        "        \"\"\"\n",
        "        print(\"loading model from %s\\n\" % (load_from))\n",
        "        try:\n",
        "            if self.use_cuda:\n",
        "                state_dict = torch.load(load_from)\n",
        "            else:\n",
        "                state_dict = torch.load(load_from, map_location='cpu')\n",
        "            self.model.load_state_dict(state_dict)\n",
        "        except:\n",
        "            print(\"Failed to load checkpoint...\")\n",
        "\n",
        "    def select_additional_infos(self) -> EnvInfos:\n",
        "        \"\"\"\n",
        "        Returns what additional information should be made available at each game step.\n",
        "\n",
        "        Requested information will be included within the `infos` dictionary\n",
        "        passed to `CustomAgent.act()`. To request specific information, create a\n",
        "        :py:class:`textworld.EnvInfos <textworld.envs.wrappers.filter.EnvInfos>`\n",
        "        and set the appropriate attributes to `True`. The possible choices are:\n",
        "\n",
        "        * `description`: text description of the current room, i.e. output of the `look` command;\n",
        "        * `inventory`: text listing of the player's inventory, i.e. output of the `inventory` command;\n",
        "        * `max_score`: maximum reachable score of the game;\n",
        "        * `objective`: objective of the game described in text;\n",
        "        * `entities`: names of all entities in the game;\n",
        "        * `verbs`: verbs understood by the the game;\n",
        "        * `command_templates`: templates for commands understood by the the game;\n",
        "        * `admissible_commands`: all commands relevant to the current state;\n",
        "\n",
        "        In addition to the standard information, game specific information\n",
        "        can be requested by appending corresponding strings to the `extras`\n",
        "        attribute. For this competition, the possible extras are:\n",
        "\n",
        "        * `'recipe'`: description of the cookbook;\n",
        "        * `'walkthrough'`: one possible solution to the game (not guaranteed to be optimal);\n",
        "\n",
        "        Example:\n",
        "            Here is an example of how to request information and retrieve it.\n",
        "\n",
        "            >>> from textworld import EnvInfos\n",
        "            >>> request_infos = EnvInfos(description=True, inventory=True, extras=[\"recipe\"])\n",
        "            ...\n",
        "            >>> env = gym.make(env_id)\n",
        "            >>> ob, infos = env.reset()\n",
        "            >>> print(infos[\"description\"])\n",
        "            >>> print(infos[\"inventory\"])\n",
        "            >>> print(infos[\"extra.recipe\"])\n",
        "\n",
        "        Notes:\n",
        "            The following information *won't* be available at test time:\n",
        "\n",
        "            * 'walkthrough'\n",
        "        \"\"\"\n",
        "        request_infos = EnvInfos()\n",
        "        request_infos.description = True\n",
        "        request_infos.inventory = True\n",
        "        request_infos.entities = True\n",
        "        request_infos.verbs = True\n",
        "        request_infos.max_score = True\n",
        "        request_infos.has_won = True\n",
        "        request_infos.has_lost = True\n",
        "        request_infos.extras = [\"recipe\", \"walkthrough\"]\n",
        "        return request_infos\n",
        "\n",
        "    def init(self, obs: List[str], infos: Dict[str, List[Any]]):\n",
        "        \"\"\"\n",
        "        Prepare the agent for the upcoming games.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            infos: Additional information for each game.\n",
        "        \"\"\"\n",
        "        # reset agent, get vocabulary masks for verbs / adjectives / nouns\n",
        "        self.scores = []\n",
        "        self.dones = []\n",
        "        self.prev_actions = [\"\" for _ in range(len(obs))]\n",
        "        # get word masks\n",
        "        batch_size = len(infos[\"verbs\"])\n",
        "        verbs_word_list = infos[\"verbs\"]\n",
        "        noun_word_list, adj_word_list = [], []\n",
        "        for entities in infos[\"entities\"]:\n",
        "            tmp_nouns, tmp_adjs = [], []\n",
        "            for name in entities:\n",
        "                split = name.split()\n",
        "                tmp_nouns.append(split[-1])\n",
        "                if len(split) > 1:\n",
        "                    tmp_adjs += split[:-1]\n",
        "            noun_word_list.append(list(set(tmp_nouns)))\n",
        "            adj_word_list.append(list(set(tmp_adjs)))\n",
        "\n",
        "        verb_mask = np.zeros((batch_size, len(self.word_vocab)), dtype=\"float32\")\n",
        "        noun_mask = np.zeros((batch_size, len(self.word_vocab)), dtype=\"float32\")\n",
        "        adj_mask = np.zeros((batch_size, len(self.word_vocab)), dtype=\"float32\")\n",
        "        for i in range(batch_size):\n",
        "            for w in verbs_word_list[i]:\n",
        "                if w in self.word2id:\n",
        "                    verb_mask[i][self.word2id[w]] = 1.0\n",
        "            for w in noun_word_list[i]:\n",
        "                if w in self.word2id:\n",
        "                    noun_mask[i][self.word2id[w]] = 1.0\n",
        "            for w in adj_word_list[i]:\n",
        "                if w in self.word2id:\n",
        "                    adj_mask[i][self.word2id[w]] = 1.0\n",
        "        second_noun_mask = copy.copy(noun_mask)\n",
        "        second_adj_mask = copy.copy(adj_mask)\n",
        "        second_noun_mask[:, self.EOS_id] = 1.0\n",
        "        adj_mask[:, self.EOS_id] = 1.0\n",
        "        second_adj_mask[:, self.EOS_id] = 1.0\n",
        "        self.word_masks_np = [verb_mask, adj_mask, noun_mask, second_adj_mask, second_noun_mask]\n",
        "\n",
        "        self.cache_chosen_indices = None\n",
        "        self.current_step = 0\n",
        "\n",
        "    def get_game_step_info(self, obs: List[str], infos: Dict[str, List[Any]]):\n",
        "        \"\"\"\n",
        "        Get all the available information, and concat them together to be tensor for\n",
        "        a neural model. we use post padding here, all information are tokenized here.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            infos: Additional information for each game.\n",
        "        \"\"\"\n",
        "#         print('inventory: ', len(infos['inventory']))\n",
        "#         print('obs: ', len(obs))\n",
        "#         print('recipees: ', len(infos['extra.recipe']))\n",
        "#         print('descriptions: ', len(infos['description']))\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "#         inventory_token_list = [preproc(item, tokenizer=self.nlp) for item in infos[\"inventory\"]]\n",
        "#         inventory_id_list = [_words_to_ids(tokens, self.word2id) for tokens in inventory_token_list]\n",
        "\n",
        "#         feedback_token_list = [preproc(item, str_type='feedback', tokenizer=self.nlp) for item in obs]\n",
        "#         feedback_id_list = [_words_to_ids(tokens, self.word2id) for tokens in feedback_token_list]\n",
        "\n",
        "#         quest_token_list = [preproc(item, tokenizer=self.nlp) for item in infos[\"extra.recipe\"]]\n",
        "#         quest_id_list = [_words_to_ids(tokens, self.word2id) for tokens in quest_token_list]\n",
        "\n",
        "#         prev_action_token_list = [preproc(item, tokenizer=self.nlp) for item in self.prev_actions]\n",
        "#         prev_action_id_list = [_words_to_ids(tokens, self.word2id) for tokens in prev_action_token_list]\n",
        "\n",
        "#         description_token_list = [preproc(item, tokenizer=self.nlp) for item in infos[\"description\"]]\n",
        "#         for i, d in enumerate(description_token_list):\n",
        "#             if len(d) == 0:\n",
        "#                 description_token_list[i] = [\"end\"]  # if empty description, insert word \"end\"\n",
        "#         description_id_list = [_words_to_ids(tokens, self.word2id) for tokens in description_token_list]\n",
        "#         description_id_list = [_d + _i + _q + _f + _pa for (_d, _i, _q, _f, _pa) in zip(description_id_list, inventory_id_list, quest_id_list, feedback_id_list, prev_action_id_list)]\n",
        "\n",
        "#         input_description = pad_sequences(description_id_list, maxlen=max_len(description_id_list)).astype('int32')\n",
        "#         input_description = to_pt(input_description, self.use_cuda)\n",
        "#-----------------------------------------------------------------------------------------------    \n",
        "        sep = ' [SEP] '\n",
        "        description_text_list = [_d + sep + _i + sep + _q + sep + _f + sep + _pa for (_d, _i, _q, _f, _pa) \n",
        "                                  in zip(infos['description'], infos['inventory'], infos['extra.recipe'], obs, self.prev_actions)]\n",
        "\n",
        "        _, bert_ids, bert_mask  = convert_examples_to_features(description_text_list, self.model.tokenizer)\n",
        "#         del inventory_token_list\n",
        "#         del inventory_id_list\n",
        "#         del feedback_token_list\n",
        "#         del feedback_id_list\n",
        "#         del quest_token_list\n",
        "#         del quest_id_list\n",
        "#         del prev_action_token_list\n",
        "#         del prev_action_id_list\n",
        "#         del description_token_list\n",
        "#         del description_id_list\n",
        "        del description_text_list\n",
        "        \n",
        "        return bert_ids, bert_mask\n",
        "\n",
        "    def word_ids_to_commands(self, verb, adj, noun, adj_2, noun_2):\n",
        "        \"\"\"\n",
        "        Turn the 5 indices into actual command strings.\n",
        "\n",
        "        Arguments:\n",
        "            verb: Index of the guessing verb in vocabulary\n",
        "            adj: Index of the guessing adjective in vocabulary\n",
        "            noun: Index of the guessing noun in vocabulary\n",
        "            adj_2: Index of the second guessing adjective in vocabulary\n",
        "            noun_2: Index of the second guessing noun in vocabulary\n",
        "        \"\"\"\n",
        "        # turns 5 indices into actual command strings\n",
        "        if self.word_vocab[verb] in self.single_word_verbs:\n",
        "            return self.word_vocab[verb]\n",
        "        if adj == self.EOS_id:\n",
        "            res = self.word_vocab[verb] + \" \" + self.word_vocab[noun]\n",
        "        else:\n",
        "            res = self.word_vocab[verb] + \" \" + self.word_vocab[adj] + \" \" + self.word_vocab[noun]\n",
        "        if self.word_vocab[verb] not in self.preposition_map:\n",
        "            return res\n",
        "        if noun_2 == self.EOS_id:\n",
        "            return res\n",
        "        prep = self.preposition_map[self.word_vocab[verb]]\n",
        "        if adj_2 == self.EOS_id:\n",
        "            res = res + \" \" + prep + \" \" + self.word_vocab[noun_2]\n",
        "        else:\n",
        "            res =  res + \" \" + prep + \" \" + self.word_vocab[adj_2] + \" \" + self.word_vocab[noun_2]\n",
        "        return res\n",
        "\n",
        "    def get_wordid_from_vocab(self, word):\n",
        "      if word in self.word2id.keys():\n",
        "        return self.word2id[word]\n",
        "      else:\n",
        "        return self.EOS_id\n",
        "    \n",
        "    def command_to_word_ids(self, cmd, batch_size):\n",
        "      verb_id=self.EOS_id\n",
        "      first_adj=self.EOS_id\n",
        "      first_noun=self.EOS_id\n",
        "      second_adj=self.EOS_id\n",
        "      second_noun=self.EOS_id\n",
        "      \n",
        "#       print('cmd_to_ids')\n",
        "#       print(cmd.split())\n",
        "      ids = _words_to_ids(cmd.split(), self.word2id)\n",
        "#       print(ids)\n",
        "      for ind, i in enumerate(ids):\n",
        "        if self.word_masks_np[0][0][i]==1.0:\n",
        "          verb = ind\n",
        "          verb_id = i\n",
        "      nouns=[]\n",
        "      for ind, i in enumerate(ids):\n",
        "        if self.word_masks_np[2][0][i]==1.0:\n",
        "          nouns.append((ind,i))\n",
        "      if len(nouns) > 0:\n",
        "        if nouns[0][0] != verb - 1:\n",
        "          adj_ids = ids[verb + 1: nouns[0][0]]\n",
        "          adj=''\n",
        "          adj= ' '.join([self.word_vocab[x] for x in adj_ids]) \n",
        "#           print(adj)\n",
        "          first_adj=self.get_wordid_from_vocab(adj)\n",
        "#         print(nouns)\n",
        "        first_noun=nouns[0][1]\n",
        "      \n",
        "      if len(nouns) > 1:\n",
        "        if nouns[1][0] != nouns[0][0] - 1:\n",
        "          adj_ids = ids[nouns[0][0]: nouns[1][0]]\n",
        "          adj= ' '.join([self.word_vocab[x] for x in adj_ids]) \n",
        "          second_adj=self.get_wordid_from_vocab(adj)\n",
        "        second_noun=nouns[1][1]\n",
        "        \n",
        "       \n",
        "      list_ids = [verb_id, first_adj, first_noun, second_adj, second_noun]\n",
        "      return [to_pt(np.array([[x]]*batch_size), self.use_cuda) for x in list_ids]  \n",
        "      \n",
        "    def get_chosen_strings(self, chosen_indices):\n",
        "        \"\"\"\n",
        "        Turns list of word indices into actual command strings.\n",
        "\n",
        "        Arguments:\n",
        "            chosen_indices: Word indices chosen by model.\n",
        "        \"\"\"\n",
        "        chosen_indices_np = [to_np(item)[:, 0] for item in chosen_indices]\n",
        "        res_str = []\n",
        "        batch_size = chosen_indices_np[0].shape[0]\n",
        "        for i in range(batch_size):\n",
        "          verb, adj, noun, adj_2, noun_2 = chosen_indices_np[0][i],\\\n",
        "                                           chosen_indices_np[1][i],\\\n",
        "                                           chosen_indices_np[2][i],\\\n",
        "                                           chosen_indices_np[3][i],\\\n",
        "                                           chosen_indices_np[4][i]\n",
        "          res_str.append(self.word_ids_to_commands(verb, adj, noun, adj_2, noun_2))\n",
        "          del verb\n",
        "          del adj\n",
        "          del noun\n",
        "          del adj_2\n",
        "          del noun_2\n",
        "            \n",
        "        del chosen_indices_np\n",
        "        return res_str\n",
        "\n",
        "    def choose_random_command(self, word_ranks, word_masks_np):\n",
        "        \"\"\"\n",
        "        Generate a command randomly, for epsilon greedy.\n",
        "\n",
        "        Arguments:\n",
        "            word_ranks: Q values for each word by model.action_scorer.\n",
        "            word_masks_np: Vocabulary masks for words depending on their type (verb, adj, noun).\n",
        "        \"\"\"\n",
        "        batch_size = word_ranks[0].size(0)\n",
        "        word_ranks_np = [to_np(item) for item in word_ranks]  # list of batch x n_vocab\n",
        "        word_ranks_np = [r * m for r, m in zip(word_ranks_np, word_masks_np)]  # list of batch x n_vocab\n",
        "        word_indices = []\n",
        "        for i in range(len(word_ranks_np)):\n",
        "          indices = []\n",
        "          for j in range(batch_size):\n",
        "              msk = word_masks_np[i][j]  # vocab\n",
        "              indices.append(np.random.choice(len(msk), p=msk / np.sum(msk, -1)))\n",
        "              del msk\n",
        "          word_indices.append(np.array(indices))\n",
        "          del indices\n",
        "        # word_indices: list of batch\n",
        "        word_qvalues = [[] for _ in word_masks_np]\n",
        "        for i in range(batch_size):\n",
        "            for j in range(len(word_qvalues)):\n",
        "                word_qvalues[j].append(word_ranks[j][i][word_indices[j][i]])\n",
        "        word_qvalues = [torch.stack(item) for item in word_qvalues]\n",
        "        word_indices = [to_pt(item, self.use_cuda) for item in word_indices]\n",
        "        word_indices = [item.unsqueeze(-1) for item in word_indices]  # list of batch x 1\n",
        "        \n",
        "        del word_ranks_np\n",
        "        \n",
        "        return word_qvalues, word_indices\n",
        "\n",
        "#     def choose_random_command(self, word_ranks, word_masks_np):\n",
        "#         batch_size = word_ranks[0].size(0)\n",
        "#         word_ranks_np = [to_np(item) for item in word_ranks]  # list of batch x n_vocab\n",
        "#         word_ranks_np = [r - np.min(r) for r in word_ranks_np] # minus the min value, so that all values are non-negative\n",
        "#         kinda_epsilon = 0.1\n",
        "#         random_ranks = np.random.normal(0, kinda_epsilon, word_ranks_np[0].shape) \n",
        "#         word_ranks_np = [r + random_ranks for r in word_ranks_np] # add noise      \n",
        "#         word_ranks_np = [r * m for r, m in zip(word_ranks_np, word_masks_np)]  # list of batch x n_vocab\n",
        "#         word_indices = [np.argmax(item, -1) for item in word_ranks_np]  # list of batch\n",
        "#         word_qvalues = [[] for _ in word_masks_np]\n",
        "\n",
        "#         for i in range(batch_size):\n",
        "#             for j in range(len(word_qvalues)):\n",
        "#                 word_qvalues[j].append(word_ranks[j][i][word_indices[j][i]])\n",
        "\n",
        "#         word_qvalues = [torch.stack(item) for item in word_qvalues]\n",
        "#         word_indices = [to_pt(item, self.use_cuda) for item in word_indices]\n",
        "#         word_indices = [item.unsqueeze(-1) for item in word_indices]  # list of batch x 1\n",
        "#         return word_qvalues, word_indices\n",
        "\n",
        "    def choose_maxQ_command(self, word_ranks, word_masks_np):\n",
        "        \"\"\"\n",
        "        Generate a command by maximum q values, for epsilon greedy.\n",
        "\n",
        "        Arguments:\n",
        "            word_ranks: Q values for each word by model.action_scorer.\n",
        "            word_masks_np: Vocabulary masks for words depending on their type (verb, adj, noun).\n",
        "        \"\"\"\n",
        "        batch_size = word_ranks[0].size(0)\n",
        "        word_ranks_np = [to_np(item) for item in word_ranks]  # list of batch x n_vocab\n",
        "        word_ranks_np = [r - np.min(r) for r in word_ranks_np] # minus the min value, so that all values are non-negative\n",
        "        word_ranks_np = [r * m for r, m in zip(word_ranks_np, word_masks_np)]  # list of batch x n_vocab\n",
        "        word_indices = [np.argmax(item, -1) for item in word_ranks_np]  # list of batch\n",
        "        word_qvalues = [[] for _ in word_masks_np]\n",
        "        for i in range(batch_size):\n",
        "            for j in range(len(word_qvalues)):\n",
        "                word_qvalues[j].append(word_ranks[j][i][word_indices[j][i]])\n",
        "        word_qvalues = [torch.stack(item) for item in word_qvalues]\n",
        "        word_indices = [to_pt(item, self.use_cuda) for item in word_indices]\n",
        "        word_indices = [item.unsqueeze(-1) for item in word_indices]  # list of batch x 1\n",
        "        \n",
        "        del word_ranks_np\n",
        "        \n",
        "        return word_qvalues, word_indices\n",
        "\n",
        "      \n",
        "#     torch.Size([16, 227])\n",
        "#     torch.Size([16, 227])\n",
        "#     torch.Size([16, 768])\n",
        "#     5\n",
        "#     torch.Size([16, 20200])\n",
        "\n",
        "# 16\n",
        "# 5\n",
        "# torch.Size([1, 20200])\n",
        "    def get_ranks(self, bert_ids, bert_masks):\n",
        "        \"\"\"\n",
        "        Given input description tensor, call model forward, to get Q values of words.\n",
        "\n",
        "        Arguments:\n",
        "            input_description: Input tensors, which include all the information chosen in\n",
        "            select_additional_infos() concatenated together.\n",
        "        \"\"\"\n",
        "#         word_ranks_arr = []\n",
        "#         for x in range(len(bert_ids)):\n",
        "#           bert_ids_single =  torch.tensor([bert_ids[x]], dtype=torch.long)\n",
        "#           bert_masks_single = torch.tensor([bert_masks[x]], dtype=torch.long)\n",
        "#           state_representation_single = self.model.representation_generator(bert_ids_single, bert_masks_single)\n",
        "#           del bert_ids_single\n",
        "#           del bert_masks_single\n",
        "#           word_ranks_arr.append(self.model.action_scorer(state_representation_single))\n",
        "# #           print(len(word_ranks_arr))\n",
        "# #           print(len(word_ranks_arr[0]))\n",
        "# #           print(word_ranks_arr[0][0].shape)\n",
        "#           del state_representation_single\n",
        "#         word_ranks = word_ranks_arr[0]\n",
        "#         for x in range(len(word_ranks_arr) - 1):\n",
        "#           for y in range(len(word_ranks_arr[x + 1])):\n",
        "#             word_ranks[y] = torch.cat((word_ranks[y], word_ranks_arr[x + 1][y]), dim=0)\n",
        "#         del word_ranks_arr\n",
        "          \n",
        "        bert_ids = torch.tensor([x for x in bert_ids], dtype=torch.long)\n",
        "        bert_masks = torch.tensor([x for x in bert_masks], dtype=torch.long)\n",
        "#         print(bert_ids.shape)\n",
        "#         print(bert_masks.shape)\n",
        "        state_representation = self.model.representation_generator(bert_ids, bert_masks)\n",
        "#         print(state_representation.shape)\n",
        "        del bert_ids\n",
        "        del bert_masks\n",
        "        \n",
        "        word_ranks = self.model.action_scorer(state_representation)  # each element in list has batch x n_vocab size\n",
        "#         print(len(word_ranks))\n",
        "#         print(word_ranks[0].shape)\n",
        "        del state_representation\n",
        "        return word_ranks\n",
        "\n",
        "    def act_eval(self, obs: List[str], scores: List[int], dones: List[bool], infos: Dict[str, List[Any]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Acts upon the current list of observations, during evaluation.\n",
        "\n",
        "        One text command must be returned for each observation.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            score: The score obtained so far for each game (at previous step).\n",
        "            done: Whether a game is finished (at previous step).\n",
        "            infos: Additional information for each game.\n",
        "\n",
        "        Returns:\n",
        "            Text commands to be performed (one per observation).\n",
        "\n",
        "        Notes:\n",
        "            Commands returned for games marked as `done` have no effect.\n",
        "            The states for finished games are simply copy over until all\n",
        "            games are done, in which case `CustomAgent.finish()` is called\n",
        "            instead.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.current_step > 0:\n",
        "            # append scores / dones from previous step into memory\n",
        "            self.scores.append(scores)\n",
        "            self.dones.append(dones)\n",
        "\n",
        "        if all(dones):\n",
        "            self._end_episode(obs, scores, infos)\n",
        "            return  # Nothing to return.\n",
        "\n",
        "        bert_ids, bert_masks = self.get_game_step_info(obs, infos)\n",
        "        word_ranks = self.get_ranks(bert_ids, bert_masks)  # list of batch x vocab\n",
        "        \n",
        "        del bert_ids\n",
        "        del bert_masks\n",
        "        \n",
        "        _, word_indices_maxq = self.choose_maxQ_command(word_ranks, self.word_masks_np)\n",
        "\n",
        "        chosen_indices = word_indices_maxq\n",
        "        chosen_indices = [item.detach() for item in chosen_indices]\n",
        "        chosen_strings = self.get_chosen_strings(chosen_indices)\n",
        "        self.prev_actions = chosen_strings\n",
        "        self.current_step += 1\n",
        "        \n",
        "        return chosen_strings\n",
        "\n",
        "    def act(self, obs: List[str], scores: List[int], dones: List[bool], infos: Dict[str, List[Any]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Acts upon the current list of observations.\n",
        "\n",
        "        One text command must be returned for each observation.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            score: The score obtained so far for each game (at previous step).\n",
        "            done: Whether a game is finished (at previous step).\n",
        "            infos: Additional information for each game.\n",
        "\n",
        "        Returns:\n",
        "            Text commands to be performed (one per observation).\n",
        "\n",
        "        Notes:\n",
        "            Commands returned for games marked as `done` have no effect.\n",
        "            The states for finished games are simply copy over until all\n",
        "            games are done, in which case `CustomAgent.finish()` is called\n",
        "            instead.\n",
        "        \"\"\"\n",
        "        if not self._epsiode_has_started:\n",
        "            self._start_episode(obs, infos)\n",
        "\n",
        "        if self.mode == \"eval\":\n",
        "            return self.act_eval(obs, scores, dones, infos)\n",
        "\n",
        "        if self.current_step > 0:\n",
        "            # append scores / dones from previous step into memory\n",
        "            self.scores.append(scores)\n",
        "            self.dones.append(dones)\n",
        "            # compute previous step's rewards and masks\n",
        "            rewards_np, rewards, mask_np, mask = self.compute_reward()\n",
        "\n",
        "        # Sample for noisy nets\n",
        "        for i in range(len(self.model.action_scorers)):\n",
        "            self.model.action_scorers[i].sample_noise()\n",
        "            \n",
        "        bert_ids, bert_masks = self.get_game_step_info(obs, infos)\n",
        "        # generate commands for one game step, epsilon greedy is applied, i.e.,\n",
        "        # there is epsilon of chance to generate random commands\n",
        "        if self.imitate:\n",
        "#           print('imitate')\n",
        "          correct_cmd=infos['extra.walkthrough'][0][self.wt_index]\n",
        "#           print(correct_cmd)\n",
        "          if self.wt_index != len(infos['extra.walkthrough'][0]) - 1:\n",
        "            self.wt_index+=1\n",
        "          chosen_indices = self.command_to_word_ids(correct_cmd, len(bert_ids))\n",
        "        else:\n",
        "          word_ranks = self.get_ranks(bert_ids, bert_masks)  # list of batch x vocab\n",
        "\n",
        "          _, word_indices_maxq = self.choose_maxQ_command(word_ranks, self.word_masks_np)\n",
        "          _, word_indices_random = self.choose_random_command(word_ranks, self.word_masks_np)\n",
        "          # random number for epsilon greedyupdate\n",
        "          rand_num = np.random.uniform(low=0.0, high=1.0, size=(len(bert_ids), 1))\n",
        "          less_than_epsilon = (rand_num < self.epsilon).astype(\"float32\")  # batch\n",
        "          greater_than_epsilon = 1.0 - less_than_epsilon\n",
        "          less_than_epsilon = to_pt(less_than_epsilon, self.use_cuda, type='float')\n",
        "          greater_than_epsilon = to_pt(greater_than_epsilon, self.use_cuda, type='float')\n",
        "          less_than_epsilon, greater_than_epsilon = less_than_epsilon.long(), greater_than_epsilon.long()\n",
        "#           print('Random_step: ',less_than_epsilon.tolist())\n",
        "          chosen_indices = [\n",
        "              less_than_epsilon * idx_random + greater_than_epsilon * idx_maxq\n",
        "              for idx_random, idx_maxq in zip(word_indices_random, word_indices_maxq)\n",
        "          ]\n",
        "          chosen_indices = [item.detach() for item in chosen_indices]\n",
        "        \n",
        "        chosen_strings = self.get_chosen_strings(chosen_indices)\n",
        "        self.prev_actions = chosen_strings\n",
        "        \n",
        "\n",
        "        # push info from previous game step into replay memory\n",
        "        if self.current_step > 0:\n",
        "            for b in range(len(obs)):\n",
        "                if mask_np[b] == 0:\n",
        "                    continue\n",
        "                is_prior = rewards_np[b] > 0.0\n",
        "                self.replay_memory.push(is_prior,*(self.cache_bert_ids[b],\n",
        "                                        self.cache_bert_masks[b],\n",
        "                                        [item[b] for item in self.cache_chosen_indices], \n",
        "                                        rewards[b], \n",
        "                                        mask[b], \n",
        "                                        dones[b],\n",
        "                                        bert_ids[b],\n",
        "                                        bert_masks[b],\n",
        "                                        [item[b] for item in self.word_masks_np]))\n",
        "\n",
        "        # cache new info in current game step into caches\n",
        "        self.cache_chosen_indices = chosen_indices\n",
        "        self.cache_bert_ids = bert_ids\n",
        "        self.cache_bert_masks = bert_masks\n",
        "\n",
        "        # update neural model by replaying snapshots in replay memory\n",
        "        #fix update\n",
        "        if self.current_step > 0 and self.current_step % self.update_per_k_game_steps == 0:\n",
        "          loss = self.update()\n",
        "          if loss is not None:\n",
        "              # Backpropagate\n",
        "              self.loss.append(to_np(loss).mean())\n",
        "              self.optimizer.zero_grad()\n",
        "              loss.backward(retain_graph=True)\n",
        "              # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "              torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_grad_norm)\n",
        "              self.optimizer.step()  # apply gradients\n",
        "          \n",
        "           \n",
        "\n",
        "        self.current_step += 1\n",
        "\n",
        "        if all(dones):\n",
        "            self._end_episode(obs, scores, infos)\n",
        "            return  # Nothing to return.\n",
        "        return chosen_strings\n",
        "\n",
        "    def compute_reward(self):\n",
        "        \"\"\"\n",
        "        Compute rewards by agent. Note this is different from what the training/evaluation\n",
        "        scripts do. Agent keeps track of scores and other game information for training purpose.\n",
        "\n",
        "        \"\"\"\n",
        "        # mask = 1 if game is not finished or just finished at current step\n",
        "        if len(self.dones) == 1:\n",
        "            # it's not possible to finish a game at 0th step\n",
        "            mask = [1.0 for _ in self.dones[-1]]\n",
        "        else:\n",
        "            assert len(self.dones) > 1\n",
        "            mask = [1.0 if not self.dones[-2][i] else 0.0 for i in range(len(self.dones[-1]))]\n",
        "        mask = np.array(mask, dtype='float32')\n",
        "        mask_pt = to_pt(mask, self.use_cuda, type='float')\n",
        "        # rewards returned by game engine are always accumulated value the\n",
        "        # agent have recieved. so the reward it gets in the current game step\n",
        "        # is the new value minus values at previous step.\n",
        "        rewards = np.array(self.scores[-1], dtype='float32')  # batch\n",
        "        if len(self.scores) > 1:\n",
        "            prev_rewards = np.array(self.scores[-2], dtype='float32')\n",
        "            rewards = rewards - prev_rewards\n",
        "        rewards_pt = to_pt(rewards, self.use_cuda, type='float')\n",
        "\n",
        "        return rewards, rewards_pt, mask, mask_pt\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Update neural model in agent. In this example we follow algorithm\n",
        "        of updating model in dqn with replay memory.\n",
        "\n",
        "        \"\"\"\n",
        "        if len(self.replay_memory) < self.replay_batch_size:\n",
        "            return None\n",
        "        transitions = self.replay_memory.sample(self.replay_batch_size)\n",
        "        batch = Transition(*zip(*transitions))\n",
        "        \n",
        "        del transitions\n",
        "\n",
        "        #pyt bert_ids and bert_masks\n",
        "#         observation_id_list = pad_sequences(batch.observation_id_list, maxlen=max_len(batch.observation_id_list)).astype('int32')\n",
        "#         print(observation_id_list)\n",
        "#         input_observation = to_pt(observation_id_list, self.use_cuda)\n",
        "\n",
        "#         bert_ids = torch.tensor(batch.bert_ids, dtype=torch.long).to(self.model.device)\n",
        "#         bert_masks = torch.tensor(batch.bert_masks, dtype=torch.long).to(self.model.device)\n",
        "        bert_ids = pad_sequences(batch.bert_ids, maxlen=max_len(batch.bert_ids)).astype('int32')\n",
        "        bert_masks = pad_sequences(batch.bert_masks, maxlen=max_len(batch.bert_masks)).astype('int32')\n",
        "\n",
        "#         next_observation_id_list = pad_sequences(batch.next_observation_id_list, maxlen=max_len(batch.next_observation_id_list)).astype('int32')\n",
        "#         next_input_observation = to_pt(next_observation_id_list, self.use_cuda)\n",
        "\n",
        "#         next_bert_ids = torch.tensor(batch.next_bert_ids, dtype=torch.long).to(self.model.device)\n",
        "#         next_bert_masks = torch.tensor(batch.next_bert_masks, dtype=torch.long).to(self.model.device)\n",
        "\n",
        "        next_bert_ids = pad_sequences(batch.next_bert_ids, maxlen=max_len(batch.next_bert_ids)).astype('int32')\n",
        "        next_bert_masks = pad_sequences(batch.next_bert_masks, maxlen=max_len(batch.next_bert_masks)).astype('int32')\n",
        "\n",
        "        chosen_indices = list(list(zip(*batch.word_indices)))\n",
        "        chosen_indices = [torch.stack(item, 0) for item in chosen_indices]  # list of batch x 1\n",
        "\n",
        "        word_ranks = self.get_ranks(bert_ids, bert_masks)  # list of batch x vocab\n",
        "        \n",
        "        del bert_ids\n",
        "        del bert_masks\n",
        "        \n",
        "        word_qvalues = [w_rank.gather(1, idx).squeeze(-1) for w_rank, idx in zip(word_ranks, chosen_indices)]  # list of batch\n",
        "        \n",
        "        del chosen_indices\n",
        "        del word_ranks\n",
        "        \n",
        "        q_value = torch.mean(torch.stack(word_qvalues, -1), -1)  # batch\n",
        "        del word_qvalues\n",
        "\n",
        "        next_word_ranks = self.get_ranks(next_bert_ids, next_bert_masks)  # batch x n_verb, batch x n_noun, batchx n_second_noun\n",
        "        del next_bert_ids\n",
        "        del next_bert_masks\n",
        "        \n",
        "        next_word_masks = list(list(zip(*batch.next_word_masks)))\n",
        "        next_word_masks = [np.stack(item, 0) for item in next_word_masks]\n",
        "        next_word_qvalues, _ = self.choose_maxQ_command(next_word_ranks, next_word_masks)\n",
        "        del next_word_masks\n",
        "        del next_word_ranks\n",
        "        \n",
        "        next_q_value = torch.mean(torch.stack(next_word_qvalues, -1), -1)  # batch\n",
        "        next_q_value = next_q_value.detach()\n",
        "\n",
        "        rewards = torch.stack(batch.reward)  # batch\n",
        "        not_done = 1.0 - np.array(batch.done, dtype='float32')  # batch\n",
        "        not_done = to_pt(not_done, self.use_cuda, type='float')\n",
        "        rewards = rewards + not_done * next_q_value * self.discount_gamma  # batch\n",
        "        del not_done\n",
        "        \n",
        "        mask = torch.stack(batch.mask)  # batch\n",
        "        loss = F.smooth_l1_loss(q_value * mask, rewards * mask)\n",
        "        \n",
        "        del q_value\n",
        "        del mask\n",
        "        del rewards\n",
        "        del batch\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def finish(self) -> None:\n",
        "        \"\"\"\n",
        "        All games in the batch are finished. One can choose to save checkpoints,\n",
        "        evaluate on validation set, or do parameter annealing here.\n",
        "        \"\"\"\n",
        "        # Game has finished (either win, lose, or exhausted all the given steps).\n",
        "        self.final_rewards = np.array(self.scores[-1], dtype='float32')  # batch\n",
        "        dones = []\n",
        "        for d in self.dones:\n",
        "            d = np.array([float(dd) for dd in d], dtype='float32')\n",
        "            dones.append(d)\n",
        "        dones = np.array(dones)\n",
        "        step_used = 1.0 - dones\n",
        "        self.step_used_before_done = np.sum(step_used, 0)  # batch\n",
        "\n",
        "        self.history_avg_scores.push(np.mean(self.final_rewards))\n",
        "        # save checkpoint\n",
        "#         print(self.mode)\n",
        "#         print(self.current_episode)\n",
        "#         print(self.save_frequency)\n",
        "        if self.mode == \"train\" and self.current_episode % self.save_frequency == 0:\n",
        "            avg_score = self.history_avg_scores.get_avg()\n",
        "            if avg_score > self.best_avg_score_so_far:\n",
        "              self.best_avg_score_so_far = avg_score\n",
        "\n",
        "              save_to = self.model_checkpoint_path + '/' + self.experiment_tag + \"_episode_\" + str(self.current_episode) + \".pt\"\n",
        "              if not os.path.isdir(self.model_checkpoint_path):\n",
        "                  os.mkdir(self.model_checkpoint_path)\n",
        "              torch.save(self.model.state_dict(), save_to)\n",
        "              print(\"\\n========= saved checkpoint =========\")\n",
        "\n",
        "        self.current_episode += 1\n",
        "        # annealing\n",
        "        if self.current_episode < self.epsilon_anneal_episodes:\n",
        "            self.epsilon -= (self.epsilon_anneal_from - self.epsilon_anneal_to) / float(self.epsilon_anneal_episodes)\n",
        "      \n",
        "    def get_mean_loss(self):\n",
        "      mean_loss = 0.\n",
        "      if len(self.loss) != 0:   \n",
        "          mean_loss = sum(self.loss) / len(self.loss)\n",
        "      self.loss = []\n",
        "      return mean_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHuITVpD0nAN",
        "colab_type": "text"
      },
      "source": [
        "## Setup configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9jFzEnr1zt9",
        "colab_type": "text"
      },
      "source": [
        "### Vocab\n",
        "Upload vocab.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfc78DzULeIf",
        "colab_type": "code",
        "outputId": "8e92dbff-4a61-4a96-e47a-0519003dca8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "if not os.path.isfile('./vocab.txt'):\n",
        "    uploaded = files.upload()\n",
        "    # Upload vocab.txt\n",
        "    for fn in uploaded.keys():\n",
        "        print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "else:\n",
        "    print(\"Vocab already uploaded!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab already uploaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhn6sd_gLvC-",
        "colab_type": "code",
        "outputId": "96b2eebe-c5d9-4f6c-f331-b5eea512c929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!head vocab.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\n",
            "\"\n",
            "#\n",
            "$\n",
            "%\n",
            "&\n",
            "'\n",
            "'a\n",
            "'d\n",
            "'ll\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWAhh8mL2WCf",
        "colab_type": "text"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9wwaYyZkid1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#enough memory first try 3 games : epochs > 8\n",
        "# with open('./config.yaml', 'w') as config:\n",
        "#     config.write(\"\"\"general:\n",
        "#   discount_gamma: 0.5\n",
        "#   random_seed: 42\n",
        "#   use_cuda: True  # disable this when running on machine without cuda\n",
        "\n",
        "#   # replay memory\n",
        "#   replay_memory_capacity: 100000  # adjust this depending on your RAM size\n",
        "#   replay_memory_priority_fraction: 0.25\n",
        "#   update_per_k_game_steps: 20\n",
        "#   replay_batch_size: 4\n",
        "\n",
        "#   # epsilon greedy\n",
        "#   epsilon_anneal_episodes: 300  # -1 if not annealing\n",
        "#   epsilon_anneal_from: 1.0\n",
        "#   epsilon_anneal_to: 0.2\n",
        "\n",
        "# checkpoint:\n",
        "#   experiment_tag: 'starting-kit'\n",
        "#   model_checkpoint_path: './saved_models'\n",
        "#   load_pretrained: False  # during test, enable this so that the agent load your pretrained model\n",
        "#   pretrained_experiment_tag: 'starting-kit'\n",
        "#   save_frequency: 100\n",
        "\n",
        "# training:\n",
        "#   batch_size: 1\n",
        "#   nb_epochs: 100\n",
        "#   max_nb_steps_per_episode: 100  # after this many steps, a game is terminated\n",
        "#   optimizer:\n",
        "#     step_rule: 'adam'  # adam\n",
        "#     learning_rate: 0.001\n",
        "#     clip_grad_norm: 5\n",
        "\n",
        "# model:\n",
        "#   embedding_size: 32\n",
        "#   encoder_rnn_hidden_size: [32]\n",
        "#   action_scorer_hidden_dim: 16\n",
        "#   dropout_between_rnn_layers: 0.\n",
        "#   bert_model: 'bert-base-uncased'\n",
        "#   layer_index: 11\n",
        "# \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyvrcvxpp2FN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# second try 3 games 7-8 epochs max\n",
        "# with open('./config.yaml', 'w') as config:\n",
        "#     config.write(\"\"\"general:\n",
        "#   discount_gamma: 0.7\n",
        "#   random_seed: 42\n",
        "#   use_cuda: True  # disable this when running on machine without cuda\n",
        "\n",
        "#   # replay memory\n",
        "#   replay_memory_capacity: 100000  # adjust this depending on your RAM size\n",
        "#   replay_memory_priority_fraction: 0.25\n",
        "#   update_per_k_game_steps: 4\n",
        "#   replay_batch_size: 4\n",
        "\n",
        "#   # epsilon greedy\n",
        "#   epsilon_anneal_episodes: 60  # -1 if not annealing\n",
        "#   epsilon_anneal_from: 1.0\n",
        "#   epsilon_anneal_to: 0.2\n",
        "\n",
        "# checkpoint:\n",
        "#   experiment_tag: 'starting-kit'\n",
        "#   model_checkpoint_path: '/gdrive/My Drive/saved_models'\n",
        "#   load_pretrained: False  # during test, enable this so that the agent load your pretrained model\n",
        "#   pretrained_experiment_tag: 'starting-kit'\n",
        "#   save_frequency: 200\n",
        "\n",
        "# training:\n",
        "#   batch_size: 1\n",
        "#   nb_epochs: 100\n",
        "#   max_nb_steps_per_episode: 100  # after this many steps, a game is terminated\n",
        "#   optimizer:\n",
        "#     step_rule: 'adam'  # adam\n",
        "#     learning_rate: 0.001\n",
        "#     clip_grad_norm: 5\n",
        "\n",
        "# model:\n",
        "#   embedding_size: 64\n",
        "#   encoder_rnn_hidden_size: [64]\n",
        "#   action_scorer_hidden_dim: 32\n",
        "#   dropout_between_rnn_layers: 0.\n",
        "#   bert_model: 'bert-base-uncased'\n",
        "#   layer_index: 11\n",
        "# \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R69AITdxqig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 6 games more than 20 epochs\n",
        "# with open('./config.yaml', 'w') as config:\n",
        "#     config.write(\"\"\"general:\n",
        "#   discount_gamma: 0.7\n",
        "#   random_seed: 42\n",
        "#   use_cuda: True  # disable this when running on machine without cuda\n",
        "\n",
        "#   # replay memory\n",
        "#   replay_memory_capacity: 100000  # adjust this depending on your RAM size\n",
        "#   replay_memory_priority_fraction: 0.25\n",
        "#   update_per_k_game_steps: 4\n",
        "#   replay_batch_size: 4\n",
        "\n",
        "#   # epsilon greedy\n",
        "#   epsilon_anneal_episodes: 60  # -1 if not annealing\n",
        "#   epsilon_anneal_from: 1.0\n",
        "#   epsilon_anneal_to: 0.2\n",
        "\n",
        "# checkpoint:\n",
        "#   experiment_tag: 'starting-kit'\n",
        "#   model_checkpoint_path: '/gdrive/My Drive/saved_models'\n",
        "#   load_pretrained: False  # during test, enable this so that the agent load your pretrained model\n",
        "#   pretrained_experiment_tag: 'starting-kit'\n",
        "#   save_frequency: 200\n",
        "\n",
        "# training:\n",
        "#   batch_size: 1\n",
        "#   nb_epochs: 100\n",
        "#   max_nb_steps_per_episode: 100  # after this many steps, a game is terminated\n",
        "#   optimizer:\n",
        "#     step_rule: 'adam'  # adam\n",
        "#     learning_rate: 0.001\n",
        "#     clip_grad_norm: 5\n",
        "\n",
        "# model:\n",
        "#   embedding_size: 64\n",
        "#   encoder_rnn_hidden_size: [64]\n",
        "#   action_scorer_hidden_dim: 32\n",
        "#   dropout_between_rnn_layers: 0.\n",
        "#   bert_model: 'bert-base-uncased'\n",
        "#   layer_index: 11\n",
        "# \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufN2JE2f1eTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./config.yaml', 'w') as config:\n",
        "    config.write(\"\"\"general:\n",
        "  discount_gamma: 0.7\n",
        "  random_seed: 42\n",
        "  use_cuda: True  # disable this when running on machine without cuda\n",
        "\n",
        "  # replay memory\n",
        "  replay_memory_capacity: 100000  # adjust this depending on your RAM size\n",
        "  replay_memory_priority_fraction: 0.5\n",
        "  update_per_k_game_steps: 8\n",
        "  replay_batch_size: 24\n",
        "\n",
        "  # epsilon greedy\n",
        "  epsilon_anneal_episodes: 200  # -1 if not annealing\n",
        "  epsilon_anneal_from: 1\n",
        "  epsilon_anneal_to: 0.2\n",
        "\n",
        "checkpoint:\n",
        "  experiment_tag: 'bert-dqn-noisy-networks-large'\n",
        "  model_checkpoint_path: '/gdrive/My Drive/TextWorld/trained_models'\n",
        "  load_pretrained: True  # during test, enable this so that the agent load your pretrained model\n",
        "  pretrained_experiment_tag: 'bert-dqn-noisy-networks-large_episode_500'\n",
        "  save_frequency: 100\n",
        "\n",
        "training:\n",
        "  batch_size: 10\n",
        "  nb_epochs: 100\n",
        "  max_nb_steps_per_episode: 100  # after this many steps, a game is terminated\n",
        "  optimizer:\n",
        "    step_rule: 'adam'  # adam\n",
        "    learning_rate: 0.001\n",
        "    clip_grad_norm: 5\n",
        "\n",
        "model:\n",
        "  noisy_std: 0.3\n",
        "  embedding_size: 192\n",
        "  encoder_rnn_hidden_size: [384]\n",
        "  action_scorer_hidden_dim: 128\n",
        "  dropout_between_rnn_layers: 0.\n",
        "  bert_model: 'bert-base-uncased'\n",
        "  train_bert: False\n",
        "  layer_index: 11\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je184JvpCfos",
        "colab_type": "text"
      },
      "source": [
        "### Mount drive to load games\n",
        "\n",
        "Notebook takes sample games from google drive(requires authentication).\n",
        "\n",
        "To train the agent with games, upload archive with them in google drive and fix the path to the archive inside drive below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XugC3fAz9hpB",
        "colab_type": "code",
        "outputId": "deb23ab8-c25f-4d03-f51d-529bd7de7b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdMypOrSL4jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# home_dir = '/gdrive/My Drive/Masters/TextWorld/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qv6m4A4MgY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path_to_sample_games = home_dir + 'sample_games'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNOgW2K4NzCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_sample_games = '/gdrive/My Drive/TextWorld/sample_games'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hLhnwCACncb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def select_additional_infos() -> EnvInfos:\n",
        "    \"\"\"\n",
        "    Returns what additional information should be made available at each game step.\n",
        "\n",
        "    Requested information will be included within the `infos` dictionary\n",
        "    passed to `CustomAgent.act()`. To request specific information, create a\n",
        "    :py:class:`textworld.EnvInfos <textworld.envs.wrappers.filter.EnvInfos>`\n",
        "    and set the appropriate attributes to `True`. The possible choices are:\n",
        "\n",
        "    * `description`: text description of the current room, i.e. output of the `look` command;\n",
        "    * `inventory`: text listing of the player's inventory, i.e. output of the `inventory` command;\n",
        "    * `max_score`: maximum reachable score of the game;\n",
        "    * `objective`: objective of the game described in text;\n",
        "    * `entities`: names of all entities in the game;\n",
        "    * `verbs`: verbs understood by the the game;\n",
        "    * `command_templates`: templates for commands understood by the the game;\n",
        "    * `admissible_commands`: all commands relevant to the current state;\n",
        "\n",
        "    In addition to the standard information, game specific information\n",
        "    can be requested by appending corresponding strings to the `extras`\n",
        "    attribute. For this competition, the possible extras are:\n",
        "\n",
        "    * `'recipe'`: description of the cookbook;\n",
        "    * `'walkt\n",
        "\n",
        "    hrough'`: one possible solution to the game (not guaranteed to be optimal);\n",
        "\n",
        "    Example:\n",
        "        Here is an example of how to request information and retrieve it.\n",
        "\n",
        "        >>> from textworld import EnvInfos\n",
        "        >>> request_infos = EnvInfos(description=True, inventory=True, extras=[\"recipe\"])\n",
        "        ...\n",
        "        >>> env = gym.make(env_id)\n",
        "        >>> ob, infos = env.reset()\n",
        "        >>> print(infos[\"description\"])\n",
        "        >>> print(infos[\"inventory\"])\n",
        "        >>> print(infos[\"extra.recipe\"])\n",
        "\n",
        "    Notes:\n",
        "        The following information *won't* be available at test time:\n",
        "\n",
        "        * 'walkthrough'\n",
        "    \"\"\"\n",
        "    request_infos = EnvInfos()\n",
        "    request_infos.description = True\n",
        "    request_infos.inventory = True\n",
        "    request_infos.entities = True\n",
        "    request_infos.verbs = True\n",
        "    request_infos.max_score = True\n",
        "    request_infos.has_won = True\n",
        "    request_infos.has_lost = True\n",
        "    request_infos.extras = [\"recipe\", \"walkthrough\"]\n",
        "    return request_infos\n",
        "  \n",
        "def gather_entites(game_files):\n",
        "    requested_infos = select_additional_infos()\n",
        "    _validate_requested_infos(requested_infos)\n",
        "\n",
        "    env_id = textworld.gym.register_games(game_files, requested_infos,\n",
        "                                          max_episode_steps=1,\n",
        "                                          name=\"training\")\n",
        "\n",
        "    env_id = textworld.gym.make_batch(env_id, batch_size=1, parallel=True)\n",
        "    env = gym.make(env_id)\n",
        "    game_range = range(len(game_files))\n",
        "    entities = set()\n",
        "    verbs = set()\n",
        "    for game_no in game_range:\n",
        "        obs, infos = env.reset()\n",
        "        env.skip()\n",
        "        entities |= { a for i in infos['entities'] for a in i }\n",
        "        verbs |= { a for i in infos['verbs'] for a in i }\n",
        "    return list(entities), list(verbs)\n",
        "    \n",
        "    \n",
        "def make_vocab(games):\n",
        "    entities, verbs = gather_entites(games)\n",
        "    \n",
        "    with open(\"./vocab.txt\") as f:\n",
        "        word_vocab = f.read().split(\"\\n\")\n",
        "        \n",
        "    #########################\n",
        "    batch_size = len(verbs)\n",
        "    verbs_word_list = verbs\n",
        "    noun_word_list, adj_word_list = [], []\n",
        "    tmp_nouns, tmp_adjs = [], []\n",
        "    for name in entities:\n",
        "        split = name.split()\n",
        "        tmp_nouns.append(split[-1])\n",
        "        if len(split) > 1:\n",
        "            tmp_adjs.append(\" \".join(split[:-1]))\n",
        "    noun_word_list = list(set(tmp_nouns))\n",
        "    adj_word_list = list(set(tmp_adjs))\n",
        "\n",
        "    word2id = { word: idx for idx, word in enumerate(word_vocab) }\n",
        "    \n",
        "    verb_mask = np.zeros((len(word_vocab),), dtype=\"float32\")\n",
        "    noun_mask = np.zeros((len(word_vocab),), dtype=\"float32\")\n",
        "    adj_mask = np.zeros((len(word_vocab),), dtype=\"float32\")\n",
        "  \n",
        "    for w in verbs_word_list:\n",
        "        if w in word2id:\n",
        "            verb_mask[word2id[w]] = 1.0\n",
        "    for w in noun_word_list:\n",
        "        if w in word2id:\n",
        "            noun_mask[word2id[w]] = 1.0\n",
        "    for w in adj_word_list:\n",
        "        if w in word2id:\n",
        "            adj_mask[word2id[w]] = 1.0\n",
        "\n",
        "    second_noun_mask = copy.copy(noun_mask)\n",
        "    second_adj_mask = copy.copy(adj_mask)\n",
        "    second_noun_mask[:, self.EOS_id] = 1.0\n",
        "    adj_mask[:, self.EOS_id] = 1.0\n",
        "    second_adj_mask[:, self.EOS_id] = 1.0\n",
        "    word_masks_np = [verb_mask, adj_mask, noun_mask, second_adj_mask, second_noun_mask]\n",
        "    \n",
        "    return word_vocab, word2id, word_masks_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2HzAOxlCPDNI",
        "colab": {}
      },
      "source": [
        "# List of additional information available during evaluation.\n",
        "AVAILABLE_INFORMATION = EnvInfos(\n",
        "    description=True, inventory=True,\n",
        "    max_score=True, objective=True, entities=True, verbs=True,\n",
        "    command_templates=True, admissible_commands=True,\n",
        "    has_won=True, has_lost=True,\n",
        "    extras=[\"recipe\"]\n",
        ")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "def _validate_requested_infos(infos: EnvInfos):\n",
        "    msg = \"The following information cannot be requested: {}\"\n",
        "    for key in infos.basics:\n",
        "        if not getattr(AVAILABLE_INFORMATION, key):\n",
        "            raise ValueError(msg.format(key))\n",
        "\n",
        "    for key in infos.extras:\n",
        "        if key not in AVAILABLE_INFORMATION.extras:\n",
        "            raise ValueError(msg.format(key))\n",
        "            \n",
        "def get_index(game_no, stats):\n",
        "    return \"G{}_{}\".format(game_no, stats)\n",
        "  \n",
        "def get_game_id(game_info):\n",
        "    return hash((tuple(game_info['entities'][0]), game_info['extra.recipe'][0]))\n",
        "  \n",
        "def make_stats(count_games):\n",
        "    stats_cols = [ \"scores\", \"steps\", \"loss\", \"max_score\", \"outcomes\", \"eps\", \"state\"]\n",
        "    stats = {}\n",
        "    for col in stats_cols:\n",
        "        stats[col] = [0] * count_games\n",
        "    return stats  \n",
        "\n",
        "def save_to_csv(epoch_no, stats_df, score_mean, states, loss, eps, col):\n",
        "  filename = '/gdrive/My Drive/stats/TextWorld/game_' + str(col) + '.csv'\n",
        "  log_df = pd.DataFrame(columns=['epoch','score', 'steps', 'loss', 'eps', 'state'])\n",
        "  log_df.loc[0,'epoch'] = epoch_no\n",
        "  log_df.loc[0,'score'] = score_mean\n",
        "  log_df.loc[0,'steps'] = stats_df[get_index(col, 'st')]['avr']\n",
        "  log_df.loc[0,'loss'] = loss[col]\n",
        "  log_df.loc[0,'eps'] = eps[col]\n",
        "  log_df.loc[0, 'state'] = states[col]\n",
        "  if not os.path.isfile(filename):\n",
        "     log_df.to_csv(filename, header=['epoch','score', 'steps', 'loss', 'eps', 'state'])\n",
        "  else: # else it exists so append without writing the header\n",
        "     log_df.to_csv(filename, mode='a', header=False)\n",
        "            \n",
        "def print_epoch_stats(epoch_no, stats):\n",
        "    print(\"\\n\\nEpoch: {:3d}\".format(epoch_no))\n",
        "    steps, scores, loss, states = stats[\"steps\"], stats[\"scores\"], stats[\"loss\"], stats[\"state\"]\n",
        "    max_scores, outcomes = stats[\"max_score\"], stats[\"outcomes\"]\n",
        "    games_cnt, parallel_cnt = len(steps), len(steps[0])\n",
        "    columns = [ get_index(col, st) for col in range(games_cnt) for st in ['st', 'sc']]\n",
        "    stats_df = pd.DataFrame(index=list(range(parallel_cnt)) + [\"avr\", \"loss\"], columns=columns)\n",
        "        \n",
        "    for col in range(games_cnt):\n",
        "        for row in range(parallel_cnt):\n",
        "          outcome = outcomes[col][row]\n",
        "          outcome = outcome > 0 and \"W\" or outcome < 0 and \"L\" or \"\"\n",
        "          stats_df[get_index(col, 'st')][row] = steps[col][row]\n",
        "          stats_df[get_index(col, 'sc')][row] = outcome + \" \" + str(scores[col][row])\n",
        "        score_mean = np.mean(scores[col])\n",
        "        stats_df[get_index(col, 'sc')]['avr'] = \"{}/{}\".format(score_mean, max_scores[col])\n",
        "        stats_df[get_index(col, 'st')]['avr'] = stats_df[get_index(col, 'st')].mean()\n",
        "        stats_df[get_index(col, 'sc')]['loss'] = \"{:.5f}\".format(loss[col])\n",
        "        stats_df[get_index(col, 'st')]['loss'] = states[col]\n",
        "        \n",
        "        save_to_csv(epoch_no, stats_df, score_mean, states, loss, stats['eps'], col)\n",
        "    print(stats_df)\n",
        "\n",
        "def train(game_files):\n",
        "    requested_infos = select_additional_infos()\n",
        "    \n",
        "    agent = CustomAgent()\n",
        "    env_id = textworld.gym.register_games(game_files, requested_infos,\n",
        "                                          max_episode_steps=agent.max_nb_steps_per_episode,\n",
        "                                          name=\"training\")\n",
        "\n",
        "    env_id = textworld.gym.make_batch(env_id, batch_size=agent.batch_size, parallel=True)\n",
        "    print(\"ENVID: {}\".format(env_id))\n",
        "\n",
        "    print(\"Making {} parallel environments to train on them\\n\".format(agent.batch_size))\n",
        "    env = gym.make(env_id)\n",
        "    count_games = len(game_files)\n",
        "    games_ids = {}\n",
        "    for epoch_no in range(1, agent.nb_epochs + 1):\n",
        "        stats = make_stats(count_games)\n",
        "        idx = 0\n",
        "        for game_no in tqdm(range(count_games)):\n",
        "            obs, infos = env.reset()\n",
        "            game_id = get_game_id(infos)\n",
        "            if epoch_no == 1:\n",
        "                games_ids[game_id] = idx\n",
        "                idx += 1\n",
        "            real_id = games_ids[game_id]\n",
        "            stats[\"max_score\"][real_id] = infos['max_score'][0]\n",
        "            \n",
        "            imitate = random.random() > 1.0\n",
        "            agent.train(imitate)\n",
        "\n",
        "            scores = [0] * len(obs) \n",
        "            dones = [False] * len(obs)\n",
        "            steps = [0] * len(obs)\n",
        "            while not all(dones):\n",
        "                # Increase step counts.\n",
        "                steps = [step + int(not done) for step, done in zip(steps, dones)]\n",
        "                commands = agent.act(obs, scores, dones, infos)\n",
        "                obs, scores, dones, infos = env.step(commands)\n",
        "\n",
        "            # Let the agent knows the game is done.\n",
        "            agent.act(obs, scores, dones, infos)\n",
        "\n",
        "            stats[\"scores\"][real_id] = scores\n",
        "            stats[\"steps\"][real_id] = steps\n",
        "            stats[\"eps\"][real_id] = agent.epsilon\n",
        "            stats[\"loss\"][real_id] = agent.get_mean_loss()\n",
        "            stats[\"state\"][real_id] = [\"imitate\" if imitate else \"agent\"]\n",
        "            stats[\"outcomes\"][real_id] = [ w-l for w, l in zip(infos['has_won'], infos['has_lost'])]\n",
        "        \n",
        "        print_epoch_stats(epoch_no, stats)\n",
        "    torch.save(agent.model, './agent_model.pt')\n",
        "    return\n",
        "          \n",
        "\n",
        "# game_dir = path_to_sample_games\n",
        "# games = []\n",
        "# if os.path.isdir(game_dir):\n",
        "#     games += glob.glob(os.path.join(game_dir, \"*.ulx\"))\n",
        "# print(\"{} games found for training.\".format(len(games)))\n",
        "\n",
        "# if len(games) != 0:\n",
        "#     train(games)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx3GsC_XE5Na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8hIulvHzNce",
        "colab_type": "text"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrIFg_ec1uvV",
        "colab_type": "code",
        "outputId": "00c72eb4-a60b-4842-b2bc-0dd14e0d2fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "# COMMENT TRAIN\n",
        "# FIX LOADING MODEL PATH\n",
        "# FIX BATCH_SIZE TO BE 10\n",
        "\n",
        "\n",
        "def eval_games(game_files):\n",
        "  requested_infos = select_additional_infos()\n",
        "\n",
        "  agent = CustomAgent()\n",
        "  \n",
        "  env_id = textworld.gym.register_games(game_files, requested_infos,\n",
        "                                        max_episode_steps=agent.max_nb_steps_per_episode,\n",
        "                                        name=\"eval\")\n",
        "\n",
        "  env_id = textworld.gym.make_batch(env_id, batch_size=10, parallel=True)\n",
        "  print(\"ENVID: {}\".format(env_id))\n",
        "\n",
        "  print(\"Making {} parallel environments to eval on them\\n\".format(agent.batch_size))\n",
        "  env = gym.make(env_id)\n",
        "  count_games = len(game_files)\n",
        "  games_ids = {}\n",
        "\n",
        "  stats = make_stats(count_games)\n",
        "  score_sum = 0\n",
        "  steps_sum = 0\n",
        "  steps_length = count_games*10\n",
        "  for game_no in tqdm(range(count_games)):\n",
        "      obs, infos = env.reset()\n",
        "\n",
        "      agent.eval()\n",
        "\n",
        "      scores = [0] * len(obs) \n",
        "      dones = [False] * len(obs)\n",
        "      steps = [0] * len(obs)\n",
        "      while not all(dones):\n",
        "          # Increase step counts.\n",
        "          steps = [step + int(not done) for step, done in zip(steps, dones)]\n",
        "          commands = agent.act(obs, scores, dones, infos)\n",
        "          obs, scores, dones, infos = env.step(commands)\n",
        "\n",
        "      # Let the agent knows the game is done.\n",
        "      agent.act(obs, scores, dones, infos)\n",
        "      score_sum += sum(scores)\n",
        "      steps_sum += sum(steps)\n",
        "      \n",
        "  print('Max score: ', score_sum)\n",
        "  print('Mean steps: ', steps_sum / steps_length)\n",
        "\n",
        "game_dir = path_to_sample_games\n",
        "games = []\n",
        "if os.path.isdir(game_dir):\n",
        "    games += glob.glob(os.path.join(game_dir, \"*.ulx\"))\n",
        "print(\"{} games found for training.\".format(len(games)))\n",
        "\n",
        "if len(games) != 0:\n",
        "  eval_games(games)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 games found for training.\n",
            "total number of parameters: 135648992\n",
            "number of trainable parameters: 26166752\n",
            "loading model from /gdrive/My Drive/TextWorld/trained_models/bert-dqn-noisy-networks-large_episode_500.pt\n",
            "\n",
            "ENVID: batch10-tw-eval-v0\n",
            "Making 10 parallel environments to eval on them\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n",
            "100%|██████████| 10/10 [04:02<00:00, 24.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max score:  90\n",
            "Mean steps:  100.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tw-eval-v0 closed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-10:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/textworld/gym/envs/batch_env.py\", line 20, in _child\n",
            "    command = pipe.recv()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
            "    buf = self._recv_bytes()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
            "    raise EOFError\n",
            "EOFError\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tw-eval-v0 closed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-9:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/textworld/gym/envs/batch_env.py\", line 20, in _child\n",
            "    command = pipe.recv()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
            "    buf = self._recv_bytes()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
            "    raise EOFError\n",
            "EOFError\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tw-eval-v0 closed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-8:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk_E3OyL1bYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}