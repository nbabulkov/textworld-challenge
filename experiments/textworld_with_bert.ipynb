{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textworld-with-bert.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaT3om3nMpml",
        "colab_type": "text"
      },
      "source": [
        "# Textworld starting kit notebook\n",
        "\n",
        "Model: *Bert-DQN with replay memory*\n",
        "\n",
        "When running first: \n",
        " 1. Run the first 2 code cells(with pip installations)\n",
        " 2. Restart runtime\n",
        " 3. Countinue with the next cells\n",
        "\n",
        "This is done, because there is a problem with dependencies of **textworld** and **colab**, requiring different versions of **prompt-toolkit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-XUxa37Z1S5",
        "colab_type": "code",
        "outputId": "31dbd4f0-0974-4a16-b929-69b611de393d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install textworld"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textworld\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ed/698f68c284aa6f45013c9cf42b26c09aebc1096226e9d004464eb33a75cf/textworld-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 2.7MB/s \n",
            "\u001b[?25hCollecting greenlet==0.4.13 (from textworld)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/ce/7b3a19a3eb8c79e6237ba1fb7a8729b39034dd2de8753b8d27e5abc59fd5/greenlet-0.4.13-cp36-cp36m-manylinux1_x86_64.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 19.4MB/s \n",
            "\u001b[?25hCollecting jericho>=1.1.5 (from textworld)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/29/162c0b34722bed00d533a657422d98396c9c4f29fc8a35c1787dc0120678/jericho-1.2.3.tar.gz (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.0.3)\n",
            "Collecting gevent==1.3.5 (from textworld)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/2b/6be042be1023df54889d9e2a90b167f6fea65445384fccfdfd988cc16239/gevent-1.3.5-cp36-cp36m-manylinux1_x86_64.whl (4.6MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6MB 27.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=3.12 in /usr/local/lib/python3.6/dist-packages (from textworld) (3.13)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from textworld)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 39.0MB/s \n",
            "\u001b[?25hCollecting pybars3>=0.9.3 (from textworld)\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/28/bf14035877a989f64081a44337ea2f5858c72b598a01f93a74be541666fb/pybars3-0.9.6.tar.gz\n",
            "Collecting tatsu>=4.3.0 (from textworld)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/36/00664e684e4bba5730db661847447bbcfe789008a154755013e5f457b648/TatSu-4.4.0-py2.py3-none-any.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 24.7MB/s \n",
            "\u001b[?25hCollecting urwid>=2.0.1 (from textworld)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/90/415728875c230fafd13d118512bde3184d810d7bf798a631abc05fac09d0/urwid-2.0.1.tar.gz (604kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2 in /usr/local/lib/python3.6/dist-packages (from textworld) (2.3)\n",
            "Collecting pillow>=5.1.0 (from textworld)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 26.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.12.3)\n",
            "Collecting selenium>=3.12.0 (from textworld)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 1.4MB/s \n",
            "\u001b[?25hCollecting gym==0.10.4 (from textworld)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/e5/4dae1de6534221f74895c8a95ae4eedc816a5fa003db1d4d608cbdc28b35/gym-0.10.4.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.16.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from textworld) (7.0.0)\n",
            "Requirement already satisfied: tqdm>=4.17.1 in /usr/local/lib/python3.6/dist-packages (from textworld) (4.28.1)\n",
            "Requirement already satisfied: pydot>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from textworld) (1.3.0)\n",
            "Collecting hashids>=1.2.0 (from textworld)\n",
            "  Downloading https://files.pythonhosted.org/packages/02/d3/0191ddd06cace1873f237f134a357d8af84c0ed3740526f4946ddbfaeed6/hashids-1.2.0.tar.gz\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->textworld) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->textworld) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->textworld) (0.15.4)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->textworld) (2.10.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->textworld) (1.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->textworld) (0.1.7)\n",
            "Collecting PyMeta3>=0.5.1 (from pybars3>=0.9.3->textworld)\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/af/409edba35fc597f1e386e3860303791ab5a28d6cc9a8aecbc567051b19a9/PyMeta3-0.5.1.tar.gz\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2->textworld) (4.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0.0->textworld) (2.19)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium>=3.12.0->textworld) (1.24.3)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.4->textworld) (2.21.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.10.4->textworld) (1.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot>=1.2.4->textworld) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask>=1.0.2->textworld) (1.1.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.4->textworld) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.4->textworld) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym==0.10.4->textworld) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym==0.10.4->textworld) (0.16.0)\n",
            "Building wheels for collected packages: jericho, pybars3, urwid, gym, hashids, PyMeta3\n",
            "  Building wheel for jericho (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/8b/fb/6d041f43ed7c5b42c93240a44931e3043740cde6fdc6b85cdc\n",
            "  Building wheel for pybars3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/ce/1e/e4432a4f5c398a55b787b4be4194ef0cb0ed30de5bbdefb2f3\n",
            "  Building wheel for urwid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/06/50/24011714e101b5ad8518c69175d117a257413e3c15a92983f0\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/41/49/1581815cc493e09e494ba013c2f6f29108b8e2adf40db4b21d\n",
            "  Building wheel for hashids (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/a9/3e/b57f0dba48497aacf3c20fc4aeefc7748a2ba34c8a8e48bf44\n",
            "  Building wheel for PyMeta3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/39/08/80a225ffde8b15eea306b6d603e3ed4aa44a616f7c2d485c6b\n",
            "Successfully built jericho pybars3 urwid gym hashids PyMeta3\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement gym[atari,classic_control]>=0.10.9, but you'll have gym 0.10.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: ipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: dopamine-rl 1.0.5 has requirement gym>=0.10.5, but you'll have gym 0.10.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: greenlet, jericho, gevent, prompt-toolkit, PyMeta3, pybars3, tatsu, urwid, pillow, selenium, gym, hashids, textworld\n",
            "  Found existing installation: greenlet 0.4.15\n",
            "    Uninstalling greenlet-0.4.15:\n",
            "      Successfully uninstalled greenlet-0.4.15\n",
            "  Found existing installation: gevent 1.4.0\n",
            "    Uninstalling gevent-1.4.0:\n",
            "      Successfully uninstalled gevent-1.4.0\n",
            "  Found existing installation: prompt-toolkit 1.0.16\n",
            "    Uninstalling prompt-toolkit-1.0.16:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.16\n",
            "  Found existing installation: Pillow 4.3.0\n",
            "    Uninstalling Pillow-4.3.0:\n",
            "      Successfully uninstalled Pillow-4.3.0\n",
            "  Found existing installation: gym 0.10.11\n",
            "    Uninstalling gym-0.10.11:\n",
            "      Successfully uninstalled gym-0.10.11\n",
            "Successfully installed PyMeta3-0.5.1 gevent-1.3.5 greenlet-0.4.13 gym-0.10.4 hashids-1.2.0 jericho-1.2.3 pillow-6.0.0 prompt-toolkit-2.0.9 pybars3-0.9.6 selenium-3.141.0 tatsu-4.4.0 textworld-1.1.1 urwid-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPpv7-6bVOsP",
        "colab_type": "code",
        "outputId": "1634a313-6311-477c-94e7-a45a3e27c5fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "!pip install prompt-toolkit==1.0.16"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting prompt-toolkit==1.0.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/a8/a151b6c61718eabe6b4672b6aa760b734989316d62ec1ba4996765e602d4/prompt_toolkit-1.0.16-py3-none-any.whl (244kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit==1.0.16) (1.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit==1.0.16) (0.1.7)\n",
            "\u001b[31mERROR: textworld 1.1.1 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: jupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.16 which is incompatible.\u001b[0m\n",
            "Installing collected packages: prompt-toolkit\n",
            "  Found existing installation: prompt-toolkit 2.0.9\n",
            "    Uninstalling prompt-toolkit-2.0.9:\n",
            "      Successfully uninstalled prompt-toolkit-2.0.9\n",
            "Successfully installed prompt-toolkit-1.0.16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48AF5zST9VJK",
        "colab_type": "code",
        "outputId": "b1f0d2de-ee9e-40c3-af7f-2048069b3ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch_pretrained_bert)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.174)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.174 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.174)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.174->boto3->pytorch_pretrained_bert) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.174->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.174->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75fX90LVjfbT",
        "colab_type": "code",
        "outputId": "627baf38-3d9a-48ab-9d4a-410f77279ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "import logging\n",
        "import yaml\n",
        "import copy\n",
        "import spacy\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Any\n",
        "from collections import namedtuple\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import gym\n",
        "import textworld.gym\n",
        "from textworld import EnvInfos\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-5AX-b4f25d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWGX1rdFtIgW",
        "colab_type": "text"
      },
      "source": [
        "## Generic functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zO94P3hjyH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_np(x):\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return x\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "\n",
        "def to_pt(np_matrix, enable_cuda=False, type='long'):\n",
        "    if type == 'long':\n",
        "        if enable_cuda:\n",
        "            return torch.autograd.Variable(torch.from_numpy(np_matrix).type(torch.LongTensor).cuda())\n",
        "        else:\n",
        "            return torch.autograd.Variable(torch.from_numpy(np_matrix).type(torch.LongTensor))\n",
        "    elif type == 'float':\n",
        "        if enable_cuda:\n",
        "            return torch.autograd.Variable(torch.from_numpy(np_matrix).type(torch.FloatTensor).cuda())\n",
        "        else:\n",
        "            return torch.autograd.Variable(torch.from_numpy(np_matrix).type(torch.FloatTensor))\n",
        "\n",
        "\n",
        "def _words_to_ids(words, word2id):\n",
        "    ids = []\n",
        "    for word in words:\n",
        "        try:\n",
        "            ids.append(word2id[word])\n",
        "        except KeyError:\n",
        "            ids.append(1)\n",
        "    return ids\n",
        "\n",
        "\n",
        "def preproc(s, str_type='None', tokenizer=None, lower_case=True):\n",
        "    if s is None:\n",
        "        return [\"nothing\"]\n",
        "    s = s.replace(\"\\n\", ' ')\n",
        "    if s.strip() == \"\":\n",
        "        return [\"nothing\"]\n",
        "    if str_type == 'feedback':\n",
        "        if \"$$$$$$$\" in s:\n",
        "            s = \"\"\n",
        "        if \"-=\" in s:\n",
        "            s = s.split(\"-=\")[0]\n",
        "    s = s.strip()\n",
        "    if len(s) == 0:\n",
        "        return [\"nothing\"]\n",
        "    tokens = [t.text for t in tokenizer(s)]\n",
        "    if lower_case:\n",
        "        tokens = [t.lower() for t in tokens]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def max_len(list_of_list):\n",
        "    return max(map(len, list_of_list))\n",
        "\n",
        "\n",
        "def pad_sequences(sequences, maxlen=None, dtype='int32', value=0.):\n",
        "    '''\n",
        "    Partially borrowed from Keras\n",
        "    # Arguments\n",
        "        sequences: list of lists where each element is a sequence\n",
        "        maxlen: int, maximum length\n",
        "        dtype: type to cast the resulting sequence.\n",
        "        value: float, value to pad the sequences to the desired value.\n",
        "    # Returns\n",
        "        x: numpy array with dimensions (number_of_sequences, maxlen)\n",
        "    '''\n",
        "    lengths = [len(s) for s in sequences]\n",
        "    nb_samples = len(sequences)\n",
        "    if maxlen is None:\n",
        "        maxlen = np.max(lengths)\n",
        "    # take the sample shape from the first non empty sequence\n",
        "    # checking for consistency in the main loop below.\n",
        "    sample_shape = tuple()\n",
        "    for s in sequences:\n",
        "        if len(s) > 0:\n",
        "            sample_shape = np.asarray(s).shape[1:]\n",
        "            break\n",
        "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
        "    for idx, s in enumerate(sequences):\n",
        "        if len(s) == 0:\n",
        "            continue  # empty list was found\n",
        "        # pre truncating\n",
        "        trunc = s[-maxlen:]\n",
        "        # check `trunc` has expected shape\n",
        "        trunc = np.asarray(trunc, dtype=dtype)\n",
        "        if trunc.shape[1:] != sample_shape:\n",
        "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
        "                             (trunc.shape[1:], idx, sample_shape))\n",
        "        # post padding\n",
        "        x[idx, :len(trunc)] = trunc\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HTSoK93tM6V",
        "colab_type": "text"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2VSAkD3s7Ke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def masked_mean(x, m=None, dim=-1):\n",
        "    \"\"\"\n",
        "        mean pooling when there're paddings\n",
        "        input:  tensor: batch x time x h\n",
        "                mask:   batch x time\n",
        "        output: tensor: batch x h\n",
        "    \"\"\"\n",
        "    if m is None:\n",
        "        return torch.mean(x, dim=dim)\n",
        "    mask_sum = torch.sum(m, dim=-1)  # batch\n",
        "    res = torch.sum(x, dim=1)  # batch x h\n",
        "    mean = res / (mask_sum.unsqueeze(-1) + 1e-6)\n",
        "    \n",
        "    del mask_sum\n",
        "    del res\n",
        "    \n",
        "    return mean\n",
        "\n",
        "\n",
        "class Embedding(torch.nn.Module):\n",
        "    '''\n",
        "    inputs: x:          batch x seq (x is post-padded by 0s)\n",
        "    outputs:embedding:  batch x seq x emb\n",
        "            mask:       batch x seq\n",
        "    '''\n",
        "\n",
        "    def __init__(self, embedding_size, vocab_size, enable_cuda=False):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.enable_cuda = enable_cuda\n",
        "        self.embedding_layer = torch.nn.Embedding(self.vocab_size, self.embedding_size, padding_idx=0)\n",
        "\n",
        "    def compute_mask(self, x):\n",
        "        mask = torch.ne(x, 0).float()\n",
        "        if self.enable_cuda:\n",
        "            mask = mask.cuda()\n",
        "        return mask\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.embedding_layer(x)  # batch x time x emb\n",
        "        mask = self.compute_mask(x)  # batch x time\n",
        "        return embeddings, mask\n",
        "\n",
        "\n",
        "class FastUniLSTM(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Adapted from https://github.com/facebookresearch/DrQA/\n",
        "    now supports:   different rnn size for each layer\n",
        "                    all zero rows in batch (from time distributed layer, by reshaping certain dimension)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ninp, nhids, dropout_between_rnn_layers=0.):\n",
        "        super(FastUniLSTM, self).__init__()\n",
        "        self.ninp = ninp\n",
        "        self.nhids = nhids\n",
        "        self.nlayers = len(self.nhids)\n",
        "        self.dropout_between_rnn_layers = dropout_between_rnn_layers\n",
        "        self.stack_rnns()\n",
        "\n",
        "    def stack_rnns(self):\n",
        "        rnns = [torch.nn.LSTM(self.ninp if i == 0 else self.nhids[i - 1],\n",
        "                              self.nhids[i],\n",
        "                              num_layers=1,\n",
        "                              bidirectional=False) for i in range(self.nlayers)]\n",
        "        self.rnns = torch.nn.ModuleList(rnns)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "        def pad_(tensor, n):\n",
        "            if n > 0:\n",
        "                zero_pad = torch.autograd.Variable(torch.zeros((n,) + tensor.size()[1:]))\n",
        "                if x.is_cuda:\n",
        "                    zero_pad = zero_pad.cuda()\n",
        "                tensor = torch.cat([tensor, zero_pad])\n",
        "            return tensor\n",
        "\n",
        "        \"\"\"\n",
        "        inputs: x:          batch x time x inp\n",
        "                mask:       batch x time\n",
        "        output: encoding:   batch x time x hidden[-1]\n",
        "        \"\"\"\n",
        "        # Compute sorted sequence lengths\n",
        "        batch_size = x.size(0)\n",
        "        lengths = mask.data.eq(1).long().sum(1)  # .squeeze()\n",
        "        _, idx_sort = torch.sort(lengths, dim=0, descending=True)\n",
        "        _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
        "\n",
        "        lengths = list(lengths[idx_sort])\n",
        "        idx_sort = torch.autograd.Variable(idx_sort)\n",
        "        idx_unsort = torch.autograd.Variable(idx_unsort)\n",
        "\n",
        "        # Sort x\n",
        "        x = x.index_select(0, idx_sort)\n",
        "\n",
        "        # remove non-zero rows, and remember how many zeros\n",
        "        n_nonzero = np.count_nonzero(lengths)\n",
        "        n_zero = batch_size - n_nonzero\n",
        "        if n_zero != 0:\n",
        "            lengths = lengths[:n_nonzero]\n",
        "            x = x[:n_nonzero]\n",
        "\n",
        "        # Transpose batch and sequence dims\n",
        "        x = x.transpose(0, 1)\n",
        "\n",
        "        # Pack it up\n",
        "        rnn_input = torch.nn.utils.rnn.pack_padded_sequence(x, lengths)\n",
        "\n",
        "        # Encode all layers\n",
        "        outputs = [rnn_input]\n",
        "        for i in range(self.nlayers):\n",
        "            rnn_input = outputs[-1]\n",
        "\n",
        "            # dropout between rnn layers\n",
        "            if self.dropout_between_rnn_layers > 0:\n",
        "                dropout_input = F.dropout(rnn_input.data,\n",
        "                                          p=self.dropout_between_rnn_layers,\n",
        "                                          training=self.training)\n",
        "                rnn_input = torch.nn.utils.rnn.PackedSequence(dropout_input,\n",
        "                                                              rnn_input.batch_sizes)\n",
        "            seq, last = self.rnns[i](rnn_input)\n",
        "            outputs.append(seq)\n",
        "            if i == self.nlayers - 1:\n",
        "                # last layer\n",
        "                last_state = last[0]  # (num_layers * num_directions, batch, hidden_size)\n",
        "                last_state = last_state[0]  # batch x hidden_size\n",
        "\n",
        "        # Unpack everything\n",
        "        for i, o in enumerate(outputs[1:], 1):\n",
        "            outputs[i] = torch.nn.utils.rnn.pad_packed_sequence(o)[0]\n",
        "        output = outputs[-1]\n",
        "\n",
        "        # Transpose and unsort\n",
        "        output = output.transpose(0, 1)  # batch x time x enc\n",
        "\n",
        "        # re-padding\n",
        "        output = pad_(output, n_zero)\n",
        "        last_state = pad_(last_state, n_zero)\n",
        "\n",
        "        output = output.index_select(0, idx_unsort)\n",
        "        last_state = last_state.index_select(0, idx_unsort)\n",
        "\n",
        "        # Pad up to original batch sequence length\n",
        "        if output.size(1) != mask.size(1):\n",
        "            padding = torch.zeros(output.size(0),\n",
        "                                  mask.size(1) - output.size(1),\n",
        "                                  output.size(2)).type(output.data.type())\n",
        "            output = torch.cat([output, torch.autograd.Variable(padding)], 1)\n",
        "\n",
        "        output = output.contiguous() * mask.unsqueeze(-1)\n",
        "        return output, last_state, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0NRD6XDtRKa",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zODbJxc7xt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_input  = '-= Pantry =- \\\n",
        "You\\'ve just sauntered into a pantry. You try to gain information on your surroundings by using a technique you call \"looking.\"\\\n",
        "You see a shelf. The shelf is wooden. On the shelf you can make out a black pepper and an orange bell pepper. I mean, just wow! Isn\\'t TextWorld just the best?\\\n",
        "There is an open frosted-glass door leading south.\\\n",
        " You are carrying nothing.\\\n",
        "Recipe #1\\\n",
        "---------\\\n",
        "Gather all following ingredients and follow the directions to prepare this tasty meal.\\\n",
        "Ingredients:\\\n",
        "  black pepper\\\n",
        "  red apple\\\n",
        "  water\\\n",
        "Directions:\\\n",
        "  prepare meal\\\n",
        "                    ________  ________  __    __  ________        \\\n",
        "                   |        \\|        \\|  \\  |  \\|        \\       \\\n",
        "                    \\$$$$$$$$| $$$$$$$$| $$  | $$ \\$$$$$$$$       \\\n",
        "                      | $$   | $$__     \\$$\\/  $$   | $$          \\\n",
        "                      | $$   | $$  \\     >$$  $$    | $$          \\\n",
        "                      | $$   | $$$$$    /  $$$$\\    | $$          \\\n",
        "                      | $$   | $$_____ |  $$ \\$$\\   | $$          \\\n",
        "                      | $$   | $$     \\| $$  | $$   | $$          \\\n",
        "                       \\$$    \\$$$$$$$$ \\$$   \\$$    \\$$          \\\n",
        "              __       __   ______   _______   __        _______  \\\n",
        "             |  \\  _  |  \\ /      \\ |       \\ |  \\      |       \\ \\\n",
        "             | $$ / \\ | $$|  $$$$$$\\| $$$$$$$\\| $$      | $$$$$$$\\ \\\n",
        "             | $$/  $\\| $$| $$  | $$| $$__| $$| $$      | $$  | $$\\\n",
        "             | $$  $$$\\ $$| $$  | $$| $$    $$| $$      | $$  | $$\\\n",
        "             | $$ $$\\$$\\$$| $$  | $$| $$$$$$$\\| $$      | $$  | $$\\\n",
        "             | $$$$  \\$$$$| $$__/ $$| $$  | $$| $$_____ | $$__/ $$\\\n",
        "             | $$$    \\$$$ \\$$    $$| $$  | $$| $$     \\| $$    $$\\\n",
        "              \\$$      \\$$  \\$$$$$$  \\$$   \\$$ \\$$$$$$$$ \\$$$$$$$ \\\n",
        "You are hungry! Let\\'s cook a delicious meal. Check the cookbook in the kitchen for the recipe. Once done, enjoy your meal!'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcWupwzq42-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preproc_example(s):\n",
        "  s = s.replace('$', '')\n",
        "  s = s.replace('#', '')\n",
        "  s = s.replace('\\n', ' ')\n",
        "  s = s.replace('  ', ' ')\n",
        "  s = s.replace('_', '')\n",
        "  s = s.replace('|', '')\n",
        "  s = s.replace('\\\\', '')\n",
        "  s = s.replace('/', '')\n",
        "  s = s.replace('-', '')\n",
        "  s = s.replace('=', '')\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0x53_FdBJ91",
        "colab_type": "code",
        "outputId": "6e9f75eb-307c-4cd0-c4bb-aea50446f7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "preproc_example(example_input)\n",
        "# example_input.replace('$', '')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Pantry  You\\'ve just sauntered into a pantry. You try to gain information on your surroundings by using a technique you call \"looking.\"You see a shelf. The shelf is wooden. On the shelf you can make out a black pepper and an orange bell pepper. I mean, just wow! Isn\\'t TextWorld just the best?There is an open frostedglass door leading south. You are carrying nothing.Recipe 1Gather all following ingredients and follow the directions to prepare this tasty meal.Ingredients: black pepper red apple waterDirections: prepare meal                                                                                                              >                                                                                                                                                                                                                                                                                                      You are hungry! Let\\'s cook a delicious meal. Check the cookbook in the kitchen for the recipe. Once done, enjoy your meal!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPMpGmA7_omf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convert_examples_to_features(sequences, tokenizer):\n",
        "  \"\"\"Loads a data file into a list of `InputFeature`s.\"\"\"\n",
        "  batch_tokens = []\n",
        "  batch_input_ids = []\n",
        "  batch_input_masks = []\n",
        "  for example in sequences:\n",
        "      _example = preproc_example(example)      \n",
        "#       print(_example)\n",
        "      tokens = tokenizer.tokenize(_example)\n",
        "      batch_tokens.append(tokens)\n",
        "      del _example\n",
        "      del tokens\n",
        "\n",
        "  max_length = max([len(x) for x in batch_tokens])\n",
        "#   print('bert_max_seqence', max_length)\n",
        "  for tokens in batch_tokens:\n",
        "      input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "      # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "      # tokens are attended to.\n",
        "      input_mask = [1] * len(input_ids)\n",
        "\n",
        "      # Zero-pad up to the sequence length.\n",
        "      while len(input_ids) < max_length:\n",
        "          input_ids.append(0)\n",
        "          input_mask.append(0)\n",
        "           \n",
        "      batch_input_ids.append(input_ids)\n",
        "      batch_input_masks.append(input_mask)\n",
        "      del input_ids\n",
        "      del input_mask\n",
        "  \n",
        "  return batch_tokens, batch_input_ids, batch_input_masks\n",
        "\n",
        "def freeze_layer(layer):\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd4txzFctSFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlogger = logging.getLogger(__name__)\n",
        "\n",
        "class Bert_DQN(torch.nn.Module):\n",
        "    model_name = 'bert_dqn'\n",
        "\n",
        "    def __init__(self, model_config, word_vocab, generate_length=5, enable_cuda=False):\n",
        "        super(Bert_DQN, self).__init__()\n",
        "        self.model_config = model_config\n",
        "        self.enable_cuda = enable_cuda\n",
        "        self.word_vocab_size = len(word_vocab)\n",
        "        self.id2word = word_vocab\n",
        "        self.generate_length = generate_length\n",
        "        self.read_config()\n",
        "#         print(enable_cuda)\n",
        "        self.device = torch.device(\"cuda\" if enable_cuda else \"cpu\")\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_model, do_lower_case=True)\n",
        "        self._def_layers()\n",
        "        self.init_weights()\n",
        "        self.print_parameters()\n",
        "\n",
        "    def print_parameters(self):\n",
        "      amount = 0\n",
        "      for p in self.parameters():\n",
        "          amount += np.prod(p.size())\n",
        "      print(\"total number of parameters: %s\" % (amount))\n",
        "      parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
        "      amount = 0\n",
        "      for p in parameters:\n",
        "          amount += np.prod(p.size())\n",
        "      print(\"number of trainable parameters: %s\" % (amount))\n",
        "\n",
        "    def read_config(self):\n",
        "        # model config\n",
        "#         self.embedding_size = self.model_config['embedding_size']\n",
        "#         self.encoder_rnn_hidden_size = self.model_config['encoder_rnn_hidden_size']\n",
        "#         self.action_scorer_hidden_dim = self.model_config['action_scorer_hidden_dim']\n",
        "#         self.dropout_between_rnn_layers = self.model_config['dropout_between_rnn_layers']\n",
        "        self.bert_model = self.model_config['bert_model']\n",
        "        self.layer_index = self.model_config['layer_index']\n",
        "        self.action_scorer_hidden_dim = self.model_config['action_scorer_hidden_dim']\n",
        "        self.train_bert = self.model_config['train_bert']\n",
        "        \n",
        "    def _def_layers(self):\n",
        "\n",
        "        # word embeddings\n",
        "#         self.word_embedding = Embedding(embedding_size=self.embedding_size,\n",
        "#                                         vocab_size=self.word_vocab_size,\n",
        "#                                         enable_cuda=self.enable_cuda)\n",
        "\n",
        "#         # lstm encoder\n",
        "#         self.encoder = FastUniLSTM(ninp=self.embedding_size,\n",
        "#                                    nhids=self.encoder_rnn_hidden_size,\n",
        "#                                    dropout_between_rnn_layers=self.dropout_\n",
        "        self.encoder = BertModel.from_pretrained(self.bert_model).to(self.device)\n",
        "        if not self.train_bert:\n",
        "          freeze_layer(self.encoder)\n",
        "        # only for base models\n",
        "        # for large models is \n",
        "        bert_embeddings = 768\n",
        "\n",
        "        self.action_scorer_shared = torch.nn.Linear(bert_embeddings, self.action_scorer_hidden_dim)\n",
        "        action_scorers = []\n",
        "        for _ in range(self.generate_length):\n",
        "            action_scorers.append(torch.nn.Linear(self.action_scorer_hidden_dim, self.word_vocab_size, bias=False))\n",
        "        self.action_scorers = torch.nn.ModuleList(action_scorers)\n",
        "        self.fake_recurrent_mask = None\n",
        "\n",
        "    def init_weights(self):\n",
        "        torch.nn.init.xavier_uniform_(self.action_scorer_shared.weight.data)\n",
        "        for i in range(len(self.action_scorers)):\n",
        "            torch.nn.init.xavier_uniform_(self.action_scorers[i].weight.data)\n",
        "        self.action_scorer_shared.bias.data.fill_(0)\n",
        "\n",
        "    def representation_generator(self, ids, mask):\n",
        "        ids = ids.to(self.device)\n",
        "        mask = mask.to(self.device)\n",
        "        \n",
        "        layers, _ = self.encoder(ids, attention_mask=mask)\n",
        "#         encoding_sequence = layers[self.layer_index]\n",
        "#         print('layer length: ', len(layers))\n",
        "        encoding_sequence = layers[-2].type(torch.FloatTensor)\n",
        "        encoding_sequence = encoding_sequence.to(self.device)\n",
        "    \n",
        "#         print('encoding_sequence: ', type(encoding_sequence))\n",
        "#         print('encoding_sequence: ', encoding_sequence)\n",
        "        mask = mask.type(torch.FloatTensor).to(self.device)\n",
        "#         print('mask: ', type(mask))\n",
        "#         print('mask: ', mask)\n",
        "        \n",
        "#         embeddings, mask = self.word_embedding.forward(_input_words)  # batch x time x emb\n",
        "#         encoding_sequence, _, _ = self.encoder.forward(embeddings, mask)  # batch x time x h\n",
        "        res_mean = masked_mean(encoding_sequence, mask)  # batch x h\n",
        "        del layers\n",
        "        del encoding_sequence\n",
        "        del mask\n",
        "        \n",
        "        return res_mean\n",
        "\n",
        "\n",
        "    def action_scorer(self, state_representation):\n",
        "        hidden = self.action_scorer_shared.forward(state_representation)  # batch x hid\n",
        "        hidden = F.relu(hidden)  # batch x hid\n",
        "        action_ranks = []\n",
        "        for i in range(len(self.action_scorers)):\n",
        "            action_ranks.append(self.action_scorers[i].forward(hidden))  # batch x n_vocab\n",
        "        del hidden\n",
        "        return action_ranks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcGhySILtg5T",
        "colab_type": "text"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jF57tZRBzMa8",
        "colab": {}
      },
      "source": [
        "# a snapshot of state to be stored in replay memory\n",
        "Transition = namedtuple('Transition', ('bert_ids', 'bert_masks',\n",
        "                                       'word_indices',\n",
        "                                       'reward', 'mask', 'done',\n",
        "                                       'next_bert_ids', 'next_bert_masks',\n",
        "                                       'next_word_masks'))\n",
        "\n",
        "\n",
        "class HistoryScoreCache(object):\n",
        "\n",
        "    def __init__(self, capacity=1):\n",
        "        self.capacity = capacity\n",
        "        self.reset()\n",
        "\n",
        "    def push(self, stuff):\n",
        "        \"\"\"stuff is float.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(stuff)\n",
        "        else:\n",
        "            self.memory = self.memory[1:] + [stuff]\n",
        "\n",
        "    def get_avg(self):\n",
        "        return np.mean(np.array(self.memory))\n",
        "\n",
        "    def reset(self):\n",
        "        self.memory = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "\n",
        "class PrioritizedReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity=100000, priority_fraction=0.0):\n",
        "        # prioritized replay memory\n",
        "        self.priority_fraction = priority_fraction\n",
        "        self.alpha_capacity = int(capacity * priority_fraction)\n",
        "        self.beta_capacity = capacity - self.alpha_capacity\n",
        "        self.alpha_memory, self.beta_memory = [], []\n",
        "        self.alpha_position, self.beta_position = 0, 0\n",
        "\n",
        "    def push(self, is_prior=False, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if self.priority_fraction == 0.0:\n",
        "            is_prior = False\n",
        "        if is_prior:\n",
        "            if len(self.alpha_memory) < self.alpha_capacity:\n",
        "                self.alpha_memory.append(None)\n",
        "            self.alpha_memory[self.alpha_position] = Transition(*args)\n",
        "            self.alpha_position = (self.alpha_position + 1) % self.alpha_capacity\n",
        "        else:\n",
        "            if len(self.beta_memory) < self.beta_capacity:\n",
        "                self.beta_memory.append(None)\n",
        "            self.beta_memory[self.beta_position] = Transition(*args)\n",
        "            self.beta_position = (self.beta_position + 1) % self.beta_capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        if self.priority_fraction == 0.0:\n",
        "            from_beta = min(batch_size, len(self.beta_memory))\n",
        "            res = random.sample(self.beta_memory, from_beta)\n",
        "        else:\n",
        "            from_alpha = min(int(self.priority_fraction * batch_size), len(self.alpha_memory))\n",
        "            from_beta = min(batch_size - int(self.priority_fraction * batch_size), len(self.beta_memory))\n",
        "            res = random.sample(self.alpha_memory, from_alpha) + random.sample(self.beta_memory, from_beta)\n",
        "        random.shuffle(res)\n",
        "        return res\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.alpha_memory) + len(self.beta_memory)\n",
        "\n",
        "\n",
        "class CustomAgent:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            word_vocab: List of words supported.\n",
        "        \"\"\"\n",
        "        self.mode = \"train\"\n",
        "        with open(\"./vocab.txt\") as f:\n",
        "            self.word_vocab = f.read().split(\"\\n\")\n",
        "        with open(\"config.yaml\") as reader:\n",
        "            self.config = yaml.safe_load(reader)\n",
        "        self.word2id = {}\n",
        "        for i, w in enumerate(self.word_vocab):\n",
        "            self.word2id[w] = i\n",
        "        self.EOS_id = self.word2id[\"</S>\"]\n",
        "\n",
        "        self.batch_size = self.config['training']['batch_size']\n",
        "        self.max_nb_steps_per_episode = self.config['training']['max_nb_steps_per_episode']\n",
        "        self.nb_epochs = self.config['training']['nb_epochs']\n",
        "\n",
        "        # Set the random seed manually for reproducibility.\n",
        "        np.random.seed(self.config['general']['random_seed'])\n",
        "        torch.manual_seed(self.config['general']['random_seed'])\n",
        "        if torch.cuda.is_available():\n",
        "            if not self.config['general']['use_cuda']:\n",
        "                print(\"WARNING: CUDA device detected but 'use_cuda: false' found in config.yaml\")\n",
        "                self.use_cuda = False\n",
        "            else:\n",
        "                torch.backends.cudnn.deterministic = True\n",
        "                torch.cuda.manual_seed(self.config['general']['random_seed'])\n",
        "                self.use_cuda = True\n",
        "        else:\n",
        "            self.use_cuda = False\n",
        "\n",
        "        self.model = Bert_DQN(model_config=self.config[\"model\"],\n",
        "                              word_vocab=self.word_vocab,\n",
        "                              enable_cuda=self.use_cuda)\n",
        "\n",
        "        self.experiment_tag = self.config['checkpoint']['experiment_tag']\n",
        "        self.model_checkpoint_path = self.config['checkpoint']['model_checkpoint_path']\n",
        "        self.save_frequency = self.config['checkpoint']['save_frequency']\n",
        "\n",
        "        if self.config['checkpoint']['load_pretrained']:\n",
        "            self.load_pretrained_model(self.model_checkpoint_path + '/' + self.config['checkpoint']['pretrained_experiment_tag'] + '.pt')\n",
        "        if self.use_cuda:\n",
        "            self.model.cuda()\n",
        "\n",
        "        self.replay_batch_size = self.config['general']['replay_batch_size']\n",
        "        self.replay_memory = PrioritizedReplayMemory(self.config['general']['replay_memory_capacity'],\n",
        "                                                     priority_fraction=self.config['general']['replay_memory_priority_fraction'])\n",
        "\n",
        "        # optimizer\n",
        "        parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
        "        self.optimizer = torch.optim.Adam(parameters, lr=self.config['training']['optimizer']['learning_rate'])\n",
        "\n",
        "        # epsilon greedy\n",
        "        self.epsilon_anneal_episodes = self.config['general']['epsilon_anneal_episodes']\n",
        "        self.epsilon_anneal_from = self.config['general']['epsilon_anneal_from']\n",
        "        self.epsilon_anneal_to = self.config['general']['epsilon_anneal_to']\n",
        "        self.epsilon = self.epsilon_anneal_from\n",
        "        self.update_per_k_game_steps = self.config['general']['update_per_k_game_steps']\n",
        "        self.clip_grad_norm = self.config['training']['optimizer']['clip_grad_norm']\n",
        "\n",
        "        self.nlp = spacy.load('en', disable=['ner', 'parser', 'tagger'])\n",
        "        self.preposition_map = {\"take\": \"from\",\n",
        "                                \"chop\": \"with\",\n",
        "                                \"slice\": \"with\",\n",
        "                                \"dice\": \"with\",\n",
        "                                \"cook\": \"with\",\n",
        "                                \"insert\": \"into\",\n",
        "                                \"put\": \"on\"}\n",
        "        self.single_word_verbs = set([\"inventory\", \"look\"])\n",
        "        self.discount_gamma = self.config['general']['discount_gamma']\n",
        "        self.current_episode = 0\n",
        "        self.current_step = 0\n",
        "        self._epsiode_has_started = False\n",
        "        self.history_avg_scores = HistoryScoreCache(capacity=1000)\n",
        "        self.best_avg_score_so_far = 0.0\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Tell the agent that it's training phase.\n",
        "        \"\"\"\n",
        "        self.mode = \"train\"\n",
        "        self.model.train()\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"\n",
        "        Tell the agent that it's evaluation phase.\n",
        "        \"\"\"\n",
        "        self.mode = \"eval\"\n",
        "        self.model.eval()\n",
        "\n",
        "    def _start_episode(self, obs: List[str], infos: Dict[str, List[Any]]) -> None:\n",
        "        \"\"\"\n",
        "        Prepare the agent for the upcoming episode.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Initial feedback for each game.\n",
        "            infos: Additional information for each game.\n",
        "        \"\"\"\n",
        "        self.init(obs, infos)\n",
        "        self._epsiode_has_started = True\n",
        "\n",
        "    def _end_episode(self, obs: List[str], scores: List[int], infos: Dict[str, List[Any]]) -> None:\n",
        "        \"\"\"\n",
        "        Tell the agent the episode has terminated.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            score: The score obtained so far for each game.\n",
        "            infos: Additional information for each game.\n",
        "        \"\"\"\n",
        "        self.finish()\n",
        "        self._epsiode_has_started = False\n",
        "\n",
        "    def load_pretrained_model(self, load_from):\n",
        "        \"\"\"\n",
        "        Load pretrained checkpoint from file.\n",
        "\n",
        "        Arguments:\n",
        "            load_from: File name of the pretrained model checkpoint.\n",
        "        \"\"\"\n",
        "        print(\"loading model from %s\\n\" % (load_from))\n",
        "        try:\n",
        "            if self.use_cuda:\n",
        "                state_dict = torch.load(load_from)\n",
        "            else:\n",
        "                state_dict = torch.load(load_from, map_location='cpu')\n",
        "            self.model.load_state_dict(state_dict)\n",
        "        except:\n",
        "            print(\"Failed to load checkpoint...\")\n",
        "\n",
        "    def select_additional_infos(self) -> EnvInfos:\n",
        "        \"\"\"\n",
        "        Returns what additional information should be made available at each game step.\n",
        "\n",
        "        Requested information will be included within the `infos` dictionary\n",
        "        passed to `CustomAgent.act()`. To request specific information, create a\n",
        "        :py:class:`textworld.EnvInfos <textworld.envs.wrappers.filter.EnvInfos>`\n",
        "        and set the appropriate attributes to `True`. The possible choices are:\n",
        "\n",
        "        * `description`: text description of the current room, i.e. output of the `look` command;\n",
        "        * `inventory`: text listing of the player's inventory, i.e. output of the `inventory` command;\n",
        "        * `max_score`: maximum reachable score of the game;\n",
        "        * `objective`: objective of the game described in text;\n",
        "        * `entities`: names of all entities in the game;\n",
        "        * `verbs`: verbs understood by the the game;\n",
        "        * `command_templates`: templates for commands understood by the the game;\n",
        "        * `admissible_commands`: all commands relevant to the current state;\n",
        "\n",
        "        In addition to the standard information, game specific information\n",
        "        can be requested by appending corresponding strings to the `extras`\n",
        "        attribute. For this competition, the possible extras are:\n",
        "\n",
        "        * `'recipe'`: description of the cookbook;\n",
        "        * `'walkthrough'`: one possible solution to the game (not guaranteed to be optimal);\n",
        "\n",
        "        Example:\n",
        "            Here is an example of how to request information and retrieve it.\n",
        "\n",
        "            >>> from textworld import EnvInfos\n",
        "            >>> request_infos = EnvInfos(description=True, inventory=True, extras=[\"recipe\"])\n",
        "            ...\n",
        "            >>> env = gym.make(env_id)\n",
        "            >>> ob, infos = env.reset()\n",
        "            >>> print(infos[\"description\"])\n",
        "            >>> print(infos[\"inventory\"])\n",
        "            >>> print(infos[\"extra.recipe\"])\n",
        "\n",
        "        Notes:\n",
        "            The following information *won't* be available at test time:\n",
        "\n",
        "            * 'walkthrough'\n",
        "        \"\"\"\n",
        "        request_infos = EnvInfos()\n",
        "        request_infos.description = True\n",
        "        request_infos.inventory = True\n",
        "        request_infos.entities = True\n",
        "        request_infos.verbs = True\n",
        "        request_infos.extras = [\"recipe\"]\n",
        "        return request_infos\n",
        "\n",
        "    def init(self, obs: List[str], infos: Dict[str, List[Any]]):\n",
        "        \"\"\"\n",
        "        Prepare the agent for the upcoming games.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            infos: Additional information for each game.\n",
        "        \"\"\"\n",
        "        # reset agent, get vocabulary masks for verbs / adjectives / nouns\n",
        "        self.scores = []\n",
        "        self.dones = []\n",
        "        self.prev_actions = [\"\" for _ in range(len(obs))]\n",
        "        # get word masks\n",
        "        batch_size = len(infos[\"verbs\"])\n",
        "        verbs_word_list = infos[\"verbs\"]\n",
        "        noun_word_list, adj_word_list = [], []\n",
        "        for entities in infos[\"entities\"]:\n",
        "            tmp_nouns, tmp_adjs = [], []\n",
        "            for name in entities:\n",
        "                split = name.split()\n",
        "                tmp_nouns.append(split[-1])\n",
        "                if len(split) > 1:\n",
        "                    tmp_adjs += split[:-1]\n",
        "            noun_word_list.append(list(set(tmp_nouns)))\n",
        "            adj_word_list.append(list(set(tmp_adjs)))\n",
        "\n",
        "        verb_mask = np.zeros((batch_size, len(self.word_vocab)), dtype=\"float32\")\n",
        "        noun_mask = np.zeros((batch_size, len(self.word_vocab)), dtype=\"float32\")\n",
        "        adj_mask = np.zeros((batch_size, len(self.word_vocab)), dtype=\"float32\")\n",
        "        for i in range(batch_size):\n",
        "            for w in verbs_word_list[i]:\n",
        "                if w in self.word2id:\n",
        "                    verb_mask[i][self.word2id[w]] = 1.0\n",
        "            for w in noun_word_list[i]:\n",
        "                if w in self.word2id:\n",
        "                    noun_mask[i][self.word2id[w]] = 1.0\n",
        "            for w in adj_word_list[i]:\n",
        "                if w in self.word2id:\n",
        "                    adj_mask[i][self.word2id[w]] = 1.0\n",
        "        second_noun_mask = copy.copy(noun_mask)\n",
        "        second_adj_mask = copy.copy(adj_mask)\n",
        "        second_noun_mask[:, self.EOS_id] = 1.0\n",
        "        adj_mask[:, self.EOS_id] = 1.0\n",
        "        second_adj_mask[:, self.EOS_id] = 1.0\n",
        "        self.word_masks_np = [verb_mask, adj_mask, noun_mask, second_adj_mask, second_noun_mask]\n",
        "\n",
        "        self.cache_chosen_indices = None\n",
        "        self.current_step = 0\n",
        "\n",
        "    def get_game_step_info(self, obs: List[str], infos: Dict[str, List[Any]]):\n",
        "        \"\"\"\n",
        "        Get all the available information, and concat them together to be tensor for\n",
        "        a neural model. we use post padding here, all information are tokenized here.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            infos: Additional information for each game.\n",
        "        \"\"\"\n",
        "#         print('inventory: ', len(infos['inventory']))\n",
        "#         print('obs: ', len(obs))\n",
        "#         print('recipees: ', len(infos['extra.recipe']))\n",
        "#         print('descriptions: ', len(infos['description']))\n",
        "#-----------------------------------------------------------------------------------------------\n",
        "#         inventory_token_list = [preproc(item, tokenizer=self.nlp) for item in infos[\"inventory\"]]\n",
        "#         inventory_id_list = [_words_to_ids(tokens, self.word2id) for tokens in inventory_token_list]\n",
        "\n",
        "#         feedback_token_list = [preproc(item, str_type='feedback', tokenizer=self.nlp) for item in obs]\n",
        "#         feedback_id_list = [_words_to_ids(tokens, self.word2id) for tokens in feedback_token_list]\n",
        "\n",
        "#         quest_token_list = [preproc(item, tokenizer=self.nlp) for item in infos[\"extra.recipe\"]]\n",
        "#         quest_id_list = [_words_to_ids(tokens, self.word2id) for tokens in quest_token_list]\n",
        "\n",
        "#         prev_action_token_list = [preproc(item, tokenizer=self.nlp) for item in self.prev_actions]\n",
        "#         prev_action_id_list = [_words_to_ids(tokens, self.word2id) for tokens in prev_action_token_list]\n",
        "\n",
        "#         description_token_list = [preproc(item, tokenizer=self.nlp) for item in infos[\"description\"]]\n",
        "#         for i, d in enumerate(description_token_list):\n",
        "#             if len(d) == 0:\n",
        "#                 description_token_list[i] = [\"end\"]  # if empty description, insert word \"end\"\n",
        "#         description_id_list = [_words_to_ids(tokens, self.word2id) for tokens in description_token_list]\n",
        "#         description_id_list = [_d + _i + _q + _f + _pa for (_d, _i, _q, _f, _pa) in zip(description_id_list, inventory_id_list, quest_id_list, feedback_id_list, prev_action_id_list)]\n",
        "\n",
        "#         input_description = pad_sequences(description_id_list, maxlen=max_len(description_id_list)).astype('int32')\n",
        "#         input_description = to_pt(input_description, self.use_cuda)\n",
        "#-----------------------------------------------------------------------------------------------    \n",
        "        sep = ' [SEP] '\n",
        "        description_text_list = [_d + sep + _i + sep + _q + sep + _f + sep + _pa for (_d, _i, _q, _f, _pa) \n",
        "                                  in zip(infos['description'], infos['inventory'], infos['extra.recipe'], obs, self.prev_actions)]\n",
        "\n",
        "        _, bert_ids, bert_mask  = convert_examples_to_features(description_text_list, self.model.tokenizer)\n",
        "#         del inventory_token_list\n",
        "#         del inventory_id_list\n",
        "#         del feedback_token_list\n",
        "#         del feedback_id_list\n",
        "#         del quest_token_list\n",
        "#         del quest_id_list\n",
        "#         del prev_action_token_list\n",
        "#         del prev_action_id_list\n",
        "#         del description_token_list\n",
        "#         del description_id_list\n",
        "        del description_text_list\n",
        "        \n",
        "        return bert_ids, bert_mask\n",
        "\n",
        "    def word_ids_to_commands(self, verb, adj, noun, adj_2, noun_2):\n",
        "        \"\"\"\n",
        "        Turn the 5 indices into actual command strings.\n",
        "\n",
        "        Arguments:\n",
        "            verb: Index of the guessing verb in vocabulary\n",
        "            adj: Index of the guessing adjective in vocabulary\n",
        "            noun: Index of the guessing noun in vocabulary\n",
        "            adj_2: Index of the second guessing adjective in vocabulary\n",
        "            noun_2: Index of the second guessing noun in vocabulary\n",
        "        \"\"\"\n",
        "        # turns 5 indices into actual command strings\n",
        "        if self.word_vocab[verb] in self.single_word_verbs:\n",
        "            return self.word_vocab[verb]\n",
        "        if adj == self.EOS_id:\n",
        "            res = self.word_vocab[verb] + \" \" + self.word_vocab[noun]\n",
        "        else:\n",
        "            res = self.word_vocab[verb] + \" \" + self.word_vocab[adj] + \" \" + self.word_vocab[noun]\n",
        "        if self.word_vocab[verb] not in self.preposition_map:\n",
        "            return res\n",
        "        if noun_2 == self.EOS_id:\n",
        "            return res\n",
        "        prep = self.preposition_map[self.word_vocab[verb]]\n",
        "        if adj_2 == self.EOS_id:\n",
        "            res = res + \" \" + prep + \" \" + self.word_vocab[noun_2]\n",
        "        else:\n",
        "            res =  res + \" \" + prep + \" \" + self.word_vocab[adj_2] + \" \" + self.word_vocab[noun_2]\n",
        "        return res\n",
        "\n",
        "    def get_chosen_strings(self, chosen_indices):\n",
        "        \"\"\"\n",
        "        Turns list of word indices into actual command strings.\n",
        "\n",
        "        Arguments:\n",
        "            chosen_indices: Word indices chosen by model.\n",
        "        \"\"\"\n",
        "        chosen_indices_np = [to_np(item)[:, 0] for item in chosen_indices]\n",
        "        res_str = []\n",
        "        batch_size = chosen_indices_np[0].shape[0]\n",
        "        for i in range(batch_size):\n",
        "          verb, adj, noun, adj_2, noun_2 = chosen_indices_np[0][i],\\\n",
        "                                           chosen_indices_np[1][i],\\\n",
        "                                           chosen_indices_np[2][i],\\\n",
        "                                           chosen_indices_np[3][i],\\\n",
        "                                           chosen_indices_np[4][i]\n",
        "          res_str.append(self.word_ids_to_commands(verb, adj, noun, adj_2, noun_2))\n",
        "          del verb\n",
        "          del adj\n",
        "          del noun\n",
        "          del adj_2\n",
        "          del noun_2\n",
        "            \n",
        "        del chosen_indices_np\n",
        "        return res_str\n",
        "\n",
        "    def choose_random_command(self, word_ranks, word_masks_np):\n",
        "        \"\"\"\n",
        "        Generate a command randomly, for epsilon greedy.\n",
        "\n",
        "        Arguments:\n",
        "            word_ranks: Q values for each word by model.action_scorer.\n",
        "            word_masks_np: Vocabulary masks for words depending on their type (verb, adj, noun).\n",
        "        \"\"\"\n",
        "        batch_size = word_ranks[0].size(0)\n",
        "        word_ranks_np = [to_np(item) for item in word_ranks]  # list of batch x n_vocab\n",
        "        word_ranks_np = [r * m for r, m in zip(word_ranks_np, word_masks_np)]  # list of batch x n_vocab\n",
        "        word_indices = []\n",
        "        for i in range(len(word_ranks_np)):\n",
        "          indices = []\n",
        "          for j in range(batch_size):\n",
        "              msk = word_masks_np[i][j]  # vocab\n",
        "              indices.append(np.random.choice(len(msk), p=msk / np.sum(msk, -1)))\n",
        "              del msk\n",
        "          word_indices.append(np.array(indices))\n",
        "          del indices\n",
        "        # word_indices: list of batch\n",
        "        word_qvalues = [[] for _ in word_masks_np]\n",
        "        for i in range(batch_size):\n",
        "            for j in range(len(word_qvalues)):\n",
        "                word_qvalues[j].append(word_ranks[j][i][word_indices[j][i]])\n",
        "        word_qvalues = [torch.stack(item) for item in word_qvalues]\n",
        "        word_indices = [to_pt(item, self.use_cuda) for item in word_indices]\n",
        "        word_indices = [item.unsqueeze(-1) for item in word_indices]  # list of batch x 1\n",
        "        \n",
        "        del word_ranks_np\n",
        "        \n",
        "        return word_qvalues, word_indices\n",
        "\n",
        "    def choose_maxQ_command(self, word_ranks, word_masks_np):\n",
        "        \"\"\"\n",
        "        Generate a command by maximum q values, for epsilon greedy.\n",
        "\n",
        "        Arguments:\n",
        "            word_ranks: Q values for each word by model.action_scorer.\n",
        "            word_masks_np: Vocabulary masks for words depending on their type (verb, adj, noun).\n",
        "        \"\"\"\n",
        "        batch_size = word_ranks[0].size(0)\n",
        "        word_ranks_np = [to_np(item) for item in word_ranks]  # list of batch x n_vocab\n",
        "        word_ranks_np = [r - np.min(r) for r in word_ranks_np] # minus the min value, so that all values are non-negative\n",
        "        word_ranks_np = [r * m for r, m in zip(word_ranks_np, word_masks_np)]  # list of batch x n_vocab\n",
        "        word_indices = [np.argmax(item, -1) for item in word_ranks_np]  # list of batch\n",
        "        word_qvalues = [[] for _ in word_masks_np]\n",
        "        for i in range(batch_size):\n",
        "            for j in range(len(word_qvalues)):\n",
        "                word_qvalues[j].append(word_ranks[j][i][word_indices[j][i]])\n",
        "        word_qvalues = [torch.stack(item) for item in word_qvalues]\n",
        "        word_indices = [to_pt(item, self.use_cuda) for item in word_indices]\n",
        "        word_indices = [item.unsqueeze(-1) for item in word_indices]  # list of batch x 1\n",
        "        \n",
        "        del word_ranks_np\n",
        "        \n",
        "        return word_qvalues, word_indices\n",
        "\n",
        "      \n",
        "#     torch.Size([16, 227])\n",
        "#     torch.Size([16, 227])\n",
        "#     torch.Size([16, 768])\n",
        "#     5\n",
        "#     torch.Size([16, 20200])\n",
        "\n",
        "# 16\n",
        "# 5\n",
        "# torch.Size([1, 20200])\n",
        "    def get_ranks(self, bert_ids, bert_masks):\n",
        "        \"\"\"\n",
        "        Given input description tensor, call model forward, to get Q values of words.\n",
        "\n",
        "        Arguments:\n",
        "            input_description: Input tensors, which include all the information chosen in\n",
        "            select_additional_infos() concatenated together.\n",
        "        \"\"\"\n",
        "#         word_ranks_arr = []\n",
        "#         for x in range(len(bert_ids)):\n",
        "#           bert_ids_single =  torch.tensor([bert_ids[x]], dtype=torch.long)\n",
        "#           bert_masks_single = torch.tensor([bert_masks[x]], dtype=torch.long)\n",
        "#           state_representation_single = self.model.representation_generator(bert_ids_single, bert_masks_single)\n",
        "#           del bert_ids_single\n",
        "#           del bert_masks_single\n",
        "#           word_ranks_arr.append(self.model.action_scorer(state_representation_single))\n",
        "# #           print(len(word_ranks_arr))\n",
        "# #           print(len(word_ranks_arr[0]))\n",
        "# #           print(word_ranks_arr[0][0].shape)\n",
        "#           del state_representation_single\n",
        "#         word_ranks = word_ranks_arr[0]\n",
        "#         for x in range(len(word_ranks_arr) - 1):\n",
        "#           for y in range(len(word_ranks_arr[x + 1])):\n",
        "#             word_ranks[y] = torch.cat((word_ranks[y], word_ranks_arr[x + 1][y]), dim=0)\n",
        "#         del word_ranks_arr\n",
        "          \n",
        "        bert_ids = torch.tensor([x for x in bert_ids], dtype=torch.long)\n",
        "        bert_masks = torch.tensor([x for x in bert_masks], dtype=torch.long)\n",
        "#         print(bert_ids.shape)\n",
        "#         print(bert_masks.shape)\n",
        "        state_representation = self.model.representation_generator(bert_ids, bert_masks)\n",
        "#         print(state_representation.shape)\n",
        "        del bert_ids\n",
        "        del bert_masks\n",
        "        \n",
        "        word_ranks = self.model.action_scorer(state_representation)  # each element in list has batch x n_vocab size\n",
        "#         print(len(word_ranks))\n",
        "#         print(word_ranks[0].shape)\n",
        "        del state_representation\n",
        "        return word_ranks\n",
        "\n",
        "    def act_eval(self, obs: List[str], scores: List[int], dones: List[bool], infos: Dict[str, List[Any]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Acts upon the current list of observations, during evaluation.\n",
        "\n",
        "        One text command must be returned for each observation.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            score: The score obtained so far for each game (at previous step).\n",
        "            done: Whether a game is finished (at previous step).\n",
        "            infos: Additional information for each game.\n",
        "\n",
        "        Returns:\n",
        "            Text commands to be performed (one per observation).\n",
        "\n",
        "        Notes:\n",
        "            Commands returned for games marked as `done` have no effect.\n",
        "            The states for finished games are simply copy over until all\n",
        "            games are done, in which case `CustomAgent.finish()` is called\n",
        "            instead.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.current_step > 0:\n",
        "            # append scores / dones from previous step into memory\n",
        "            self.scores.append(scores)\n",
        "            self.dones.append(dones)\n",
        "\n",
        "        if all(dones):\n",
        "            self._end_episode(obs, scores, infos)\n",
        "            return  # Nothing to return.\n",
        "\n",
        "        bert_ids, bert_masks = self.get_game_step_infoget_game_step_info(obs, infos)\n",
        "        word_ranks = self.get_ranks(bert_ids, bert_masks)  # list of batch x vocab\n",
        "        \n",
        "        del bert_ids\n",
        "        del bert_masks\n",
        "        \n",
        "        _, word_indices_maxq = self.choose_maxQ_command(word_ranks, self.word_masks_np)\n",
        "\n",
        "        chosen_indices = word_indices_maxq\n",
        "        chosen_indices = [item.detach() for item in chosen_indices]\n",
        "        chosen_strings = self.get_chosen_strings(chosen_indices)\n",
        "        self.prev_actions = chosen_strings\n",
        "        self.current_step += 1\n",
        "        \n",
        "        del word_indices_max_q\n",
        "        \n",
        "        return chosen_strings\n",
        "\n",
        "    def act(self, obs: List[str], scores: List[int], dones: List[bool], infos: Dict[str, List[Any]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Acts upon the current list of observations.\n",
        "\n",
        "        One text command must be returned for each observation.\n",
        "\n",
        "        Arguments:\n",
        "            obs: Previous command's feedback for each game.\n",
        "            score: The score obtained so far for each game (at previous step).\n",
        "            done: Whether a game is finished (at previous step).\n",
        "            infos: Additional information for each game.\n",
        "\n",
        "        Returns:\n",
        "            Text commands to be performed (one per observation).\n",
        "\n",
        "        Notes:\n",
        "            Commands returned for games marked as `done` have no effect.\n",
        "            The states for finished games are simply copy over until all\n",
        "            games are done, in which case `CustomAgent.finish()` is called\n",
        "            instead.\n",
        "        \"\"\"\n",
        "        if not self._epsiode_has_started:\n",
        "            self._start_episode(obs, infos)\n",
        "\n",
        "        if self.mode == \"eval\":\n",
        "            return self.act_eval(obs, scores, dones, infos)\n",
        "\n",
        "        if self.current_step > 0:\n",
        "            # append scores / dones from previous step into memory\n",
        "            self.scores.append(scores)\n",
        "            self.dones.append(dones)\n",
        "            # compute previous step's rewards and masks\n",
        "            rewards_np, rewards, mask_np, mask = self.compute_reward()\n",
        "\n",
        "        bert_ids, bert_masks = self.get_game_step_info(obs, infos)\n",
        "        # generate commands for one game step, epsilon greedy is applied, i.e.,\n",
        "        # there is epsilon of chance to generate random commands\n",
        "        word_ranks = self.get_ranks(bert_ids, bert_masks)  # list of batch x vocab\n",
        "        _, word_indices_maxq = self.choose_maxQ_command(word_ranks, self.word_masks_np)\n",
        "        _, word_indices_random = self.choose_random_command(word_ranks, self.word_masks_np)\n",
        "        # random number for epsilon greedy\n",
        "        rand_num = np.random.uniform(low=0.0, high=1.0, size=(len(bert_ids), 1))\n",
        "        less_than_epsilon = (rand_num < self.epsilon).astype(\"float32\")  # batch\n",
        "        greater_than_epsilon = 1.0 - less_than_epsilon\n",
        "        less_than_epsilon = to_pt(less_than_epsilon, self.use_cuda, type='float')\n",
        "        greater_than_epsilon = to_pt(greater_than_epsilon, self.use_cuda, type='float')\n",
        "        less_than_epsilon, greater_than_epsilon = less_than_epsilon.long(), greater_than_epsilon.long()\n",
        "\n",
        "        chosen_indices = [less_than_epsilon * idx_random + greater_than_epsilon * idx_maxq for idx_random, idx_maxq in zip(word_indices_random, word_indices_maxq)]\n",
        "        chosen_indices = [item.detach() for item in chosen_indices]\n",
        "        chosen_strings = self.get_chosen_strings(chosen_indices)\n",
        "        self.prev_actions = chosen_strings\n",
        "        \n",
        "\n",
        "        # push info from previous game step into replay memory\n",
        "        if self.current_step > 0:\n",
        "            for b in range(len(obs)):\n",
        "                if mask_np[b] == 0:\n",
        "                    continue\n",
        "                is_prior = rewards_np[b] > 0.0\n",
        "                self.replay_memory.push(is_prior,*(self.cache_bert_ids[b],\n",
        "                                        self.cache_bert_masks[b],\n",
        "                                        [item[b] for item in self.cache_chosen_indices], \n",
        "                                        rewards[b], \n",
        "                                        mask[b], \n",
        "                                        dones[b],\n",
        "                                        bert_ids[b],\n",
        "                                        bert_masks[b],\n",
        "                                        [item[b] for item in self.word_masks_np]))\n",
        "\n",
        "        # cache new info in current game step into caches\n",
        "        self.cache_chosen_indices = chosen_indices\n",
        "        self.cache_bert_ids = bert_ids\n",
        "        self.cache_bert_masks = bert_masks\n",
        "\n",
        "        # update neural model by replaying snapshots in replay memory\n",
        "        #fix update\n",
        "        if self.current_step > 0 and self.current_step % self.update_per_k_game_steps == 0:\n",
        "          loss = self.update()\n",
        "          if loss is not None:\n",
        "              # Backpropagate\n",
        "              self.optimizer.zero_grad()\n",
        "              loss.backward(retain_graph=True)\n",
        "              # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "              torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_grad_norm)\n",
        "              self.optimizer.step()  # apply gradients\n",
        "          \n",
        "           \n",
        "\n",
        "        self.current_step += 1\n",
        "\n",
        "        if all(dones):\n",
        "            self._end_episode(obs, scores, infos)\n",
        "            return  # Nothing to return.\n",
        "        return chosen_strings\n",
        "\n",
        "    def compute_reward(self):\n",
        "        \"\"\"\n",
        "        Compute rewards by agent. Note this is different from what the training/evaluation\n",
        "        scripts do. Agent keeps track of scores and other game information for training purpose.\n",
        "\n",
        "        \"\"\"\n",
        "        # mask = 1 if game is not finished or just finished at current step\n",
        "        if len(self.dones) == 1:\n",
        "            # it's not possible to finish a game at 0th step\n",
        "            mask = [1.0 for _ in self.dones[-1]]\n",
        "        else:\n",
        "            assert len(self.dones) > 1\n",
        "            mask = [1.0 if not self.dones[-2][i] else 0.0 for i in range(len(self.dones[-1]))]\n",
        "        mask = np.array(mask, dtype='float32')\n",
        "        mask_pt = to_pt(mask, self.use_cuda, type='float')\n",
        "        # rewards returned by game engine are always accumulated value the\n",
        "        # agent have recieved. so the reward it gets in the current game step\n",
        "        # is the new value minus values at previous step.\n",
        "        rewards = np.array(self.scores[-1], dtype='float32')  # batch\n",
        "        if len(self.scores) > 1:\n",
        "            prev_rewards = np.array(self.scores[-2], dtype='float32')\n",
        "            rewards = rewards - prev_rewards\n",
        "        rewards_pt = to_pt(rewards, self.use_cuda, type='float')\n",
        "\n",
        "        return rewards, rewards_pt, mask, mask_pt\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Update neural model in agent. In this example we follow algorithm\n",
        "        of updating model in dqn with replay memory.\n",
        "\n",
        "        \"\"\"\n",
        "        if len(self.replay_memory) < self.replay_batch_size:\n",
        "            return None\n",
        "        transitions = self.replay_memory.sample(self.replay_batch_size)\n",
        "        batch = Transition(*zip(*transitions))\n",
        "        \n",
        "        del transitions\n",
        "\n",
        "        #pyt bert_ids and bert_masks\n",
        "#         observation_id_list = pad_sequences(batch.observation_id_list, maxlen=max_len(batch.observation_id_list)).astype('int32')\n",
        "#         print(observation_id_list)\n",
        "#         input_observation = to_pt(observation_id_list, self.use_cuda)\n",
        "\n",
        "#         bert_ids = torch.tensor(batch.bert_ids, dtype=torch.long).to(self.model.device)\n",
        "#         bert_masks = torch.tensor(batch.bert_masks, dtype=torch.long).to(self.model.device)\n",
        "        bert_ids = pad_sequences(batch.bert_ids, maxlen=max_len(batch.bert_ids)).astype('int32')\n",
        "        bert_masks = pad_sequences(batch.bert_masks, maxlen=max_len(batch.bert_masks)).astype('int32')\n",
        "\n",
        "#         next_observation_id_list = pad_sequences(batch.next_observation_id_list, maxlen=max_len(batch.next_observation_id_list)).astype('int32')\n",
        "#         next_input_observation = to_pt(next_observation_id_list, self.use_cuda)\n",
        "\n",
        "#         next_bert_ids = torch.tensor(batch.next_bert_ids, dtype=torch.long).to(self.model.device)\n",
        "#         next_bert_masks = torch.tensor(batch.next_bert_masks, dtype=torch.long).to(self.model.device)\n",
        "\n",
        "        next_bert_ids = pad_sequences(batch.next_bert_ids, maxlen=max_len(batch.next_bert_ids)).astype('int32')\n",
        "        next_bert_masks = pad_sequences(batch.next_bert_masks, maxlen=max_len(batch.next_bert_masks)).astype('int32')\n",
        "\n",
        "        chosen_indices = list(list(zip(*batch.word_indices)))\n",
        "        chosen_indices = [torch.stack(item, 0) for item in chosen_indices]  # list of batch x 1\n",
        "\n",
        "        word_ranks = self.get_ranks(bert_ids, bert_masks)  # list of batch x vocab\n",
        "        \n",
        "        del bert_ids\n",
        "        del bert_masks\n",
        "        \n",
        "        word_qvalues = [w_rank.gather(1, idx).squeeze(-1) for w_rank, idx in zip(word_ranks, chosen_indices)]  # list of batch\n",
        "        \n",
        "        del chosen_indices\n",
        "        del word_ranks\n",
        "        \n",
        "        q_value = torch.mean(torch.stack(word_qvalues, -1), -1)  # batch\n",
        "        del word_qvalues\n",
        "\n",
        "        next_word_ranks = self.get_ranks(next_bert_ids, next_bert_masks)  # batch x n_verb, batch x n_noun, batchx n_second_noun\n",
        "        del next_bert_ids\n",
        "        del next_bert_masks\n",
        "        \n",
        "        next_word_masks = list(list(zip(*batch.next_word_masks)))\n",
        "        next_word_masks = [np.stack(item, 0) for item in next_word_masks]\n",
        "        next_word_qvalues, _ = self.choose_maxQ_command(next_word_ranks, next_word_masks)\n",
        "        del next_word_masks\n",
        "        del next_word_ranks\n",
        "        \n",
        "        next_q_value = torch.mean(torch.stack(next_word_qvalues, -1), -1)  # batch\n",
        "        next_q_value = next_q_value.detach()\n",
        "\n",
        "        rewards = torch.stack(batch.reward)  # batch\n",
        "        not_done = 1.0 - np.array(batch.done, dtype='float32')  # batch\n",
        "        not_done = to_pt(not_done, self.use_cuda, type='float')\n",
        "        rewards = rewards + not_done * next_q_value * self.discount_gamma  # batch\n",
        "        del not_done\n",
        "        \n",
        "        mask = torch.stack(batch.mask)  # batch\n",
        "        loss = F.smooth_l1_loss(q_value * mask, rewards * mask)\n",
        "        \n",
        "        del q_value\n",
        "        del mask\n",
        "        del rewards\n",
        "        del batch\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def finish(self) -> None:\n",
        "        \"\"\"\n",
        "        All games in the batch are finished. One can choose to save checkpoints,\n",
        "        evaluate on validation set, or do parameter annealing here.\n",
        "        \"\"\"\n",
        "        # Game has finished (either win, lose, or exhausted all the given steps).\n",
        "        self.final_rewards = np.array(self.scores[-1], dtype='float32')  # batch\n",
        "        dones = []\n",
        "        for d in self.dones:\n",
        "            d = np.array([float(dd) for dd in d], dtype='float32')\n",
        "            dones.append(d)\n",
        "        dones = np.array(dones)\n",
        "        step_used = 1.0 - dones\n",
        "        self.step_used_before_done = np.sum(step_used, 0)  # batch\n",
        "\n",
        "        self.history_avg_scores.push(np.mean(self.final_rewards))\n",
        "        # save checkpoint\n",
        "        if self.mode == \"train\" and self.current_episode % self.save_frequency == 0:\n",
        "            avg_score = self.history_avg_scores.get_avg()\n",
        "            if avg_score > self.best_avg_score_so_far:\n",
        "                self.best_avg_score_so_far = avg_score\n",
        "\n",
        "                save_to = self.model_checkpoint_path + '/' + self.experiment_tag + \"_episode_\" + str(self.current_episode) + \".pt\"\n",
        "                if not os.path.isdir(self.model_checkpoint_path):\n",
        "                    os.mkdir(self.model_checkpoint_path)\n",
        "                torch.save(self.model.state_dict(), save_to)\n",
        "                print(\"\\n========= saved checkpoint =========\")\n",
        "\n",
        "        self.current_episode += 1\n",
        "        # annealing\n",
        "        if self.current_episode < self.epsilon_anneal_episodes:\n",
        "            self.epsilon -= (self.epsilon_anneal_from - self.epsilon_anneal_to) / float(self.epsilon_anneal_episodes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHuITVpD0nAN",
        "colab_type": "text"
      },
      "source": [
        "## Setup configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9jFzEnr1zt9",
        "colab_type": "text"
      },
      "source": [
        "### Vocab\n",
        "Upload vocab.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfc78DzULeIf",
        "colab_type": "code",
        "outputId": "840c6fb2-245e-4356-e35c-15b9330b606d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "if not os.path.isfile('./vocab.txt'):\n",
        "    uploaded = files.upload()\n",
        "    # Upload vocab.txt\n",
        "    for fn in uploaded.keys():\n",
        "        print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "else:\n",
        "    print(\"Vocab already uploaded!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab already uploaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhn6sd_gLvC-",
        "colab_type": "code",
        "outputId": "38ce4f53-74fd-49ab-efd8-1ac25b9984a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "!head vocab.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD>\n",
            "<UNK>\n",
            "</S>\n",
            "<S>\n",
            "<|>\n",
            "!\n",
            "\"\n",
            "#\n",
            "$\n",
            "%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWAhh8mL2WCf",
        "colab_type": "text"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9wwaYyZkid1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#enough memory first try 3 games : epochs > 8\n",
        "# with open('./config.yaml', 'w') as config:\n",
        "#     config.write(\"\"\"general:\n",
        "#   discount_gamma: 0.5\n",
        "#   random_seed: 42\n",
        "#   use_cuda: True  # disable this when running on machine without cuda\n",
        "\n",
        "#   # replay memory\n",
        "#   replay_memory_capacity: 100000  # adjust this depending on your RAM size\n",
        "#   replay_memory_priority_fraction: 0.25\n",
        "#   update_per_k_game_steps: 20\n",
        "#   replay_batch_size: 4\n",
        "\n",
        "#   # epsilon greedy\n",
        "#   epsilon_anneal_episodes: 300  # -1 if not annealing\n",
        "#   epsilon_anneal_from: 1.0\n",
        "#   epsilon_anneal_to: 0.2\n",
        "\n",
        "# checkpoint:\n",
        "#   experiment_tag: 'starting-kit'\n",
        "#   model_checkpoint_path: './saved_models'\n",
        "#   load_pretrained: False  # during test, enable this so that the agent load your pretrained model\n",
        "#   pretrained_experiment_tag: 'starting-kit'\n",
        "#   save_frequency: 100\n",
        "\n",
        "# training:\n",
        "#   batch_size: 1\n",
        "#   nb_epochs: 100\n",
        "#   max_nb_steps_per_episode: 100  # after this many steps, a game is terminated\n",
        "#   optimizer:\n",
        "#     step_rule: 'adam'  # adam\n",
        "#     learning_rate: 0.001\n",
        "#     clip_grad_norm: 5\n",
        "\n",
        "# model:\n",
        "#   embedding_size: 32\n",
        "#   encoder_rnn_hidden_size: [32]\n",
        "#   action_scorer_hidden_dim: 16\n",
        "#   dropout_between_rnn_layers: 0.\n",
        "#   bert_model: 'bert-base-uncased'\n",
        "#   layer_index: 11\n",
        "# \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyvrcvxpp2FN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# second try 3 games 7-8 epochs max\n",
        "# with open('./config.yaml', 'w') as config:\n",
        "#     config.write(\"\"\"general:\n",
        "#   discount_gamma: 0.7\n",
        "#   random_seed: 42\n",
        "#   use_cuda: True  # disable this when running on machine without cuda\n",
        "\n",
        "#   # replay memory\n",
        "#   replay_memory_capacity: 100000  # adjust this depending on your RAM size\n",
        "#   replay_memory_priority_fraction: 0.25\n",
        "#   update_per_k_game_steps: 4\n",
        "#   replay_batch_size: 4\n",
        "\n",
        "#   # epsilon greedy\n",
        "#   epsilon_anneal_episodes: 60  # -1 if not annealing\n",
        "#   epsilon_anneal_from: 1.0\n",
        "#   epsilon_anneal_to: 0.2\n",
        "\n",
        "# checkpoint:\n",
        "#   experiment_tag: 'starting-kit'\n",
        "#   model_checkpoint_path: '/gdrive/My Drive/saved_models'\n",
        "#   load_pretrained: False  # during test, enable this so that the agent load your pretrained model\n",
        "#   pretrained_experiment_tag: 'starting-kit'\n",
        "#   save_frequency: 200\n",
        "\n",
        "# training:\n",
        "#   batch_size: 1\n",
        "#   nb_epochs: 100\n",
        "#   max_nb_steps_per_episode: 100  # after this many steps, a game is terminated\n",
        "#   optimizer:\n",
        "#     step_rule: 'adam'  # adam\n",
        "#     learning_rate: 0.001\n",
        "#     clip_grad_norm: 5\n",
        "\n",
        "# model:\n",
        "#   embedding_size: 64\n",
        "#   encoder_rnn_hidden_size: [64]\n",
        "#   action_scorer_hidden_dim: 32\n",
        "#   dropout_between_rnn_layers: 0.\n",
        "#   bert_model: 'bert-base-uncased'\n",
        "#   layer_index: 11\n",
        "# \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R69AITdxqig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 6 games more than 20 epochs\n",
        "# with open('./config.yaml', 'w') as config:\n",
        "#     config.write(\"\"\"general:\n",
        "#   discount_gamma: 0.7\n",
        "#   random_seed: 42\n",
        "#   use_cuda: True  # disable this when running on machine without cuda\n",
        "\n",
        "#   # replay memory\n",
        "#   replay_memory_capacity: 100000  # adjust this depending on your RAM size\n",
        "#   replay_memory_priority_fraction: 0.25\n",
        "#   update_per_k_game_steps: 4\n",
        "#   replay_batch_size: 4\n",
        "\n",
        "#   # epsilon greedy\n",
        "#   epsilon_anneal_episodes: 60  # -1 if not annealing\n",
        "#   epsilon_anneal_from: 1.0\n",
        "#   epsilon_anneal_to: 0.2\n",
        "\n",
        "# checkpoint:\n",
        "#   experiment_tag: 'starting-kit'\n",
        "#   model_checkpoint_path: '/gdrive/My Drive/saved_models'\n",
        "#   load_pretrained: False  # during test, enable this so that the agent load your pretrained model\n",
        "#   pretrained_experiment_tag: 'starting-kit'\n",
        "#   save_frequency: 200\n",
        "\n",
        "# training:\n",
        "#   batch_size: 1\n",
        "#   nb_epochs: 100\n",
        "#   max_nb_steps_per_episode: 100  # after this many steps, a game is terminated\n",
        "#   optimizer:\n",
        "#     step_rule: 'adam'  # adam\n",
        "#     learning_rate: 0.001\n",
        "#     clip_grad_norm: 5\n",
        "\n",
        "# model:\n",
        "#   embedding_size: 64\n",
        "#   encoder_rnn_hidden_size: [64]\n",
        "#   action_scorer_hidden_dim: 32\n",
        "#   dropout_between_rnn_layers: 0.\n",
        "#   bert_model: 'bert-base-uncased'\n",
        "#   layer_index: 11\n",
        "# \"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufN2JE2f1eTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./config.yaml', 'w') as config:\n",
        "    config.write(\"\"\"general:\n",
        "  discount_gamma: 0.7\n",
        "  random_seed: 42\n",
        "  use_cuda: True  # disable this when running on machine without cuda\n",
        "\n",
        "  # replay memory\n",
        "  replay_memory_capacity: 100000  # adjust this depending on your RAM size\n",
        "  replay_memory_priority_fraction: 0.25\n",
        "  update_per_k_game_steps: 8\n",
        "  replay_batch_size: 32\n",
        "\n",
        "  # epsilon greedy\n",
        "  epsilon_anneal_episodes: 60  # -1 if not annealing\n",
        "  epsilon_anneal_from: 1.0\n",
        "  epsilon_anneal_to: 0.2\n",
        "\n",
        "checkpoint:\n",
        "  experiment_tag: 'starting-kit'\n",
        "  model_checkpoint_path: '/gdrive/My Drive/Masters/TextWorld/models'\n",
        "  load_pretrained: False  # during test, enable this so that the agent load your pretrained model\n",
        "  pretrained_experiment_tag: 'starting-kit'\n",
        "  save_frequency: 100\n",
        "\n",
        "training:\n",
        "  batch_size: 16\n",
        "  nb_epochs: 100\n",
        "  max_nb_steps_per_episode: 100  # after this many steps, a game is terminated\n",
        "  optimizer:\n",
        "    step_rule: 'adam'  # adam\n",
        "    learning_rate: 0.001\n",
        "    clip_grad_norm: 5\n",
        "\n",
        "model:\n",
        "  embedding_size: 192\n",
        "  encoder_rnn_hidden_size: [192]\n",
        "  action_scorer_hidden_dim: 64\n",
        "  dropout_between_rnn_layers: 0.\n",
        "  bert_model: 'bert-base-uncased'\n",
        "  train_bert: False\n",
        "  layer_index: 11\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je184JvpCfos",
        "colab_type": "text"
      },
      "source": [
        "### Mount drive to load games\n",
        "\n",
        "Notebook takes sample games from google drive(requires authentication).\n",
        "\n",
        "To train the agent with games, upload archive with them in google drive and fix the path to the archive inside drive below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XugC3fAz9hpB",
        "colab_type": "code",
        "outputId": "3a4e85b1-64aa-4f8b-f600-699859a5fb2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdMypOrSL4jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "home_dir = '/gdrive/My Drive/Masters/TextWorld/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qv6m4A4MgY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_sample_games = home_dir + 'sample_games'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNOgW2K4NzCO",
        "colab_type": "code",
        "outputId": "29945c7c-af15-43ce-da42-4ba1f27509b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "path_to_sample_games"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/My Drive/Masters/TextWorld/sample_games'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hLhnwCACncb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8hIulvHzNce",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e7f1fb71-9ce2-41e4-8a14-f96a2362b35a",
        "id": "2HzAOxlCPDNI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# List of additional information available during evaluation.\n",
        "AVAILABLE_INFORMATION = EnvInfos(\n",
        "    description=True, inventory=True,\n",
        "    max_score=True, objective=True, entities=True, verbs=True,\n",
        "    command_templates=True, admissible_commands=True,\n",
        "    has_won=True, has_lost=True,\n",
        "    extras=[\"recipe\"]\n",
        ")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "pd.options.display.width = 120\n",
        "\n",
        "def _validate_requested_infos(infos: EnvInfos):\n",
        "    msg = \"The following information cannot be requested: {}\"\n",
        "    for key in infos.basics:\n",
        "        if not getattr(AVAILABLE_INFORMATION, key):\n",
        "            raise ValueError(msg.format(key))\n",
        "\n",
        "    for key in infos.extras:\n",
        "        if key not in AVAILABLE_INFORMATION.extras:\n",
        "            raise ValueError(msg.format(key))\n",
        "            \n",
        "def get_index(game_no, stats):\n",
        "    return \"G{}_{}\".format(game_no, stats)\n",
        "            \n",
        "def print_epoch_stats(epoch_no, stats):\n",
        "    print(\"\\n\\nEpoch: {:3d}\".format(epoch_no))\n",
        "    steps, scores = stats[\"steps\"], stats[\"scores\"]\n",
        "    games_cnt, parallel_cnt = len(steps), len(steps[0])\n",
        "    columns = [ get_index(col, st) for col in range(games_cnt) for st in ['steps', 'scores']]\n",
        "    stats_df = pd.DataFrame(index=list(range(parallel_cnt)) + [\"avr\"], columns=columns)\n",
        "        \n",
        "    for col in range(games_cnt):\n",
        "        for row in range(parallel_cnt):\n",
        "            stats_df[get_index(col, 'steps')][row] = steps[col][row]\n",
        "            stats_df[get_index(col, 'scores')][row] = scores[col][row]\n",
        "        stats_df[get_index(col, 'scores')]['avr'] = stats_df[get_index(col, 'scores')].mean()\n",
        "        stats_df[get_index(col, 'steps')]['avr'] = stats_df[get_index(col, 'steps')].mean()\n",
        "    print(stats_df)\n",
        "\n",
        "def train(game_files):\n",
        "    agent = CustomAgent()\n",
        "    requested_infos = agent.select_additional_infos()\n",
        "    _validate_requested_infos(requested_infos)\n",
        "\n",
        "    env_id = textworld.gym.register_games(game_files, requested_infos,\n",
        "                                          max_episode_steps=agent.max_nb_steps_per_episode,\n",
        "                                          name=\"training\")\n",
        "    env_id = textworld.gym.make_batch(env_id, batch_size=agent.batch_size, parallel=True)\n",
        "    print(\"Making {} parallel environments to train on them\\n\".format(agent.batch_size))\n",
        "    env = gym.make(env_id)\n",
        "    max_score = -1\n",
        "    game_range = range(len(game_files))\n",
        "    for epoch_no in range(1, agent.nb_epochs + 1):\n",
        "        stats = {\n",
        "            \"scores\": [],\n",
        "            \"steps\": [],\n",
        "        }\n",
        "        \n",
        "        for game_no in tqdm(game_range):\n",
        "            obs, infos = env.reset()\n",
        "            agent.train()\n",
        "\n",
        "            scores = [0] * len(obs) \n",
        "            dones = [False] * len(obs)\n",
        "            steps = [0] * len(obs)\n",
        "            while not all(dones):\n",
        "                # Increase step counts.\n",
        "                steps = [step + int(not done) for step, done in zip(steps, dones)]\n",
        "                commands = agent.act(obs, scores, dones, infos)\n",
        "                obs, scores, dones, infos = env.step(commands)\n",
        "\n",
        "            # Let the agent knows the game is done.\n",
        "            agent.act(obs, scores, dones, infos)\n",
        "\n",
        "            stats[\"scores\"].append(scores)\n",
        "            stats[\"steps\"].append(steps)\n",
        "            \n",
        "        #score = sum(stats[\"scores\"]) / agent.batch_size\n",
        "        #steps = sum(stats[\"steps\"]) / agent.batch_size\n",
        "        \n",
        "        print_epoch_stats(epoch_no, stats)\n",
        "    return\n",
        "          \n",
        "\n",
        "game_dir = path_to_sample_games\n",
        "games = []\n",
        "if os.path.isdir(game_dir):\n",
        "    games += glob.glob(os.path.join(game_dir, \"*.ulx\"))\n",
        "print(\"{} games found for training.\".format(len(games)))\n",
        "\n",
        "if len(games) != 0:\n",
        "    train(games)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 games found for training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 416440.76B/s]\n",
            "100%|██████████| 407873900/407873900 [00:35<00:00, 11492724.29B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total number of parameters: 115998016\n",
            "number of trainable parameters: 6515776\n",
            "Making 16 parallel environments to train on them\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n",
            " 83%|████████▎ | 5/6 [09:55<01:52, 112.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "open fridge\n",
            "imitate\n",
            "take yellow bell pepper from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice yellow bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [10:02<00:00, 80.99s/it] \n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "\n",
            "\n",
            "Epoch:   1\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0      100         0      100         0      100         0      100         0       11         6\n",
            "1        100         0      100         0      100         0      100         0      100         0       11         6\n",
            "2        100         0      100         0      100         0      100         0      100         0       11         6\n",
            "3        100         0      100         0      100         0      100         0      100         0       11         6\n",
            "4        100         0      100         0      100         0       40         0      100         0       11         6\n",
            "5        100         0      100         0      100         0        7         0      100         0       11         6\n",
            "6        100         0      100         0      100         0      100         0      100         0       11         6\n",
            "7        100         0      100         0       21         0      100         0      100         0       11         6\n",
            "8        100         0      100         0       72         0      100         0      100         0       11         6\n",
            "9        100         0      100         0      100         0      100         0      100         0       11         6\n",
            "10       100         0      100         0      100         0      100         0      100         0       11         6\n",
            "11       100         0      100         0      100         0      100         0      100         0       11         6\n",
            "12       100         0      100         0      100         0       96         0      100         0       11         6\n",
            "13       100         0      100         0      100         0      100         0      100         0       11         6\n",
            "14       100         0      100         0      100         0      100         0      100         0       11         6\n",
            "15       100         0      100         0      100         0      100         0      100         0       11         6\n",
            "avr      100         0      100         0  93.3125         0  90.1875         0      100         0       11         6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 2/6 [03:45<08:10, 122.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "chop block of cheese with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice parsley with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 3/6 [03:54<04:25, 88.54s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [11:08<00:00, 126.10s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:   2\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0      100         0       14         6       65         0      100         0      100         0\n",
            "1        100         0      100         0       14         6      100         0      100         0      100         0\n",
            "2        100         0      100         0       14         6      100         0      100         0      100         0\n",
            "3        100         1       78         0       14         6      100         0      100         0      100         0\n",
            "4        100         0      100         0       14         6      100         0      100         0      100         0\n",
            "5        100         0      100         0       14         6      100         0      100         0      100         0\n",
            "6        100         0       22         0       14         6      100         0      100         0      100         0\n",
            "7        100         0      100         0       14         6      100         0      100         0      100         0\n",
            "8        100         0      100         0       14         6      100         0      100         0      100         0\n",
            "9        100         0      100         0       14         6      100         0      100         0      100         0\n",
            "10       100         0      100         0       14         6      100         0      100         0      100         0\n",
            "11       100         0      100         0       14         6      100         0      100         0      100         0\n",
            "12       100         0      100         0       14         6      100         0      100         0      100         0\n",
            "13       100         0      100         0       14         6      100         0      100         0      100         0\n",
            "14       100         0      100         0       14         6      100         0      100         0      100         0\n",
            "15       100         0       75         0       14         6      100         0      100         0      100         0\n",
            "avr      100    0.0625  92.1875         0       14         6  97.8125         0      100         0      100         0\n",
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop red potato\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go east\n",
            "imitate\n",
            "go west\n",
            "imitate\n",
            "go north\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go north\n",
            "imitate\n",
            "cook yellow potato with BBQ\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go east\n",
            "imitate\n",
            "drop salt\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice red hot pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take salt\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red hot pepper\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [00:18<01:30, 18.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 3/6 [04:48<03:53, 77.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "chop block of cheese with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice parsley with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [04:56<01:53, 56.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "take red apple from counter\n",
            "imitate\n",
            "take red onion from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "cook red apple with oven\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red onion\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red onion with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take yellow potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [05:10<00:43, 44.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "open fridge\n",
            "imitate\n",
            "take yellow bell pepper from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice yellow bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [05:17<00:00, 32.99s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "\n",
            "\n",
            "Epoch:   3\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0         29         5      100         0      100         0       14         6       22        10       11         6\n",
            "1         29         5      100         0      100         0       14         6       22        10       11         6\n",
            "2         29         5      100         0      100         0       14         6       22        10       11         6\n",
            "3         29         5      100         0      100         0       14         6       22        10       11         6\n",
            "4         29         5      100         0      100         0       14         6       22        10       11         6\n",
            "5         29         5      100         0      100         0       14         6       22        10       11         6\n",
            "6         29         5      100         0        6         0       14         6       22        10       11         6\n",
            "7         29         5      100         0      100         0       14         6       22        10       11         6\n",
            "8         29         5      100         0       80         0       14         6       22        10       11         6\n",
            "9         29         5      100         0      100         0       14         6       22        10       11         6\n",
            "10        29         5      100         0       33         0       14         6       22        10       11         6\n",
            "11        29         5      100         0      100         0       14         6       22        10       11         6\n",
            "12        29         5      100         0      100         0       14         6       22        10       11         6\n",
            "13        29         5      100         0      100         0       14         6       22        10       11         6\n",
            "14        29         5      100         0       45         0       14         6       22        10       11         6\n",
            "15        29         5      100         0      100         0       14         6       22        10       11         6\n",
            "avr       29         5      100         0    85.25         0       14         6       22        10       11         6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [02:16<11:21, 136.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "chop block of cheese with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice parsley with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [02:24<06:31, 97.87s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 5/6 [09:38<02:09, 129.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop red potato\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go east\n",
            "imitate\n",
            "go west\n",
            "imitate\n",
            "go north\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go north\n",
            "imitate\n",
            "cook yellow potato with BBQ\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go east\n",
            "imitate\n",
            "drop salt\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice red hot pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take salt\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red hot pepper\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [09:57<00:00, 96.55s/it] \n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "\n",
            "\n",
            "Epoch:   4\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0       14         6      100         0      100         0      100         0       29         5\n",
            "1        100         0       14         6      100         0      100         0      100         0       29         5\n",
            "2        100         0       14         6      100         0      100         0      100         0       29         5\n",
            "3        100         0       14         6      100         0      100         0      100         0       29         5\n",
            "4        100         0       14         6      100         0      100         0      100         0       29         5\n",
            "5        100         0       14         6      100         0      100         0      100         0       29         5\n",
            "6        100         0       14         6      100         0      100         0      100         0       29         5\n",
            "7        100         0       14         6      100         0      100         0      100         0       29         5\n",
            "8         90         0       14         6      100         0      100         0      100         0       29         5\n",
            "9        100         0       14         6      100         0      100         0      100         0       29         5\n",
            "10       100         0       14         6      100         0      100         0      100         0       29         5\n",
            "11       100         0       14         6      100         0      100         0      100         0       29         5\n",
            "12       100         0       14         6      100         0      100         0      100         0       29         5\n",
            "13        99         0       14         6      100         0      100         0      100         0       29         5\n",
            "14       100         0       14         6      100         0      100         0      100         0       29         5\n",
            "15       100         0       14         6      100         0      100         0      100         0       29         5\n",
            "avr  99.3125         0       14         6      100         0      100         0      100         0       29         5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 4/6 [08:46<04:34, 137.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "take red hot pepper from counter\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [08:48<01:36, 96.78s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [11:13<00:00, 111.26s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:   5\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "1        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "2        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "3        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "4        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "5        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "6        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "7        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "8        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "9        100         0      100         0      100         0      100         0        3         3      100         0\n",
            "10       100         0      100         0      100         0      100         0        3         3      100         0\n",
            "11       100         0      100         0      100         0      100         0        3         3      100         0\n",
            "12       100         0      100         0      100         0      100         0        3         3      100         0\n",
            "13       100         0      100         0      100         0      100         0        3         3      100         0\n",
            "14       100         0      100         0      100         0      100         0        3         3      100         0\n",
            "15       100         0      100         0      100         0      100         0        3         3      100         0\n",
            "avr      100         0      100         0      100         0      100         0        3         3      100         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [02:38<13:14, 158.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop red potato\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go east\n",
            "imitate\n",
            "go west\n",
            "imitate\n",
            "go north\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go north\n",
            "imitate\n",
            "cook yellow potato with BBQ\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go east\n",
            "imitate\n",
            "drop salt\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice red hot pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take salt\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red hot pepper\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [02:57<07:47, 116.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 3/6 [05:55<06:45, 135.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "cook orange bell pepper with oven\n",
            "imitate\n",
            "cook purple potato with stove\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "dice orange bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take purple potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice purple potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "drop orange bell pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take orange bell pepper\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [06:09<03:17, 98.79s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [08:56<01:59, 119.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "take red apple from counter\n",
            "imitate\n",
            "take red onion from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "cook red apple with oven\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red onion\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red onion with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take yellow potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 6/6 [09:10<00:00, 87.71s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 3/6 [06:27<06:48, 136.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:   6\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0       29         5      100         0       22         7      100         0       22        10\n",
            "1        100         0       29         5      100         0       22         7      100         0       22        10\n",
            "2        100         0       29         5      100         0       22         7      100         0       22        10\n",
            "3        100         0       29         5      100         0       22         7      100         0       22        10\n",
            "4        100         0       29         5      100         0       22         7      100         0       22        10\n",
            "5        100         0       29         5      100         0       22         7       47         0       22        10\n",
            "6        100         0       29         5      100         0       22         7      100         0       22        10\n",
            "7        100         0       29         5      100         0       22         7      100         0       22        10\n",
            "8        100         0       29         5      100         0       22         7      100         0       22        10\n",
            "9        100         0       29         5      100         0       22         7      100         0       22        10\n",
            "10       100         0       29         5      100         0       22         7      100         0       22        10\n",
            "11       100         0       29         5      100         0       22         7      100         0       22        10\n",
            "12       100         0       29         5      100         0       22         7      100         0       22        10\n",
            "13       100         0       29         5      100         0       22         7      100         0       22        10\n",
            "14       100         0       29         5      100         0       22         7      100         0       22        10\n",
            "15       100         0       29         5      100         0       22         7      100         0       22        10\n",
            "avr      100         0       29         5      100         0       22         7  96.6875         0       22        10\n",
            "imitate\n",
            "take red apple from counter\n",
            "imitate\n",
            "take red onion from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "cook red apple with oven\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red onion\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red onion with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take yellow potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [06:41<03:18, 99.44s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [08:49<01:48, 108.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "cook orange bell pepper with oven\n",
            "imitate\n",
            "cook purple potato with stove\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "dice orange bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take purple potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice purple potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "drop orange bell pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take orange bell pepper\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 6/6 [09:03<00:00, 79.90s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 17%|█▋        | 1/6 [02:20<11:40, 140.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:   7\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0      100         0      100         1       22        10      100         0       22         7\n",
            "1        100         0      100         0      100         1       22        10      100         0       22         7\n",
            "2         27         0      100         0      100         1       22        10      100         0       22         7\n",
            "3        100         0      100         0      100         1       22        10      100         0       22         7\n",
            "4        100         0       54         0      100         1       22        10      100         0       22         7\n",
            "5        100         0      100         0      100         0       22        10      100         0       22         7\n",
            "6        100         0      100         0      100         1       22        10      100         0       22         7\n",
            "7        100         0      100         0      100         1       22        10      100         0       22         7\n",
            "8        100         0      100         0      100         1       22        10      100         0       22         7\n",
            "9        100         0      100         0      100         1       22        10      100         0       22         7\n",
            "10        38         0      100         0      100         1       22        10      100         0       22         7\n",
            "11       100         0      100         0      100         1       22        10      100         0       22         7\n",
            "12       100         0      100         0      100         1       22        10      100         0       22         7\n",
            "13        16         0      100         0      100         1       22        10      100         0       22         7\n",
            "14       100         0      100         0      100         1       22        10      100         0       22         7\n",
            "15       100         0      100         0      100         1       22        10      100         0       22         7\n",
            "avr  86.3125         0   97.125         0      100    0.9375       22        10      100         0       22         7\n",
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "cook orange bell pepper with oven\n",
            "imitate\n",
            "cook purple potato with stove\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "dice orange bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take purple potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice purple potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "drop orange bell pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take orange bell pepper\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [02:33<06:48, 102.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [11:01<00:00, 118.35s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:   8\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "1        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "2        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "3        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "4        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "5        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "6        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "7        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "8        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "9        100         0       22         7      100         0      100         0      100         0      100         0\n",
            "10       100         0       22         7      100         0      100         0      100         0      100         0\n",
            "11       100         0       22         7      100         0      100         0      100         0      100         0\n",
            "12       100         0       22         7      100         0      100         0      100         0      100         0\n",
            "13       100         0       22         7      100         0      100         0      100         0      100         0\n",
            "14       100         0       22         7      100         0      100         0      100         0      100         0\n",
            "15       100         0       22         7      100         0      100         0      100         0      100         0\n",
            "avr      100         0       22         7      100         0      100         0      100         0      100         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 5/6 [11:37<02:14, 134.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "take red apple from counter\n",
            "imitate\n",
            "take red onion from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "cook red apple with oven\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red onion\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red onion with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take yellow potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 6/6 [11:51<00:00, 98.33s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n",
            "\n",
            "\n",
            "Epoch:   9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\r  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0      100         0      100         0      100         0      100         0       22        10\n",
            "1        100         0      100         0      100         0      100         0      100         0       22        10\n",
            "2        100         0      100         0      100         0      100         0      100         0       22        10\n",
            "3        100         0      100         0      100         0      100         0      100         0       22        10\n",
            "4         20         0      100         0      100         0      100         0      100         0       22        10\n",
            "5        100         0      100         0      100         0      100         0      100         0       22        10\n",
            "6        100         0      100         0      100         0      100         0      100         0       22        10\n",
            "7        100         0      100         0      100         0      100         0      100         0       22        10\n",
            "8        100         0      100         0      100         0      100         0      100         0       22        10\n",
            "9        100         0      100         0      100         0      100         0      100         0       22        10\n",
            "10       100         0      100         0      100         0      100         0      100         0       22        10\n",
            "11        74         0      100         0      100         0      100         0      100         0       22        10\n",
            "12       100         0      100         0      100         0      100         0      100         0       22        10\n",
            "13       100         0      100         0      100         0      100         0      100         0       22        10\n",
            "14       100         0      100         0      100         0      100         0      100         0       22        10\n",
            "15       100         0      100         0      100         0      100         0      100         0       22        10\n",
            "avr   93.375         0      100         0      100         0      100         0      100         0       22        10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [02:40<13:20, 160.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "take red apple from counter\n",
            "imitate\n",
            "take red onion from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "cook red apple with oven\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red onion\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red onion with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take yellow potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [02:53<07:44, 116.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "open fridge\n",
            "imitate\n",
            "take yellow bell pepper from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice yellow bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 3/6 [03:01<04:10, 83.59s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "cook orange bell pepper with oven\n",
            "imitate\n",
            "cook purple potato with stove\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "dice orange bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take purple potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice purple potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "drop orange bell pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take orange bell pepper\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [03:15<02:05, 62.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [06:53<00:00, 88.35s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  10\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "1        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "2        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "3        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "4        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "5        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "6        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "7        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "8        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "9        100         0       22        10       11         6       22         7      100         0      100         0\n",
            "10       100         0       22        10       11         6       22         7      100         0      100         0\n",
            "11       100         0       22        10       11         6       22         7      100         0      100         0\n",
            "12       100         0       22        10       11         6       22         7      100         0      100         0\n",
            "13       100         0       22        10       11         6       22         7      100         0      100         0\n",
            "14       100         0       22        10       11         6       22         7      100         0      100         0\n",
            "15       100         0       22        10       11         6       22         7      100         0      100         0\n",
            "avr      100         0       22        10       11         6       22         7      100         0      100         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [02:35<12:55, 155.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "open fridge\n",
            "imitate\n",
            "take yellow bell pepper from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice yellow bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [02:42<07:23, 110.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 3/6 [04:08<05:10, 103.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "cook orange bell pepper with oven\n",
            "imitate\n",
            "cook purple potato with stove\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "dice orange bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take purple potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice purple potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "drop orange bell pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take orange bell pepper\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [04:22<02:33, 76.56s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [09:01<00:00, 109.19s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  11\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "1        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "2        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "3        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "4        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "5        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "6        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "7        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "8        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "9        100         0       11         6      100         0       22         7      100         0      100         0\n",
            "10       100         0       11         6      100         0       22         7      100         0      100         0\n",
            "11       100         0       11         6      100         0       22         7      100         0      100         0\n",
            "12       100         0       11         6      100         0       22         7      100         0      100         0\n",
            "13       100         0       11         6      100         0       22         7      100         0      100         0\n",
            "14       100         0       11         6      100         0       22         7      100         0      100         0\n",
            "15       100         0       11         6      100         0       22         7      100         0      100         0\n",
            "avr      100         0       11         6      100         0       22         7      100         0      100         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 3/6 [06:11<05:49, 116.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "chop block of cheese with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice parsley with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [06:19<02:47, 83.93s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [11:38<00:00, 123.94s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  12\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         0       22         1      100         0       14         6      100         0      100         0\n",
            "1        100         0       22         1      100         0       14         6      100         0      100         0\n",
            "2        100         0      100         0      100         0       14         6      100         0      100         0\n",
            "3        100         0       22         1      100         0       14         6      100         0      100         0\n",
            "4        100         0       22         1      100         0       14         6      100         0      100         0\n",
            "5        100         0       22         1      100         0       14         6      100         0      100         0\n",
            "6        100         0       20         1      100         0       14         6      100         0      100         0\n",
            "7        100         0       20         1      100         0       14         6      100         0      100         0\n",
            "8        100         0       20         1      100         0       14         6      100         0      100         0\n",
            "9        100         0       22         1      100         0       14         6      100         0      100         0\n",
            "10       100         0       26         1      100         0       14         6      100         0      100         0\n",
            "11       100         0       22         1      100         0       14         6      100         0      100         0\n",
            "12       100         0       20         1      100         0       14         6      100         0      100         0\n",
            "13       100         0       22         1      100         0       14         6      100         0      100         0\n",
            "14       100         0       20         1      100         0       14         6      100         0      100         0\n",
            "15       100         0       22         1      100         0       14         6      100         0      100         0\n",
            "avr      100         0     26.5    0.9375      100         0       14         6      100         0      100         0\n",
            "imitate\n",
            "take red apple from counter\n",
            "imitate\n",
            "take red onion from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "cook red apple with oven\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red onion\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red onion with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take yellow potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [00:13<01:09, 13.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 4/6 [07:44<03:27, 103.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "cook orange bell pepper with oven\n",
            "imitate\n",
            "cook purple potato with stove\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "dice orange bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take purple potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice purple potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "drop orange bell pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take orange bell pepper\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [07:58<01:16, 76.80s/it] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [09:25<00:00, 79.83s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  13\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0         22        10      100         0        9         1      100         1       22         7      100         0\n",
            "1         22        10      100         0        9         1      100         1       22         7      100         0\n",
            "2         22        10      100         0        9         1      100         1       22         7      100         0\n",
            "3         22        10      100         0       10         1      100         1       22         7      100         0\n",
            "4         22        10      100         0       10         1      100         1       22         7      100         0\n",
            "5         22        10      100         0       10         1      100         1       22         7      100         0\n",
            "6         22        10      100         0      100         0      100         1       22         7      100         0\n",
            "7         22        10      100         0        9         1      100         1       22         7      100         0\n",
            "8         22        10      100         0        9         1      100         1       22         7      100         0\n",
            "9         22        10      100         0      100         1      100         1       22         7      100         0\n",
            "10        22        10      100         0        9         1      100         1       22         7      100         0\n",
            "11        22        10      100         0       10         1      100         1       22         7      100         0\n",
            "12        22        10      100         0       10         1      100         1       22         7      100         0\n",
            "13        22        10      100         0        9         1      100         1       22         7      100         0\n",
            "14        22        10      100         0        9         1      100         1       22         7      100         0\n",
            "15        22        10      100         0       10         1      100         1       22         7      100         0\n",
            "avr       22        10      100         0    20.75    0.9375      100         1       22         7      100         0\n",
            "imitate\n",
            "open fridge\n",
            "imitate\n",
            "take yellow bell pepper from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice yellow bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [00:08<00:42,  8.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [10:51<00:00, 110.94s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  14\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0         11         6      100         0      100         0      100         0      100         0      100         0\n",
            "1         11         6      100         0      100         0      100         0      100         0      100         0\n",
            "2         11         6      100         0      100         0      100         0      100         0      100         0\n",
            "3         11         6      100         0      100         0      100         0      100         0      100         0\n",
            "4         11         6      100         0      100         0      100         0      100         0      100         0\n",
            "5         11         6      100         0      100         0      100         0      100         0      100         0\n",
            "6         11         6       36         0      100         0      100         0      100         0      100         0\n",
            "7         11         6      100         0      100         0      100         0      100         0      100         0\n",
            "8         11         6      100         0      100         0      100         0      100         0      100         0\n",
            "9         11         6      100         0      100         0      100         0      100         0      100         0\n",
            "10        11         6      100         0      100         0      100         0      100         0      100         0\n",
            "11        11         6      100         0      100         0      100         0      100         0      100         0\n",
            "12        11         6      100         0      100         0      100         0      100         0      100         0\n",
            "13        11         6      100         0      100         0      100         0      100         0      100         0\n",
            "14        11         6      100         0      100         0      100         0      100         0      100         0\n",
            "15        11         6      100         0      100         0      100         0      100         0      100         0\n",
            "avr       11         6       96         0      100         0      100         0      100         0      100         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [13:08<00:00, 127.38s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  15\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0         94         0      100         0      100         0      100         0      100         1      100         0\n",
            "1        100         0      100         0      100         0      100         0      100         1      100         0\n",
            "2        100         0      100         0      100         0      100         0      100         1      100         0\n",
            "3        100         0      100         0      100         0      100         0      100         1      100         0\n",
            "4        100         0      100         0      100         0      100         0      100         1      100         0\n",
            "5        100         0      100         0      100         0      100         0      100         1      100         0\n",
            "6        100         0      100         0      100         0      100         0      100         1      100         0\n",
            "7        100         0      100         0      100         0      100         0      100         1      100         0\n",
            "8        100         0      100         0      100         0      100         0      100         1      100         0\n",
            "9        100         0      100         0      100         0      100         0      100         1      100         0\n",
            "10       100         0      100         0      100         0      100         0      100         1      100         0\n",
            "11       100         0      100         0      100         0      100         0      100         1      100         0\n",
            "12       100         0      100         0      100         0      100         0      100         1      100         0\n",
            "13       100         0      100         0      100         0      100         0      100         1      100         0\n",
            "14       100         0      100         0      100         0      100         0      100         1      100         0\n",
            "15       100         0      100         0      100         0      100         0      100         1      100         0\n",
            "avr   99.625         0      100         0      100         0      100         0      100         1      100         0\n",
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "cook orange bell pepper with oven\n",
            "imitate\n",
            "cook purple potato with stove\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "dice orange bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take purple potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice purple potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "drop orange bell pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take orange bell pepper\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [00:15<01:15, 15.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "take red apple from counter\n",
            "imitate\n",
            "take red onion from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "cook red apple with oven\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red onion\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red onion with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take yellow potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [00:29<00:59, 14.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 4/6 [05:38<02:56, 88.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop red potato\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go east\n",
            "imitate\n",
            "go west\n",
            "imitate\n",
            "go north\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go north\n",
            "imitate\n",
            "cook yellow potato with BBQ\n",
            "imitate\n",
            "open sliding patio door\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go south\n",
            "imitate\n",
            "go east\n",
            "imitate\n",
            "drop salt\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice red hot pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take salt\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red hot pepper\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [05:57<01:07, 67.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [08:34<00:00, 94.25s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  16\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0         22         7       22        10      100         1      100         1       29         5      100         0\n",
            "1         22         7       22        10      100         1      100         1       29         5      100         0\n",
            "2         22         7       22        10      100         0      100         1       29         5      100         0\n",
            "3         22         7       22        10      100         0      100         1       29         5      100         0\n",
            "4         22         7       22        10      100         0      100         1       29         5      100         0\n",
            "5         22         7       22        10      100         1      100         1       29         5      100         0\n",
            "6         22         7       22        10      100         1      100         1       29         5      100         0\n",
            "7         22         7       22        10      100         0      100         1       29         5      100         0\n",
            "8         22         7       22        10      100         0      100         1       29         5      100         0\n",
            "9         22         7       22        10      100         0      100         1       29         5      100         0\n",
            "10        22         7       22        10      100         0      100         1       29         5      100         0\n",
            "11        22         7       22        10      100         0      100         1       29         5      100         0\n",
            "12        22         7       22        10      100         0      100         1       29         5      100         0\n",
            "13        22         7       22        10      100         0      100         1       29         5      100         0\n",
            "14        22         7       22        10      100         0      100         1       29         5      100         0\n",
            "15        22         7       22        10      100         0      100         1       29         5      100         0\n",
            "avr       22         7       22        10      100      0.25      100         1       29         5      100         0\n",
            "imitate\n",
            "take red apple from counter\n",
            "imitate\n",
            "take red onion from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "cook red apple with oven\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "drop red onion\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red onion\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red onion with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take yellow potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [00:14<01:12, 14.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "open fridge\n",
            "imitate\n",
            "take yellow bell pepper from fridge\n",
            "imitate\n",
            "take yellow potato from counter\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "slice yellow bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [00:23<00:50, 12.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "cook orange bell pepper with oven\n",
            "imitate\n",
            "cook purple potato with stove\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "dice orange bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take purple potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice purple potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "drop orange bell pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take orange bell pepper\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 3/6 [00:37<00:39, 13.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 5/6 [05:50<01:26, 86.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "========= saved checkpoint =========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [07:16<00:00, 86.06s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  17\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "1         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "2         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "3         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "4         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "5         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "6         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "7         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "8         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "9         22        10       11         6       22         7      100         0      100         0      100         0\n",
            "10        22        10       11         6       22         7      100         0      100         0      100         0\n",
            "11        22        10       11         6       22         7      100         0      100         0      100         0\n",
            "12        22        10       11         6       22         7      100         0      100         0      100         0\n",
            "13        22        10       11         6       22         7      100         0      100         0      100         0\n",
            "14        22        10       11         6       22         7      100         0      100         0      100         0\n",
            "15        22        10       11         6       22         7      100         0      100         0      100         0\n",
            "avr       22        10       11         6       22         7      100         0      100         0      100         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [02:21<11:49, 141.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "cook yellow potato with stove\n",
            "imitate\n",
            "take knife from counter\n",
            "imitate\n",
            "chop block of cheese with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice parsley with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice yellow potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [02:29<06:46, 101.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [10:47<00:00, 121.30s/it]\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  18\n",
            "    G0_steps G0_scores G1_steps G1_scores G2_steps G2_scores G3_steps G3_scores G4_steps G4_scores G5_steps G5_scores\n",
            "0        100         1       14         6      100         0      100         1      100         0      100         0\n",
            "1        100         1       14         6      100         0      100         1      100         0      100         0\n",
            "2        100         1       14         6      100         0      100         1      100         0      100         0\n",
            "3        100         1       14         6      100         0      100         1      100         0      100         0\n",
            "4        100         1       14         6      100         0      100         1      100         0      100         0\n",
            "5        100         1       14         6      100         0      100         1      100         0      100         0\n",
            "6        100         1       14         6      100         0      100         1      100         0      100         0\n",
            "7        100         1       14         6      100         0      100         1      100         0      100         0\n",
            "8        100         1       14         6      100         0       96         1      100         0      100         0\n",
            "9        100         1       14         6      100         0      100         1      100         0      100         0\n",
            "10       100         1       14         6      100         0      100         1      100         0      100         0\n",
            "11       100         1       14         6      100         0      100         1      100         0      100         0\n",
            "12       100         1       14         6      100         0      100         1      100         0      100         0\n",
            "13       100         1       14         6      100         0      100         1      100         0      100         0\n",
            "14       100         1       14         6      100         0      100         1      100         0      100         0\n",
            "15       100         1       14         6      100         0      100         1      100         0      100         0\n",
            "avr      100         1       14         6      100         0    99.75         1      100         0      100         0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 3/6 [07:19<07:24, 148.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "drop yellow bell pepper\n",
            "imitate\n",
            "drop yellow potato\n",
            "imitate\n",
            "drop red hot pepper\n",
            "imitate\n",
            "cook orange bell pepper with oven\n",
            "imitate\n",
            "cook purple potato with stove\n",
            "imitate\n",
            "drop purple potato\n",
            "imitate\n",
            "take knife from table\n",
            "imitate\n",
            "dice orange bell pepper with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take purple potato\n",
            "imitate\n",
            "drop red apple\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "dice purple potato with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take red apple\n",
            "imitate\n",
            "drop orange bell pepper\n",
            "imitate\n",
            "take knife\n",
            "imitate\n",
            "slice red apple with knife\n",
            "imitate\n",
            "drop knife\n",
            "imitate\n",
            "take orange bell pepper\n",
            "imitate\n",
            "prepare meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [07:33<03:35, 107.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "imitate\n",
            "eat meal\n",
            "imitate\n",
            "eat meal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [09:41<01:53, 113.89s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrIFg_ec1uvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls saved_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk_E3OyL1bYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}